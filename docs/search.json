[
  {
    "objectID": "lectures/wyklad5.html",
    "href": "lectures/wyklad5.html",
    "title": "Algorytmy kwantowego uczenia maszynowego QML",
    "section": "",
    "text": "\\[\n\\newcommand{\\bra}[1]{\\left \\langle #1 \\right \\rvert}\n\\newcommand{\\ket}[1]{\\left \\rvert #1 \\right \\rangle}\n\\newcommand{\\braket}[2]{\\left \\langle #1 \\middle \\rvert #2 \\right \\rangle}\n\\]\nKomputery kwantowe nie są jeszcze maszynami, które moglibyśmy wykorzystać do codziennych zadań. Dostępne komputery kwantowe pozwalają wykonywać algorytmy i obliczenia na około 100 kubitach. Nie posiadają one jednak mechanizmu korekcji błędów. Ponadto, bramki muszą działać znacznie szybciej niż ich czas dekoherencji, co uniemożliwia realizację długich sekwencji bramek dla złożonych algorytmów. Dlatego obecny etap rozwoju tych maszyn nazywany jest erą NISQ(ang. Noisy Intermediate-Scale Quantum)\nPomimo ograniczeń technologicznych, wciąż można wykazać tzw. kwantową supremację (czyli przewagę algorytmów kwantowych nad klasycznymi) w problemach optymalizacyjnych i w modelowaniu danych wykorzystując do tego celu parametryzowane obwody kwantowe (ang. Parameterized quantum circuits, PQCs), które z wykorzystaniem klasycznych optymalizatorów mogą być trenowane w celu znalezienia optymalnych wartości dla zadanej funkcji kosztu. Podejście takie nazywane jest uczeniem hybrydowym.\nPQC realizowane są z wykorzystaniem bramek w postaci ustalonej (np. bramki CNOT). Wykorzystują one również bramki parametryzowane, co pozwala generować nietrywialne wyniki. Algorytmy przystosowane do realizacji na obecnych komputerach kwantowych nazywamy algorytmami NISQ.\nModele kwantowego uczenia maszynowego (ang. Quantum Machine Learning, QML) realizowane przez kwantowe algorytmy wariacyjne (ang. Variational Quantum Algorithms, VQA) reprezentują całą klasę algorytmów, które używają klasycznych optymalizatorów do znalezienia parametrów kwantowych obwodów. Szczególnymi realizacjami tak zdefiniowanych modeli są:\nPostaramy się zdefiniować jakie problemy i modele możemy sformułować tak by nie wymagały one duzej liczby (zaszumionych) kubitów.\nCały obwód kwantowy moze być kontrolowany za pomocą parametrów realizowanych w bramkach. Mozna go traktować jako rózniczkowalną funkcję.\nAutomatyczne rózniczkowanie wykorzystywane jest w paradygmacie programowania Differentiable programming jak równiez w szeroko stosowanych sieciach neuronowych. Podejście to mozna wyrazic jako coś więcej niz sieci neuronowe. To paradygmat gdzie algorytmy nie są kodowane ale uczące się.",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Algorytmy kwantowego uczenia maszynowego QML"
    ]
  },
  {
    "objectID": "lectures/wyklad5.html#parameterised-quantum-circuit-jak-ogólny-model-uczenia-maszynowego",
    "href": "lectures/wyklad5.html#parameterised-quantum-circuit-jak-ogólny-model-uczenia-maszynowego",
    "title": "Algorytmy kwantowego uczenia maszynowego QML",
    "section": "Parameterised Quantum Circuit jak ogólny model uczenia maszynowego",
    "text": "Parameterised Quantum Circuit jak ogólny model uczenia maszynowego\nWiemy juz jak składać bramki w celu utworzenia dowolnego (i o dowolnej głębokości) obwodu. \\[ \\ket{\\psi'} = U_m(\\theta_m)\\dots U_2(\\theta_2) U_1(\\theta_1) \\ket{\\psi} \\]\nCzęść indywidualnych bramek (ze zbioru \\((U_i)_{i=1,/dots,m}\\)) moze być ustalona np. \\(X\\), \\(CNOT\\), czyli ich parametry są ściśle określone (np. \\(\\pi\\)). Jednak część bramek moze zalezeć od parametrów obrotów wyrazonych najczęściej jako radiany (w zakresi \\(\\theta \\in [-\\pi, \\pi]\\)). Po przygotowaniu stanu \\(\\ket{\\psi'}\\) mozemy zmierzyć jeden lub cały zestaw kubitów. Po pomiarze kubity zostają w stanie bazowym zgodnie z wykorzystanym operatorem. Najczęściej wybieramy bazę obliczeniową pozwalającą uzyskać rezultat jako listę bitów.\nTak zdefiniowany i działający obwód kwantowy mozna wykorzystać do wielu rzeczy. Dla nas najwazniejszym aspektem jest mozliwość trenowania parametrów obwodu.",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Algorytmy kwantowego uczenia maszynowego QML"
    ]
  },
  {
    "objectID": "lectures/wyklad5.html#quantum-neural-networks",
    "href": "lectures/wyklad5.html#quantum-neural-networks",
    "title": "Algorytmy kwantowego uczenia maszynowego QML",
    "section": "Quantum Neural Networks",
    "text": "Quantum Neural Networks\nPQC mozna wykorzystać do tworzenia modelu predykcyjnego - kwantowa sieć neuronowa jako klasyfikator. W tym przypadku dokonuje się pomiaru kilku a nawet jednego kubitu w celu weryfikacji wyniku. Stan początkowy powinien kodować próbkę danych do sklasyfikowania",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Algorytmy kwantowego uczenia maszynowego QML"
    ]
  },
  {
    "objectID": "lectures/wyklad5.html#modele-generatywne",
    "href": "lectures/wyklad5.html#modele-generatywne",
    "title": "Algorytmy kwantowego uczenia maszynowego QML",
    "section": "Modele generatywne",
    "text": "Modele generatywne\nW tym przypadku mozemy zbudować Quantum Circuit Born Machine gdzie dokonujemy pomiaru wszystkich kubitów w celu wygenerowania nowej próbki. Prawdopodobieństwo pojawienia się wartości otrzymanych z próbki zakodowane zostaje w stanie \\(\\ket{\\psi'}\\).",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Algorytmy kwantowego uczenia maszynowego QML"
    ]
  },
  {
    "objectID": "lectures/wyklad5.html#basis-encoding",
    "href": "lectures/wyklad5.html#basis-encoding",
    "title": "Algorytmy kwantowego uczenia maszynowego QML",
    "section": "Basis encoding",
    "text": "Basis encoding\nJedną ze strategii jest tzw. kodowanie bazowe (ang. basis encoding), które polega na zamianie wektora danych wyrażonego w postaci bitowej na wektory bazowe kubitów (\\(0\\to \\ket{0}\\) i \\(1\\to \\ket{1}\\)). Chcąc jednak kodować dużo zmiennych i z dużą precyzją poszczególnych wartości będziemy zmuszeni do wykorzystania bardzo dużej ilości kubitów, co dla obecnych maszyn nie jest zbyt dobrym rozwiązaniem. Kodowanie to, tak samo jak w przypadku bitów, pozwala realizować zarówno liczby całkowite jak i rzeczywiste (dla z góry określonej precyzji).",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Algorytmy kwantowego uczenia maszynowego QML"
    ]
  },
  {
    "objectID": "lectures/wyklad5.html#amplitude-encoding",
    "href": "lectures/wyklad5.html#amplitude-encoding",
    "title": "Algorytmy kwantowego uczenia maszynowego QML",
    "section": "Amplitude encoding",
    "text": "Amplitude encoding\nUkład n-kubitów może być reprezentowany jako superpozycja stanów bazowych. Pozwala to zakodować dane w amplitudach (ang. amplitude encoding). Normalizując wektor danych \\(x=(x_1,\\dots x_{2^k})\\) , tak by \\(\\sum_k |x_k|^2 = 1\\) możemy zakodować wszystkie \\(x_k\\) jako amplitudy. Na przykład \\[x=(0.073,-0.438,0.730,0.000) \\to \\ket{x}=0.073\\ket{00}-0.438 \\ket{01} + 0.730 \\ket{10} + 0\\ket{11} \\]\nWięcej przykładów kwantowego embeddingu",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Algorytmy kwantowego uczenia maszynowego QML"
    ]
  },
  {
    "objectID": "lectures/wyklad5.html#angle-encoding",
    "href": "lectures/wyklad5.html#angle-encoding",
    "title": "Algorytmy kwantowego uczenia maszynowego QML",
    "section": "Angle Encoding",
    "text": "Angle Encoding\nKażdy kubit moze być opisany przez dwa kąty \\(\\theta\\in [0,\\pi]\\) oraz \\(\\phi \\in [0,2\\pi]\\). Każda wartość opisuje jeden punkt na sferze Blocha. Przetwarza ono zmienne na iloczyny i sumy funkcji cosinus i sinus. W kodowaniu tym istotne jest, aby podczas procesu skalowania zmiennych wyskalować je do wartości \\((-1,1)\\).\n\\[\n|x⟩ = cos⁡(x_i) \\ket{0} + sin⁡(x_i)\\ket{1}  \n\\]\n\nSchemat kodowania\nRozwazmy N wierszy 8 zmiennych \\(X_1\\dots X_8\\) o wartościach rzeczywistych.\nPotrzebujemy określić \\(X_i^{max}\\) oraz \\(X_i^{min}\\).\n\\(\\theta^j_i = \\frac{X^j_i - X_i^{min}}{X_i^{max}-X_i^{min}} \\pi\\)\nKorzystając z bramki \\(R_y\\) mozemy zakodować kazdy kubit z osobnym kątem. Mozna takze wybrać dwie bramki z dwoma kątami dla jednego kubitu (\\(R_y\\) i \\(R_z\\))",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Algorytmy kwantowego uczenia maszynowego QML"
    ]
  },
  {
    "objectID": "lectures/wyklad4.html",
    "href": "lectures/wyklad4.html",
    "title": "Kwantowe bramki logiczne w prostych algorytmach i obwodach kwantowych",
    "section": "",
    "text": "Zmianę stanu kwantowego w czasie opisuje Ewolucja kwantowa.\nRozważmy stan układu w chwili \\(t=0\\).\n\\[\\ket{\\psi_{t=0}}\\] W chwili \\(t=1\\) otrzymujemy stan \\(\\ket{\\psi_{t=1}}\\) t. że: \\[\\ket{\\psi_{t=1}} = \\textbf{U} \\, \\ket{\\psi_{t=0}} \\] gdzie \\(\\textbf{U}\\) jest macierzą unitarną.\nPowyższe równanie opisuje zachowanie wszystkich układów kwantowych.\nRozważmy stany bazowe \\(\\ket{0}\\), \\(\\ket{1}\\), które będziemy chcieli zamienic w ich superpozycję. \\[\n\\textbf{U}\\ket{0} = a\\ket{0} + b\\ket{1} = \\begin{bmatrix} a \\\\ b \\end{bmatrix}\n\\] \\[\n\\textbf{U}\\ket{1} = c\\ket{0} + d\\ket{1} = \\begin{bmatrix} c \\\\ d \\end{bmatrix}\n\\]\nKorzystając z tych równań możemy napisac: \\[\n\\textbf{U} = \\left( \\begin{bmatrix} a \\\\ b \\end{bmatrix} \\begin{bmatrix} c \\\\ d \\end{bmatrix}\\right) = \\begin{bmatrix} a \\, \\, b \\\\ c \\,\\, d \\end{bmatrix}\n\\]\nW informatyce macierze unitarne będą realizowały logiczne bramki kwantowe.\n\nDlaczego bramki kwantowe muszą by unitarne?\n\nNorma stanu kwantowego wynosi zawsze 1. Jest to prawdopodobieństwo całkowite sumy stanów bazowych. Prawdopodobieństwo to powinno by zachowane. Co oznacza, że chcemy znaleźc taką transformację, która nie zmienia długości (kwadratu) wektora. Taka transformacja realizowana jest przez obroty.\nWarto zwrócic uwagę na jeszcze jeden fakt. Macierz odwrotna do \\(\\textbf{U}\\) (oznaczana jako \\(\\textbf{U}^{-1}\\)) zawsze istnieje i jest ona równa sprzężeniu Hermitowskiemu macierzu \\(\\textbf{U}=\\textbf{U}^{\\dagger}\\). Dlatego ewolucja stanów kwantowych zawsze jest odwracalna. A to oznacza, że i bramki muszą by operacjami odwracalnymi. \\[\\ket{\\psi_{t=0}} = \\textbf{U}^{\\dagger} \\ket{\\psi_{t=1}} \\]",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Kwantowe bramki logiczne w prostych algorytmach i obwodach kwantowych"
    ]
  },
  {
    "objectID": "lectures/wyklad4.html#ewolucja-kwantowa",
    "href": "lectures/wyklad4.html#ewolucja-kwantowa",
    "title": "Kwantowe bramki logiczne w prostych algorytmach i obwodach kwantowych",
    "section": "",
    "text": "Zmianę stanu kwantowego w czasie opisuje Ewolucja kwantowa.\nRozważmy stan układu w chwili \\(t=0\\).\n\\[\\ket{\\psi_{t=0}}\\] W chwili \\(t=1\\) otrzymujemy stan \\(\\ket{\\psi_{t=1}}\\) t. że: \\[\\ket{\\psi_{t=1}} = \\textbf{U} \\, \\ket{\\psi_{t=0}} \\] gdzie \\(\\textbf{U}\\) jest macierzą unitarną.\nPowyższe równanie opisuje zachowanie wszystkich układów kwantowych.\nRozważmy stany bazowe \\(\\ket{0}\\), \\(\\ket{1}\\), które będziemy chcieli zamienic w ich superpozycję. \\[\n\\textbf{U}\\ket{0} = a\\ket{0} + b\\ket{1} = \\begin{bmatrix} a \\\\ b \\end{bmatrix}\n\\] \\[\n\\textbf{U}\\ket{1} = c\\ket{0} + d\\ket{1} = \\begin{bmatrix} c \\\\ d \\end{bmatrix}\n\\]\nKorzystając z tych równań możemy napisac: \\[\n\\textbf{U} = \\left( \\begin{bmatrix} a \\\\ b \\end{bmatrix} \\begin{bmatrix} c \\\\ d \\end{bmatrix}\\right) = \\begin{bmatrix} a \\, \\, b \\\\ c \\,\\, d \\end{bmatrix}\n\\]\nW informatyce macierze unitarne będą realizowały logiczne bramki kwantowe.\n\nDlaczego bramki kwantowe muszą by unitarne?\n\nNorma stanu kwantowego wynosi zawsze 1. Jest to prawdopodobieństwo całkowite sumy stanów bazowych. Prawdopodobieństwo to powinno by zachowane. Co oznacza, że chcemy znaleźc taką transformację, która nie zmienia długości (kwadratu) wektora. Taka transformacja realizowana jest przez obroty.\nWarto zwrócic uwagę na jeszcze jeden fakt. Macierz odwrotna do \\(\\textbf{U}\\) (oznaczana jako \\(\\textbf{U}^{-1}\\)) zawsze istnieje i jest ona równa sprzężeniu Hermitowskiemu macierzu \\(\\textbf{U}=\\textbf{U}^{\\dagger}\\). Dlatego ewolucja stanów kwantowych zawsze jest odwracalna. A to oznacza, że i bramki muszą by operacjami odwracalnymi. \\[\\ket{\\psi_{t=0}} = \\textbf{U}^{\\dagger} \\ket{\\psi_{t=1}} \\]",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Kwantowe bramki logiczne w prostych algorytmach i obwodach kwantowych"
    ]
  },
  {
    "objectID": "lectures/wyklad4.html#bramki-jednokubitowe",
    "href": "lectures/wyklad4.html#bramki-jednokubitowe",
    "title": "Kwantowe bramki logiczne w prostych algorytmach i obwodach kwantowych",
    "section": "Bramki jednokubitowe",
    "text": "Bramki jednokubitowe\nSpośród wszystkich bramek kwantowych istnieje kilka, które mają swoje ustalone nazwy. Są one często wykorzystywane w obliczeniach kwatnowych. Rozważmy stan \\[\n\\ket{\\psi} = \\alpha \\ket{0} + \\beta \\ket{1}\n\\]\n\nBramka identycznościowa\n\\[\n\\textbf{I} = \\begin{bmatrix} 1 \\,\\, 0 \\\\ 0 \\,\\, 1 \\end{bmatrix}\n\\]\nZobaczmy jak operator ten działa na stany bazowe: \\[ \\textbf{I} \\ket{0} = \\begin{bmatrix} 1 \\,\\, 0 \\\\ 0 \\,\\, 1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} \\]\n\\[ \\textbf{I} \\ket{1} = \\begin{bmatrix} 1 \\,\\, 0 \\\\ 0 \\,\\, 1 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\]\nDziałając na stan \\(\\ket{\\psi}\\) otrzymujemy: \\[\n\\textbf{I} \\ket{\\psi} = \\begin{bmatrix} 1 \\,\\, 0 \\\\ 0 \\,\\, 1 \\end{bmatrix} \\ket{\\psi} =  \\textbf{I} \\left( \\alpha \\ket{0} + \\beta \\ket{1} \\right) = \\alpha \\ket{0} + \\beta \\ket{1}\n\\]\n\n\nBramka negacji X (NOT)\n\\[\n\\textbf{X} = \\begin{bmatrix} 0 \\,\\, 1 \\\\ 1 \\,\\, 0 \\end{bmatrix}\n\\]\n\\[\n\\textbf{X} \\ket{0} = \\begin{bmatrix} 0 \\,\\, 1 \\\\ 1\\,\\, 0 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\ket{1}\n\\]\n\\[\n\\textbf{X} \\ket{1} = \\begin{bmatrix} 0 \\,\\, 1 \\\\ 1 \\,\\, 0 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\ket{0}\n\\]\nDziałając na stan \\(\\ket{\\psi}\\) otrzymujemy: \\[\n\\textbf{X} \\ket{\\psi} = \\begin{bmatrix} 0 \\,\\, 1 \\\\ 1 \\,\\, 0 \\end{bmatrix} \\ket{\\psi} =  \\textbf{X} \\left( \\alpha \\ket{0} + \\beta \\ket{1} \\right) = \\alpha \\ket{1} + \\beta \\ket{0}\n\\]\n\n\nBramka negacji fazy Y\n\\[\n\\textbf{Y} = \\begin{bmatrix} 0 \\,\\, -i \\\\ i \\,\\,\\,\\,\\,\\,\\, 0 \\end{bmatrix}\n\\]\n\\[\n\\textbf{Y} \\ket{0} = \\begin{bmatrix} 0 \\,\\, -i \\\\ i \\,\\,\\,\\,\\,\\,\\, 0 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = i \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = i \\ket{1}\n\\]\n\\[\n\\textbf{Y} \\ket{1} = \\begin{bmatrix} 0 \\, -i \\\\ i \\,\\,\\,\\,\\,\\, 0 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = -i \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = -i \\ket{0}\n\\]\nDziałając na stan \\(\\ket{\\psi}\\) otrzymujemy: \\[\n\\textbf{Y} \\ket{\\psi} = \\begin{bmatrix} 0 \\,\\, -i \\\\ i \\,\\,\\,\\,\\,\\, 0 \\end{bmatrix} \\ket{\\psi} =  \\textbf{Y} \\left( \\alpha \\ket{0} + \\beta \\ket{1} \\right) = \\alpha i \\ket{1} - \\beta i \\ket{0}\n\\]\n\n\nBramka negacji fazy i bitu Z\n\\[\n\\textbf{Z} = \\begin{bmatrix} 1 \\,\\,\\,\\,\\,\\,\\,\\,\\, 0 \\\\ 0\\,\\, -1 \\end{bmatrix}\n\\]\n\\[ \\textbf{Z} \\ket{0} = \\begin{bmatrix} 1\\,\\,\\,\\,\\,\\,\\, 0 \\\\ 0 \\, -1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = 1 \\ket{0} \\]\n\\[ \\textbf{Z} \\ket{1} = \\begin{bmatrix} 1 \\,\\,\\,\\,\\,\\,\\, 0 \\\\ 0 \\, -1 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = -1 \\ket{1}\\]\nDziałając na stan \\(\\ket{\\psi}\\) otrzymujemy: \\[\n\\textbf{Z} \\ket{\\psi} = \\begin{bmatrix} 0 \\,\\,\\,\\,\\,\\,\\, 1 \\\\ 0 \\, -1 \\end{bmatrix} \\ket{\\psi} =  \\textbf{Z} \\left( \\alpha \\ket{0} + \\beta \\ket{1} \\right) = \\alpha \\ket{0} - \\beta \\ket{1}\n\\]\n\n\nBramka Hadamarda H\n\\[\n\\textbf{H}= \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1\\,\\,\\,\\,\\,\\,\\, 1 \\\\ 1 \\, -1 \\end{bmatrix}\n\\]\n\\[\n\\textbf{H} \\ket{0} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1\\,\\,\\,\\,\\,\\,\\, 1 \\\\ 1 \\, -1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\frac{1}{\\sqrt{2}} \\left( \\ket{0} + \\ket{1} \\right) = \\ket{+}\n\\]\n\\[\n\\textbf{H} \\ket{1} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1\\,\\,\\,\\,\\,\\,\\, 1 \\\\ 1 \\, -1 \\end{bmatrix}  \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\frac{1}{\\sqrt{2}} \\left( \\ket{0} - \\ket{1} \\right) = \\ket{-}\n\\]\n\n\n\nLosowy bit\nStwórzmy pierwszy kwantowy program, który wykona zadanie niemożliwe do zrealizowania na komputerze klasycznym. Jak można zauważyc zdefiniowaliśmy bramkę Hadamarda. Brami tej nie było w klasycznych bramkach realizujących operacje na bitach.\nNa przestrzeni dziejów informatyki bardzo dużo czasu i wysiłku poświęcono opracowaniu systemu generowania liczb pseudolosowych (ang. PRNG - Pseudo Random Number Generator), który znalazł szerokie zastosowanie. Generowane liczby traktujemy jako pseudolosowe - tzn. jeśli znasz zawartośc pamięci komputera i algorytm PRNG możesz (przynajmniej teoretycznie) przewidzie jaka jest następna wartosc wygenerowanej liczby.\nZgodnie z zasadami fizyki zachwanie kubitu będącego w superpozycji w czasie dokonania pomiaru jest idealne i nieprzewidywalne. Dzięki temu już pojedynczy kubit pozwala wygenerowa najlepszy na świecie generator liczb losowych.\ninstrukcja\n\nPrzygotuj kubit w stanie początkowym \\(\\ket{0}\\).\nZastosuj bramkę Hadamarda tworząc z kubitu stan superpozycji stanów bazowych.\nWykonaj pomiar\n\nWłaśnie otrzymałeś QRNG - Quantum Random Number Generator. Nie jest to tani sposób na losow rzut monetą. Jednak trzeba miec swiadomośc, że tutaj nie ma wewnętrznego mechanizmu, który generuje losowośc - wynika ona tylko i wyłącznie z praw mechaniki kwantowej.\n\nCzy potrafisz wygenerowac losowy bajt?\n\n\n\nGra w obracanie monety\nWykorzystując powyżej zdefiniowane bramki możemy zrealizowa następującą grę:\n\nW grze bierze udział dwóch graczy. Gracze dysponują monetą, której nie widzą w trakcie gry (np. jest zamknięta w pudełku). Natomiast wiedzą, że początkowo moneta ułożona jest orłem do góry (w stanie \\(\\ket{0}\\)) Gra polega na wykonaniu trzech ruchów na przemian. Każdy ruch polega na odwróceniu monety bądź pozostawieniu jej w takim stanie w jakim była. Gracze nie wiedzą jaki ruch wykonuje przeciwnik. Po ostatnim ruchu pudełko zostaje otwarte i gracze sprawdzają w jakiej pozycji jest moneta. Pierwszy gracz wygrywa jeśli moneta jest w pozycji orła, a drugi jeśli przeciwnie.\n\nSzansa wygranej wynosi dla każdego \\(50\\%\\) i jak można sprawdzic nie istnieje strategia wygrywająca.\nPytanie zasadnicze - a co jeśli zamienimy monetę na kubit?\nMożliwe operacje pozostawienia kubitu w takim samym stanie - bramka I, zmiany stanu na przeciwny bramka X. Czyli pierwszy gracz ustala pierwszą bramkę, drugi drugą i ponownie pierwszy trzecią. Otwarcie pudełka to pomiar stanu kubitu.\n\nPrzeanalizuj wynik dla sekwencji I X I\n\ndef klasycze_strategie():\n    wyniki = []\n    for ruch_1 in ['I','X']:\n        for ruch_2 in ['I','X']:\n            for ruch_3 in ['I','X']:\n                strategia = ruch_1 + ruch_2 + ruch_3\n                ob = obwod(strategia)\n                stats = sedzia(ob())\n                wyniki.append((strategia, stats))\n    return wyniki\nA co jeśli pierwszy gracz wie, że działa na kubicie?\n\nCzy może sprawic on, że wygra zawsze? (skoro wie, że działa na kubicie może użyc innych bramek)",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Kwantowe bramki logiczne w prostych algorytmach i obwodach kwantowych"
    ]
  },
  {
    "objectID": "lectures/wyklad4.html#bramki-dwukubitowe",
    "href": "lectures/wyklad4.html#bramki-dwukubitowe",
    "title": "Kwantowe bramki logiczne w prostych algorytmach i obwodach kwantowych",
    "section": "Bramki dwukubitowe",
    "text": "Bramki dwukubitowe\nAnalogicznie do bramek jednokubitowych reprezentowanych przez macierze unitarne \\(2\\times 2\\) możemy skonstruowac dowolną wielo-kubitową bramkę. Dla n kubitów mamy \\(2^n \\times 2^n\\) unitarną macierz reprezentującą taką bramkę. Ponieważ bramki wielo kubiotwe działają na raz na kilka kubitów mogą służyc one do otrzymywania stanów splątanych. Mamy również możliwośc stworzyc bramkę warunkową (kontrolowaną), która zmienia bit docelowy jeśli kontrolny bit jest w stanie \\(\\ket{1}\\).\nW ogólności taka bramka może zostac zapisana jako: \\[\n\\textbf{CU}= \\ket{0}\\bra{0} \\otimes \\textbf{I} + \\ket{1}\\bra{1} \\otimes \\textbf{\\textbf{U}}\n\\]\nDowolna bramka działajaca na 1 kubit może byc przedstawiona jako mecierz \\[\n\\textbf{U} = \\begin{bmatrix} u_{00} \\, u_{01} \\\\ u_{10}\\, u_{11} \\end{bmatrix}\n\\]\ndlatego:\n\\[\n\\textbf{CU}=  \\begin{bmatrix} 1 \\,\\, \\,\\,\\, 0 \\,\\,\\,\\,\\, 0 \\,\\,\\,\\,\\, 0 \\\\\n0\\,\\, \\,\\,\\, 1 \\,\\,\\,\\,\\, 0 \\,\\,\\,\\,\\, 0 \\\\\n0\\,\\,\\,\\, 0\\,\\,\\,  u_{00} \\,\\, u_{01} \\\\ 0\\,\\,\\,\\, 0\\,\\,\\, u_{10}\\, \\, u_{11} \\end{bmatrix}\n\\]\nSzczegółowe działanie bramki można zapisac jako:\n\\[\\begin{align*}\n\\textbf{CU} \\ket{0} \\otimes \\ket{0} &=&  \\ket{0} \\otimes \\ket{0} \\\\\n\\textbf{CU} \\ket{0} \\otimes \\ket{1} &=& \\ket{0}\\otimes \\ket{1} \\\\\n\\textbf{CU} \\ket{1}\\otimes \\ket{0} &=& \\ket{1}\\otimes \\textbf{U} \\ket{0} \\\\\n\\textbf{CU} \\ket{1}\\otimes \\ket{1} &=& \\ket{1}\\otimes \\textbf{U} \\ket{1} \\\\\n\\end{align*}\\]\nDla kwantowej bramki NOT \\(\\textbf{U}= X\\) \\[\n\\text{CNOT} = \\begin{bmatrix} 1 \\,\\, \\,\\,\\, 0 \\,\\,\\,\\,\\, 0 \\,\\,\\,\\,\\, 0 \\\\\n0\\,\\, \\,\\,\\, 1 \\,\\,\\,\\,\\, 0 \\,\\,\\,\\,\\, 0 \\\\\n0\\,\\,\\,\\,\\, 0\\,\\,\\,\\,\\,  0 \\,\\,\\,\\,\\, 1 \\\\ 0\\,\\,\\,\\,\\, 0\\,\\,\\,\\,\\, 1\\,\\,\\,\\,\\, 0 \\end{bmatrix}\n\\] Bramka ta do drugiego kubitu (targetu) stosuje bramkę X jeśli pierwszy kubit jest w pozycji \\(\\ket{1}\\). W przeciwnym wypadku nie zmienia się nic.\n\\[\\begin{align*}\n\\textbf{CNOT} \\ket{0} \\otimes \\ket{0} &=&  \\ket{0} \\otimes \\ket{0} \\\\\n\\textbf{CNOT} \\ket{0} \\otimes \\ket{1} &=& \\ket{0}\\otimes \\ket{1} \\\\\n\\textbf{CNOT} \\ket{1}\\otimes \\ket{0} &=& \\ket{1}\\otimes \\ket{1} \\\\\n\\textbf{CNOT} \\ket{1}\\otimes \\ket{1} &=& \\ket{1}\\otimes \\ket{0} \\\\\n\\end{align*}\\]\n\nRozpoczynajac od stanu \\(\\ket{0} \\otimes \\ket{0}\\) zadziałaj na pierwszy kubit bramka Hadamarda a na tak otrzymany stan zadziałaj CNOT. Jaki stan uzyskujemy?",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Kwantowe bramki logiczne w prostych algorytmach i obwodach kwantowych"
    ]
  },
  {
    "objectID": "lectures/wyklad3.html",
    "href": "lectures/wyklad3.html",
    "title": "Przestrzenie wektorowe, stany kwantowe, reprezentacja klasycznych i kwantowych bitów",
    "section": "",
    "text": "\\[\n\\newcommand{\\bra}[1]{\\left \\langle #1 \\right \\rvert}\n\\newcommand{\\ket}[1]{\\left \\rvert #1 \\right \\rangle}\n\\newcommand{\\braket}[2]{\\left \\langle #1 \\middle \\rvert #2 \\right \\rangle}\n\\]\nMechanika Kwantowa a zatem i obliczenia kwantowe opierają się na algebrze liniowej. W ogólności teoria ta posługuje się pojęciem nieskończenie wymiarowej przestrzeni liniowej. Na szczęście do opisu kubitów (2-dim) i układów kwantowych (\\(2^{n}\\)-dim) wystarczy nam pojęcie skończenie wymiarowej przestrzeni wektorowej. Bardzo upraszcza nam to naukę o kwantowym uczeniu maszynowym, gdyż wiele problemów matematycznych (dla fizyków) tutaj nie występuje. Upraszcza to również ilość potrzebnych matematycznych pojęć.\nBędziemy posługiwali się notacją Diraca, jednego z twórców mechaniki kwantowej. W książce Ch. Bernhardta “Obliczenia kwantowe dla każdego” autor rezygnuje z liczb zespolonych, na rzecz liczb rzeczywistych. O ile podejście takie sprawdza się na poziomie opisu o tyle dla pełnego zrozumienia posługiwanie się liczbami zespolonymi jest niezbędne.",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Przestrzenie wektorowe, stany kwantowe, reprezentacja klasycznych i kwantowych bitów"
    ]
  },
  {
    "objectID": "lectures/wyklad3.html#liczby-rzeczywiste-i-zespolone---przypomnienie",
    "href": "lectures/wyklad3.html#liczby-rzeczywiste-i-zespolone---przypomnienie",
    "title": "Przestrzenie wektorowe, stany kwantowe, reprezentacja klasycznych i kwantowych bitów",
    "section": "Liczby rzeczywiste i zespolone - przypomnienie",
    "text": "Liczby rzeczywiste i zespolone - przypomnienie\nLiczby to matematyczne, abstrakcyjne pojęcia wywodzące się z teorii mnogości (zbiorów). Przykładowo, liczbę 42 można zapisa w postaci dziesiętnej lub binarnej \\(42=101010_2\\). Możemy znaleźć 42 przedmioty i je przeliczyć, ale w naszym przypadku skupimy się na abstrakcyjnym pojęciu liczby, niezależnie od jej reprezentacji. Liczba 42 jest liczbą naturalną. Zbiór liczb naturalnych oznaczamy jako \\(\\mathbb{N}\\). Identyczne cechy abstrakcji mają liczby całkowite \\(\\mathbb{Z}\\), liczby wymierne \\(\\mathbb{Q}\\), liczby rzeczywiste \\(\\mathbb{R}\\) oraz liczby zespolone \\(\\mathbb{C}\\). Nie możemy zobaczyć ani dotknąć liczb, ale możemy wykonywać na nich operacje matematyczne. Liczb Warto zaznaczyc,że liczby zespolone nie są bardziej abstrakcyjne niż liczby rzeczywiste, czy naturalne.\nLiczba zespolona (we współrzędnych Kartezjańskich) składa się z (dwóch liczb rzeczywistych) części rzeczywistej i urojonej: \\[z=x + i y\\] gdzie \\(i^2=-1\\).\nNatomiast częśc rzeczywista \\(R(z)=x\\) i częśc urojona \\(I(z)=y\\).\nNa przykład: \\[1+i\\sqrt{3}\\] \\(R(z)=1\\) i \\(I(z)=\\sqrt{3}\\).\nInaczej mówiąc, liczba zespolona jest sumą liczby rzeczywistej i urojonej.\nLiczy zespolone, można traktowac jako punkty na płaszczyźnie o współrzędnych \\(x\\) i \\(y\\).\n\nKażdą liczbę zespoloną możemy zapisać w postaci polarnej (współrzędne biegunowe) \\[ z=r\\, e^{i \\phi} , \\] gdzie \\(r=|z|\\) to moduł liczby zespolonej, a \\(\\phi\\) to jej argument czyli wyrażony w radianach kąt między osią rzeczywistą a półprostą poprowadzoną od środka ukł. wsp. i przechodzącą przez punkt \\(z\\). \\[ z = r\\, e^{i \\, \\phi} = r\\, (\\cos{\\phi} + i\\, \\sin{\\phi})\\] gdzie: \\[r = |z| = \\sqrt{x^2 + y^2}\\] \\[\\phi = \\arctan{\\frac{y}{x}}. \\] Natomiast: \\[x = r \\cos{\\phi}\\] \\[y = r \\sin{\\phi}\\]\nDla naszego przykładu: \\[1+i\\sqrt{3} = 2 e^{i \\frac{\\pi}{3}} . \\]\n\nUdowodnij samodzielnie, że powyższe równanie jest prawdziwe.\n\nLiczby zespolone można dodawa, mnożyc i dzieli zgodnie z zwykłymi regułami arytmetyki. Dodawanie liczb zespolonych jest łatwe dla liczb w postaci kartezjańskiej. Natomiast mnożenie liczb zespolonych upraszcza się dla postaci biegunowej (następuje zamiana mnożenia na dodawanie fazy).\nLiczba sprzężona do liczby zespolonej powstaje poprzez zmianę znaku części urojonej\n\\(z=x + i\\, y\\,\\,\\,\\,\\) to \\(\\,\\,\\,z^*=x - i y = r*e^{-i \\phi}\\).\nNorma liczby zespolonej \\(z=x + i y\\,\\,\\,\\,\\) to \\(\\,\\,\\,|z|=\\sqrt{x^2 + y^2}=r\\).\nKwadrat normy liczby zespolonej \\(z=x + i y\\,\\,\\,\\,\\) to \\(\\,\\,\\, |z|^2=x^2 + y^2=r^2\\). Warto zauważyc, że każdy kwadrat modułu daje w wyniku nieujemną liczbę rzeczywistą.\nMożna go również zapisać jako \\[|z|^2=z z^* = z^* z\\]\nCzynniki fazowe to szczególna klasa liczb zespolonych \\(z\\) dla której \\(r=1\\).\nOtrzymujemy wtedy: \\[\nz=e^{i \\phi}=\\cos{\\phi} + i\\, \\sin{\\phi}\\] \\[\nz z^* = 1\n\\]\n\nUdowodnij w kartezjańskim i polarnym układzie oniesienia.\n\n\nile wynosi \\(z_1 z_2\\)\n\n\nile wynosi \\(\\frac{z_1}{z_2}\\)",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Przestrzenie wektorowe, stany kwantowe, reprezentacja klasycznych i kwantowych bitów"
    ]
  },
  {
    "objectID": "lectures/wyklad3.html#wektory-i-przestrzenie-wektorowe",
    "href": "lectures/wyklad3.html#wektory-i-przestrzenie-wektorowe",
    "title": "Przestrzenie wektorowe, stany kwantowe, reprezentacja klasycznych i kwantowych bitów",
    "section": "Wektory i przestrzenie wektorowe",
    "text": "Wektory i przestrzenie wektorowe\nNiech dany będzie zbiór \\(\\mathbb{V}\\) oraz zbiór \\(\\mathbb{K}\\). Elementy zbioru \\(\\mathbb{V}\\) można ze sobą dodawać i mnożyć przez elementy zbioru \\(\\mathbb{K}\\). Wraz z dodatkowymi opracjami (zdefiniowanymi poniżej) zbiór ten będziemy nazwywali przestrzenią wektorową. Jej elementy to wektory ket \\(\\ket{u}\\) (lub kety).\nJeśli współczynniki liczbowe wektorów będą rzeczywiste to będziemy mówić o przestrzeni wektorowej rzeczywistej. Natomiast jeśli liczby te będą zespolone to będziemy mówić o przestrzeni wektorowej zespolonej.\nMyśląc o wektorach często wyobrażamy je sobie jako strzałki w przestrzeni. Przez strzałki rozumiemy tutaj obiekty znajdujące się w zwykłej przestrzeni i posiadające wielkoś oraz kierunek. Wektory takie mają trzy składowe - trzy (rzeczywiste) współrzędne przestrzenne.\nNa tych zajęciach lepiej zapomniec o tej koncepcji. Wszystkie wektory będą reprezentowane jako abstrakcyjne elementy przestrzeni wektorowej. Warto jednak pamiętać, że wszystkie własności (algebraiczne) wektorów są również spełnione dla strzałek.\n\nAksjomaty przestrzeni stanów\nNiech \\(\\ket{v}\\) , \\(\\ket{u}\\), \\(\\ket{z}\\) będą dowolnymi wektorami, natomiast \\(\\alpha\\) i \\(\\beta\\) dowolnymi liczbami.\n\nSuma dwóch wektorów ket jest wektorem ket \\[\\ket{v} + \\ket{u} = \\ket{z}\\]\nDodawanie wektorów jest przemienne: \\[\\ket{v} + \\ket{u} = \\ket{u} + \\ket{v}\\]\nDodawanie wektorów jest łączne: \\[\\ket{v} + (\\ket{u} + \\ket{z}) = (\\ket{v} + \\ket{u}) + \\ket{z}\\]\nIstnieje szczególny (i jedyny) wektor \\(\\ket{v}\\) odwrotny do wektora \\(\\ket{u}\\): \\[\\ket{v} + \\ket{u} = 0\\]\nIstnieje szczególny (i jedyny) wektor \\(0\\) zerowy. Dla każdego wektora \\(\\ket{v}\\) zachodzi: \\[\\ket{v} + 0 = 0 + \\ket{v} = \\ket{v}\\]\n1*wektor = wektor: \\[1 \\ket{v} = \\ket{v}\\]\nŁączność mnożenia przez skalar: \\[\\alpha (\\beta \\ket{v}) = (\\alpha \\beta) \\ket{v}\\]\nRozdzielność mnożenia przez skalar względem dodawania wektorów: \\[\\alpha (\\ket{v} + \\ket{u}) = \\alpha \\ket{v} + \\alpha \\ket{u}\\]\nRozdzielność dodawania skalarów względem mnożenia przez wektor: \\[(\\alpha + \\beta) \\ket{v} = \\alpha \\ket{v} + \\beta \\ket{v}\\]\n\n\n\nWektory kolumnowe\nZapiszmy pionową jednokolumnową tablicę liczb: \\[ \\begin{bmatrix} x_1 \\\\ x_2 \\\\ .\\\\ x_n \\end{bmatrix} \\]\nMnożenie przez liczbę: \\[ \\alpha \\begin{bmatrix} x_1 \\\\ x_2 \\\\ .\\\\ x_n \\end{bmatrix} = \\begin{bmatrix} \\alpha x_1 \\\\ \\alpha x_2 \\\\ .\\\\ \\alpha x_n \\end{bmatrix} \\]\nDodawanie kolumn: \\[ \\begin{bmatrix} x_1 \\\\ x_2 \\\\ .\\\\ x_n \\end{bmatrix} + \\begin{bmatrix} y_1 \\\\ y_2 \\\\ .\\\\ y_n \\end{bmatrix} = \\begin{bmatrix} x_1+y_1 \\\\ x_2+y_2 \\\\ .\\\\ x_n+y_n \\end{bmatrix}\\]\nPozwala to otrzymać konkretną reprezentację wektorów, które będziemy oznaczać w notacji Diraca przez “ket” \\(\\ket{.}\\).\n\n\nWektory wierszowe\n\\[ \\begin{bmatrix} x_1 \\,\\, x_2 \\,\\, \\dots \\,\\, x_n \\end{bmatrix}\\]\nAnalogicznie do poprzedniego przykładu łatwo określić jak dodawać je ze sobą i mnożyć przez liczbę. W notacji Diraca będziemy takie wektory oznaczali przez “bra” \\(\\bra{.}\\).\n\n\nTranspozycja i sprzężenie Hermitowskie.\nTranspozycja \\(T\\) Zamienia wektory wierszowe na kolumnowe i odwrotnie.\n\\[ \\begin{bmatrix} x_1 \\\\ x_2 \\\\ .\\\\ x_n \\end{bmatrix}^{T} = \\begin{bmatrix} x_1 \\,\\, x_2 \\,\\, \\dots \\,\\, x_n \\end{bmatrix}\\]\noraz \\[ \\begin{bmatrix} x_1 \\,\\, x_2 \\,\\, \\dots \\,\\, x_n \\end{bmatrix}^{T} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ .\\\\ x_n \\end{bmatrix}\\]\nNatomiast sprzężenie hermitowskie \\(\\dagger = T \\ast\\) dodatkowo do transpozycji dodaje sprzężenie zespolone.\n\\[\\ket{u}^{\\dagger} = \\bra{u}\\] \\[\\bra{u}^{\\dagger} = \\ket{u}\\]\nCzyli: \\[ (\\ket{u} + \\ket{v})^{\\dagger} = \\bra{u} + \\bra{v} \\] oraz \\[ \\alpha \\ket{u} \\to \\bra{u} \\alpha^*\\]\n\\[ \\begin{bmatrix} x_1 \\\\ x_2 \\\\ .\\\\ x_n \\end{bmatrix}^{\\dagger} = \\begin{bmatrix} x_1^* \\,\\, x_2^* \\,\\, \\dots \\,\\, x_n^* \\end{bmatrix}\\]\noraz \\[ \\begin{bmatrix} x_1 \\,\\, x_2 \\,\\, \\dots \\,\\, x_n \\end{bmatrix}^{\\dagger} = \\begin{bmatrix} x_1^* \\\\ x_2^* \\\\ .\\\\ x_n^* \\end{bmatrix}\\]\n\n\nIloczyn skalarny\nIloczynem skalarnym dwóch wektorów \\(\\ket{u}\\) i \\(\\ket{v}\\) nazywany funkcję, która zwraca liczbę.\n\n\\(\\braket{u}{v} = \\braket{v}{u}^{\\ast}\\)\n\\((\\alpha \\bra{u})\\ket{v} = \\alpha \\braket{u}{v}\\)\n\\((\\bra{u} + \\bra{v}) \\ket{z} = \\braket{u}{z} +\\braket{v}{z}\\)\n\\(\\braket{u}{u} &gt; 0\\)\n\\(\\braket{u}{u} = 0, gdy \\ket{u}=\\ket{0}\\)\n\nDla dwóch wektorów \\(\\ket{u}\\) i \\(\\ket{v}\\) otrzymujemy: \\[ \\ket{u} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ .\\\\ x_n \\end{bmatrix}, \\ket{v} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ .\\\\ y_n \\end{bmatrix} \\]\n\\[ \\braket{u}{v} = x_1^{*}y_1 +x_2^{*}y_2 + \\dots + x_n^{*}y_n\\]\n\nZadanie - Udowodnij, że \\(\\braket{u}{u}\\) jest liczbą rzeczywistą.\n\nwektor znormalizowany \\(\\braket{u}{u}=1\\)\nwektory ortogonalne \\(\\braket{u}{v}=0\\)\n\n\nKombinacja liniowa wektorów\nDla dwóch wektorów \\(\\ket{u}\\) i \\(\\ket{v}\\) oraz dwóch liczb \\(\\alpha\\), \\(\\beta\\) możemy stworzyć nowy wektor: \\[\\ket{z} = \\alpha \\ket{u} + \\beta \\ket{v}\\] Wektor ten nazywamy kombinacją liniową wektorów \\(\\ket{u}\\) i \\(\\ket{v}\\) o współczynnikach \\(\\alpha\\) i \\(\\beta\\).\n\n\nBaza\nKażda przestrzeń wektorowa ma bazę.\nDowolny wektor można zapisa jako kombinację liniową wektorów bazowych.\nInteresowac będzie nas baza (obliczeniowa) dla której:\n\\[ \\braket{e_i}{e_i}=1 \\,\\, \\braket{e_i}{e_j}=0 \\,\\, \\text{dla i} \\neq j \\] gdzie \\(i,\\,j = 1,2,\\dots, n\\).\nDowolny wektor \\(\\ket{u}\\) możemy zapisa jako: \\[ \\ket{u} = \\braket{e_1}{u}\\ket{e_1} + \\braket{e_2}{u}\\ket{e_2} + ... + \\braket{e_n}{u}\\ket{e_n}  \\]\nWarto zauważyc: \\[\\braket{e_1}{u}= x_1\\] \\[\\ket{u} = \\sum_{i=1}^{n} \\ket{i}\\bra{i} \\ket{u}\\]",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Przestrzenie wektorowe, stany kwantowe, reprezentacja klasycznych i kwantowych bitów"
    ]
  },
  {
    "objectID": "lectures/wyklad3.html#formalizm-matematyczny-obliczeń-kwantowych",
    "href": "lectures/wyklad3.html#formalizm-matematyczny-obliczeń-kwantowych",
    "title": "Przestrzenie wektorowe, stany kwantowe, reprezentacja klasycznych i kwantowych bitów",
    "section": "Formalizm matematyczny obliczeń kwantowych",
    "text": "Formalizm matematyczny obliczeń kwantowych\nTa wiedza wystarczy do wyjaśnienia notacji Diraca.\nIloczyn skalarny \\(\\braket{\\psi}{\\phi}\\) wektorów \\(\\ket{\\psi}\\) i \\(\\ket{\\phi}\\) czytamy jako braket u v.\n\nStan\nW fizyce klasycznej znajomość stanu układu oznacza, iż wiemy wszystko co jest potrzebne\nStanem w mechanice kwantowej nazywamy wektor:\n\\[\\ket{\\psi} = x_0 \\ket{0} + x_1 \\ket{1} + \\dots x_{n-1} \\ket{n-1}\\]\nChcemy aby współczynniki \\(x_i\\) były liczbami zespolonymi a cały wektor był unormowany do 1.\nLiczby \\(x_i\\) nazywamy amplitudami prawdopodobieństwa stanu kwantowego. Jeśli przynajmniej dwie liczby \\(x_i\\) są niezerowe, to układ znajduje się w superpozycji stanów.\n\n\nKubit\nElementarnym obiektem w informatyce kwantowej jest kubit, który realizowany jest jako dwu wymiarowy układ kwantowy. Stan kwantowy kubitu opisuje wektor w przestrzeni liniowej \\(\\mathbb{C}^2\\).\nW celu wykonywania obliczeń i opisu stanu kubitu wybierzemy tzw. bazę obliczeniową: \\[\\ket{0} = \\begin{bmatrix} 1 \\\\ 0  \\end{bmatrix} , \\ket{1} = \\begin{bmatrix} 0 \\\\ 1  \\end{bmatrix}\\]\nTo co wyróżnia kubit w porównaniu do klasycznego bitu dowolny stan \\(\\ket{\\psi}\\) może być superpozycją stanów bazowych: \\[\n\\ket{\\psi} = \\alpha \\ket{0} + \\beta \\ket{1} = \\alpha \\begin{bmatrix} 1 \\\\ 0\\end{bmatrix} + \\beta \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} \\alpha \\\\ \\beta \\end{bmatrix}\n\\] dla którego zachodzi warunek normalizacji: \\[\n\\braket{\\psi}{\\psi} = |\\alpha|^2 + |\\beta|^2 = 1\n\\] gdzie \\(\\alpha, \\beta \\in \\mathbb{C}\\).\n\nZADANIE - oblicz \\(\\braket{\\psi}{\\psi}\\).\n\nLiczby \\(\\alpha\\) i \\(\\beta\\) nazywamy amplitudami prawdopodobieństwa. Są one reprezentowane przez liczby zespolone. Potrzeba 4 liczb rzeczywistych aby je opisać. Ze względu na warunek normalizacji jedną liczbę można obliczyc co oznacza potrzebę użycia już tylko trzech liczb rzeczywiste.\nStan kubitu możemy zapisać w postaci: \\[\n\\ket{\\psi} = e^{i \\gamma}\\left( \\cos{\\frac{\\phi}{2}} \\ket{0} + e^{i \\theta} \\sin{\\frac{\\phi}{2}} \\ket{1} \\right)\n\\] gdzie \\(\\phi \\in [0, \\pi]\\), \\(\\theta \\in [0, 2\\pi]\\) i \\(\\gamma \\in [0, 2\\pi]\\) są liczbami rzeczywistymi.\nWspółczynnik \\(e^{i \\gamma}\\) nazywamy fazą globalną. Ze względu, iż analizować będziemy kwadraty amplitud prawdopodobieństwa to faza globalna nie ma znaczenia. Dlatego możemy napisać: \\[\n\\ket{\\psi} = \\cos{\\frac{\\phi}{2}} \\ket{0} + e^{i \\theta} \\sin{\\frac{\\phi}{2}} \\ket{1}\n= \\begin{bmatrix} \\cos{\\frac{\\phi}{2}} \\\\ e^{i \\theta} \\sin{\\frac{\\phi}{2}} \\end{bmatrix}\n\\]\nWarto zauważyć, że dwa dowolne stany kubitów \\(\\ket{\\psi}\\) i \\(\\ket{\\phi}\\) różnią się o czynnik fazowy \\(e^{i \\gamma}\\) to stany te dają identyczne wyniki.\nLiczby rzeczywiste \\(\\phi\\) i \\(\\theta\\) nazywamy kątami kubitu i możemy interpretować je jako współrzędne na sferze Blocha. Bardzo często będziemy wykorzystywać ją do wizualizacji stanów kubitów.\nStany w bazie obliczeniowej, którymi często będziemy operowac: \\[\\ket{+} = \\frac{1}{\\sqrt{2}}(\\ket{0} + \\ket{1})\\] \\[\\ket{-} = \\frac{1}{\\sqrt{2}}(\\ket{0} - \\ket{1})\\] \\[\\ket{i} =\\frac{1}{\\sqrt{2}}(\\ket{0} + i \\ket{1})\\] \\[\\ket{-i} =\\frac{1}{\\sqrt{2}}(\\ket{0} - i \\ket{1})\\]\nLub: \\[\\frac{1}{\\sqrt{2}}(\\ket{0} + e^{i\\pi/6} \\ket{1})\\] \\[\\frac{\\sqrt{3}}{2}(\\ket{0} + \\frac{1}{2} \\ket{1})\\]\n\nKubit może by dowolnym punktem na sferze Blocha.\n\n\n\nDwa kubity\nZłączenie układu dwóch kubitów realizowane jest przez iloczyn tensorowy (iloczyn Kroneckera).\nRozważmy dwa stany kubitów \\(\\ket{\\psi}\\), \\(\\ket{\\phi}\\)\n\\[\n\\ket{\\psi} = \\alpha \\ket{0} + \\beta \\ket{1} = \\begin{bmatrix} \\alpha \\\\ \\beta \\end{bmatrix}\\, ,\\,\\,\n\\ket{\\phi} = \\gamma \\ket{0} + \\delta \\ket{1} = \\begin{bmatrix} \\gamma \\\\ \\delta \\end{bmatrix}\n\\]\nStan dwukubitowy: \\[\n\\ket{\\psi} \\otimes \\ket{\\phi} = \\begin{bmatrix} \\alpha \\gamma \\\\ \\alpha \\delta \\\\ \\beta \\gamma \\\\ \\beta \\delta \\end{bmatrix} = \\alpha \\gamma \\ket{0} \\otimes \\ket{0} + \\beta \\delta \\ket{1} \\otimes \\ket{0}  + \\alpha \\delta \\ket{0} \\otimes \\ket{1}  + \\beta \\delta \\ket{1} \\otimes \\ket{1}\n\\] co możemy zapisa jako: \\[\n\\ket{\\psi \\phi} = \\alpha \\gamma \\ket{00} + \\beta \\delta \\ket{10}  + \\alpha \\delta \\ket{01}  + \\beta \\delta \\ket{11}\n\\] gdzie: \\[\n\\ket{00} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\, \\,\n\\ket{01} = \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\, \\,\n\\ket{10} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 0 \\end{bmatrix}, \\, \\,\n\\ket{11} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{bmatrix}\n\\]\nPo przenumerowaniu stanów możemy napisac: \\[\n\\ket{\\Phi} = c_0 \\ket{0} + c_1 \\ket{1}  + c_2 \\ket{2}  + c_3 \\ket{3}\n\\] dla którego: \\[\n|c_0|^2 + |c_1|^2 + |c_2|^2 + |c_3|^2 = 1\n\\]\n\n\nStan separowalny i splątany\nJeżeli istnieją stany \\(\\ket{\\phi_1}\\) i \\(\\ket{\\phi_2}\\) takie, że \\[\\ket{\\psi} = \\ket{\\phi_1} \\otimes \\ket{\\phi_2}\\] to stan nazywamy separowalny.\nZobaczmy, czy istnieje przypadek w którym stan układu dwóch kubitów nie da się zaprezentowac jako iloczynu tensorowego podukładów. Aby to sprawdzic zobaczmy czy istnieją takie liczby \\(c_0, c_1, c_2, c_3\\) dla których nie da się znaleźc \\(\\alpha, \\beta,\\gamma, \\delta\\), które spełniają układ równań: \\[c_0 = \\alpha \\gamma , \\, c_1 = \\alpha \\delta , \\, c_2 = \\beta \\gamma , \\, c_3 = \\beta \\delta \\]\nRozważmy stan \\[\\ket{bell} = \\frac{1}{\\sqrt{2}}(\\ket{0}+\\ket{3}) = \\frac{1}{\\sqrt{2}}(\\ket{00}+\\ket{11})\\]\nZałóżmy, że możemy zapisa stan bell w postaci: \\[ \\alpha \\gamma \\ket{0} + \\beta \\delta \\ket{1}  + \\alpha \\delta \\ket{2}  + \\beta \\delta \\ket{3} \\]\nAby stan bell był separowalny musi by spełniony układ równań:\n\\[\\begin{eqnarray}\n\\alpha \\gamma = \\frac{1}{\\sqrt{2}} \\\\ \\alpha \\delta = 0 \\\\ \\beta \\gamma = 0 \\\\ \\beta \\delta =\\frac{1}{\\sqrt{2}}\n\\end{eqnarray}\\]\nZ warunku drugiego mamy dwie możliwości: albo \\(\\alpha=0\\) lub \\(\\delta=0\\). Jeżeli \\(\\alpha=0\\) to warunek pierwszy nie może byc spełniony. Jeżeli \\(\\delta=0\\) to warunek czwarty nie może byc spełniony. Otrzymujemy sprzecznośc.\nProwadzi to do wniosu, że stan bell'a nie jest stanem separowalnym i jest stanem splątanym. Stany te mają bardzo nieintuicyjne własności. Związany jest z nimi słynny paradox EPR oraz tak zwane nierówności Bella.\n\nSplątane stany Bell’a, wraz z zasadą superpozycji będą podstawowymi kwantowymi własnościami pozwalającymi zrealizowac przewagę obliczeń kwantowych nad obliczeniami klasycznymi.",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Przestrzenie wektorowe, stany kwantowe, reprezentacja klasycznych i kwantowych bitów"
    ]
  },
  {
    "objectID": "lectures/wyklad3.html#pomiar-w-bazie-z",
    "href": "lectures/wyklad3.html#pomiar-w-bazie-z",
    "title": "Przestrzenie wektorowe, stany kwantowe, reprezentacja klasycznych i kwantowych bitów",
    "section": "Pomiar w bazie Z",
    "text": "Pomiar w bazie Z\nW opisie kubitów wybraliśmy specyficzą bazę (obliczeniową) wektorów, która rozkłada każdy wektor na kombinację wektora \\(\\ket{0}\\) i \\(\\ket{1}\\).\nZasady przestrzeni wektorowej i mechaniki kwantowej dopuszczają tworzenie kombinacji liniowej (superpozycji) dla tych dwóch stanów. \\[\n\\ket{\\psi} = \\alpha \\ket{0} + \\beta \\ket{1}\n\\] Po pomiarze kubitu, czyli na końcu procesu obliczeniowego, ze względu na prawa fizyki otrzymujemy tylko i wyłącznie jeden ze stanów bazowych \\(\\ket{0}\\) lub \\(\\ket{1}\\). Każdy następny pomiar (tej samej obserwabli) będzie kończyc się w tym samym (otrzymanym) stanie.\n\nPomiar niszczy superpozycję kubitu i sprowadza go do jednego ze stanów bazowych.\n\nDla kubitu w superpozycji stanów bazowych jedyne co możemy określic to prawdopodobieństwo otrzymania stanu \\(\\ket{0}\\) i \\(\\ket{1}\\).\n\nPrawdopodobieństwo określone jest jako kwadrat (modułu) amplitudy Dla stanu \\(\\ket{0}\\) \\(P(0) = |\\alpha|^2\\) oraz dla stanu \\(\\ket{1}\\) \\(P(1)= |\\beta|^2\\).\n\nIstnieje możliwośc pomiaru kubitów w innych bazach. Jednak w większości przypadków ograniczymy się do pomiaru w bazie obliczeniowej.\n\nPrzykład\nRozważmy stan \\[\\ket{\\psi} = \\frac{\\sqrt{3}}{2}\\ket{0}+\\frac{1}{2}\\ket{1}\\]\nMożliwe wyniki pomiaru w bazie Z \\(\\{ \\ket{0},\\ket{1} \\}\\).\n\\[\n\\braket{0}{\\psi} = \\bra{0}\\left( \\frac{\\sqrt{3}}{2}\\ket{0} +\\frac{1}{2}\\ket{1}\\right) = \\frac{\\sqrt{3}}{2}\\braket{0}{0} + \\frac{1}{2}\\braket{0}{1} = \\frac{\\sqrt{3}}{2}\n\\] Biorąc kwadrat apmlitudy otrzymujemy kubit w stanie \\(\\ket{0}\\) z prawdopodobieństwem \\(0.75\\). \\[\n\\braket{1}{\\psi} = \\bra{1}\\left( \\frac{\\sqrt{3}}{2}\\ket{0} +\\frac{1}{2}\\ket{1}\\right) = \\frac{\\sqrt{3}}{2}\\braket{1}{0} + \\frac{1}{2}\\braket{1}{1} = \\frac{1}{2}\n\\] Biorąc kwadrat apmlitudy otrzymujemy stan \\(\\ket{1}\\) z prawdopodobieństwem \\(0.25\\).\n\\[\\ket{\\psi} = \\braket{0}{\\psi}\\ket{0} + \\braket{1}{\\psi}\\ket{1}\\]\nDowolna para liniowo niezależnych wektorów jednostkowych \\(\\ket{u}\\) i \\(\\ket{v}\\) pochodząca z dwuwymiarowej przestrzeni wektorowej może tworzyc bazę: \\[\n\\alpha \\ket{0} +\\beta \\ket{1} = \\alpha' \\ket{u} +\\beta' \\ket{v}\n\\] Przykładem może byc tzw Baza Hadamarda \\(\\ket{+}\\) i \\(\\ket{-}\\) zdefiniowana jako: \\[\n\\ket{+} = \\frac{1}{\\sqrt{2}}(\\ket{0}+\\ket{1}) = \\begin{bmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{bmatrix}\n\\] \\[\n\\ket{-} = \\frac{1}{\\sqrt{2}}(\\ket{0}-\\ket{1}) = \\begin{bmatrix} \\frac{1}{\\sqrt{2}} \\\\ - \\frac{1}{\\sqrt{2}} \\end{bmatrix}\n\\]\n\nBardzo ważnym etapem jest wybór bazy w której dokonujemy pomiaru. np. dla wektora \\(\\ket{+}\\) pomiar w bazie standardowej pozwoli otrzymac wyniki stanu \\(\\ket{0}\\) i \\(\\ket{1}\\) z prawdopodobieństwami \\(\\frac{1}{2}\\). Natomiast jeśli pomiar dokonywany byłby w bazie Hadamarda to zawsze otrzymamy stan \\(\\ket{+}\\) z prawdopodobieństwem 1.",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Przestrzenie wektorowe, stany kwantowe, reprezentacja klasycznych i kwantowych bitów"
    ]
  },
  {
    "objectID": "lectures/wyklad3.html#kilka-ciekawostek-matematycznych",
    "href": "lectures/wyklad3.html#kilka-ciekawostek-matematycznych",
    "title": "Przestrzenie wektorowe, stany kwantowe, reprezentacja klasycznych i kwantowych bitów",
    "section": "Kilka ciekawostek matematycznych",
    "text": "Kilka ciekawostek matematycznych\nStan kubitów, czyli dwuwymiarowych układów kwantowych, opisujemy wektorem ket \\(\\ket{a}\\). Wektory te reprezentowane są jako listy zapisane w kolumnach. \\[ \\ket{a} = \\begin{bmatrix} a_0 \\\\ a_1 \\end{bmatrix} \\]\nOprócz wektorów ket wprowadziliśmy wektory bra powstające w wyniku operacji transpozycji i sprzęzenia zespolonego. Operacja ta jest bijekcją. \nPrzez bijekcję rozumiemy odwzorowanie bądź funkcję, która każdemu elementowi dziedziny przypisuje tylko jeden element przeciwdziedziny oraz dodatkowo cały zbiór dziedziny jest odwzorowany na przeciwdziedzinę. Zauważ, że druga własność jest potrzebna do zdefiniowania funkcji odwrotnej. Aby mówić o funkcji (odwrotnej), wszystkie elementy dziedziny (przeciwdziedziny) muszą zostać odwzorowane. Dzięki tej własności możemy zdefiniować całą przestrzeń dualną, w której podstawowymi składnikami są wektory dualne. Ponadto, wszystkie elementy przestrzeni wektorów bra mają swoje różne odpowiedniki w przestrzeni ketów i odwrotnie. To pozwala również stwierdzić, że tak naprawdę obie przestrzenie są izomorficzne, czyli takie same. Jedyną różnicą jest forma zapisu elementów. Operacja ta podobna jest do wpowadzenia wektorów dualnych na poziomie zakrzywionych rozmaitości rózniczkowalnych (ang. manifolds). W drugim przypadku definiujemy wektory kontrawariantne i kowariantne.\nWektory bra definiujemy jako listę wierszową. \\[ \\bra{b} = \\begin{bmatrix} a_0 \\,\\,\\,  a_1 \\end{bmatrix} \\]\nDo definicji przestrzeni wektorowej dodaliśmy definicję iloczynu skalarny. Zauważ, iz nie mówimy w tym przypadku o działaniu. Działania definiowały nam własności przestrzeni wektorowej. Wynikiem dodawania wektorów jak i mnożenia ich przez liczbę był zawsze jakiś wektor. A więc działania nie wyprowadzały nas poza przestrzeń wektorową. W przypadku iloczynu skalarnego wybieramy wektor oraz drugi wektor dualny. Po złozeniu jednego i drugiego otrzymujemy liczbę (skalar). \\[ \\braket{a}{b} \\]\nDo jego wprowadenia wymagane było wprowadzenie przestrzeni dualnej.\nKorzystając z wektorów bra i ket możemy zdefiniować jeszcze jedną operacje.\n\\[ \\ket{a} \\bra{b} \\] Tym razem to co otrzymujemy mozemy traktować jako operator.",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Przestrzenie wektorowe, stany kwantowe, reprezentacja klasycznych i kwantowych bitów"
    ]
  },
  {
    "objectID": "lectures/cw_w2.html",
    "href": "lectures/cw_w2.html",
    "title": "Modele uczenia maszynowego",
    "section": "",
    "text": "Rozwój technologii i powszechna cyfryzacja przyczyniły się do powstania nowego zasobu, jakim są dane. Dane te są generowane i przetwarzane zarówno w sposób ustrukturyzowany, jak i nieustrukturyzowany. Strukturyzacja danych doprowadziła do rozwoju wielu modeli, które dziś ogólnie określamy jako modele uczenia maszynowego (ang. machine learning, ML). Natomiast przetwarzanie danych nieustrukturyzowanych takich jak tekst, obrazy czy wideo, przyczyniło się do rozwoju uczenia głębokiego (ang. deep learning, DL). Oba te podejścia często określane zbiorczo jako sztuczna inteligencja (ang. artificial inteligence, AI), zostały stworzone głównie do rozpoznawania wzorców. Jednak coraz częściej wykorzystywane są również do modelowania i generowania nowych danych. Klasyczny model sztucznej inteligencji możemy wyrazić jako funkcję \\(f(x;\\theta)\\), która zależy zarówno od danych reprezentowanych przez ustrukturyzowaną macierz \\(x\\), jak i od parametrów \\(\\theta\\), których wartości zostają ustalone w procesie uczenia.\nW uczeniu nadzorowanym posiadamy wartości zmiennej celu dla wygenerowanych danych treningowych. Dwa podstawowe modele nadzorowanego uczenia maszynowego możemy zrealizować jako proste sieci neuronowe.\nDo wygenerowania kodów użyjemy biblioteki PyTorch",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "ćwiczenia do W2",
      "Modele uczenia maszynowego"
    ]
  },
  {
    "objectID": "lectures/cw_w2.html#regresja-liniowa",
    "href": "lectures/cw_w2.html#regresja-liniowa",
    "title": "Modele uczenia maszynowego",
    "section": "Regresja liniowa",
    "text": "Regresja liniowa\nWygenerujemy niezaszumione dane na podstawie wzoru \\(y = 2 x - 1\\). Na podstawie zbioru danych postaramy się oszacować nieznane parametry czyli wyraz przy \\(x\\) (\\(\\alpha_1 = 2\\)) i wyraz wolny (\\(\\alpha_0 = -1\\)).\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# zbior danych\nx = range(11)\ny = [2*xi - 1 for xi in x]\nplt.plot(x, y, 'go', label='True data', alpha=0.5)\n\n\n\n\n\n\n\n\nModel regresji liniowej dla jednej zmiennej można zrealizować jako prostą jednowarstwową sieć neuronową. Cały proces można zrealizować za pomocą obiektu torch.nn.Linear\n\nimport torch\n\nclass LinearRegression(torch.nn.Module):\n\n    def __init__(self, inputSize, outputSize):\n        super(LinearRegression, self).__init__()\n        self.layers = torch.nn.Sequential(\n            torch.nn.Linear(inputSize, outputSize)\n        ) \n        \n    def forward(self, x):\n        return self.layers(x)\n\nAby nasze dane mogłybyć przeliczane przez bibliotekę PyTorch musimy je przetworzyć na tensory - czyli obiekty z biblioteki PyTorch.\n\n# dostosowanie do pytorch\nx = np.array(x, dtype=np.float32)\ny = np.array(y, dtype=np.float32)\n\nX_train = torch.from_numpy(x).view(-1,1)\ny_train = torch.from_numpy(y).view(-1,1)\n\nUwaga - ponieważ mamy jedną zmienną zawierającą 10 przypadków - potrzebujemy listy składającej się z 10 list jednoelementowych.\nMożemy utworzyć model i wybrać optymalizator z funkcją kosztu.\n\n# obiekt liniowej regresji w wersji sieci nn\nlr_model = LinearRegression(1,1)\n\ncriterion = torch.nn.MSELoss()\noptimizer = torch.optim.SGD(lr_model.parameters(), lr=0.01)\n\nMożemy sprawdzić, że nasz model będzie dostrajał 2 parametry.\n\nnum_params = sum(p.numel() for p in lr_model.parameters() if p.requires_grad)\nprint(f\"liczba trenowalnych parametrów: {num_params}\")\n\nliczba trenowalnych parametrów: 2\n\n\nParametry te w początkowej inicjalizacji mają następujące wartości:\n\nfor layer in lr_model.layers:\n    if isinstance(layer, torch.nn.Linear):\n        print(f\"weight: {layer.state_dict()['weight']}\")\n        print(f\"bias: {layer.state_dict()['bias']}\")\n\nweight: tensor([[-0.1064]])\nbias: tensor([-0.0780])\n\n\n\nepochs = 400\n# petla uczaca \nfor epoch in range(epochs):\n    lr_model.train() # etap trenowania \n\n    y_pred = lr_model(X_train)\n    loss = criterion(y_pred, y_train)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n    \n    if (epoch+1) % 50 == 0:\n        print(f'epoch: {epoch+1:03d}, loss = {loss.item():.2f}')\n \n    lr_model.eval() # etap ewaluacji modelu\n\n# po treningu jeszcze raz generujemy predykcje\nlr_model.eval()\nwith torch.no_grad():\n    predicted = lr_model(X_train)\n\nepoch: 050, loss = 0.24\nepoch: 100, loss = 0.14\nepoch: 150, loss = 0.08\nepoch: 200, loss = 0.04\nepoch: 250, loss = 0.03\nepoch: 300, loss = 0.01\nepoch: 350, loss = 0.01\nepoch: 400, loss = 0.00\n\n\nOtrzymane parametry po uczeniu\n\nprint(f\"po procesie uczenia waga: {lr_model.layers[0].weight} oraz bias {lr_model.layers[0].bias}\")\n\npo procesie uczenia waga: Parameter containing:\ntensor([[1.9817]], requires_grad=True) oraz bias Parameter containing:\ntensor([-0.8730], requires_grad=True)\n\n\nDopasowanie modelu do danych można przedstawić na wykresie\n\nplt.clf()\nplt.plot(X_train, y_train, 'go', label='True data', alpha=0.5)\nplt.plot(X_train, predicted, '--', label='Predictions', alpha=0.5)\nplt.legend(loc='best')\nplt.show()",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "ćwiczenia do W2",
      "Modele uczenia maszynowego"
    ]
  },
  {
    "objectID": "lectures/cw_w2.html#regresja-logistyczna",
    "href": "lectures/cw_w2.html#regresja-logistyczna",
    "title": "Modele uczenia maszynowego",
    "section": "Regresja logistyczna",
    "text": "Regresja logistyczna\nW przypadku procesu klasyfikacji danych do numerycznego wyniku musimy dodać funkcję aktywacji - sigmoid \\(\\sigma\\), która pozwoli nam wygenerować prawdopodobieństwo otrzymania klasy 1.\nDane wygenerujemy na podstawie pakietu scikit-learn\n\nfrom sklearn.datasets import make_classification\nimport numpy as np\n\n# prepare dataset\nX, y = make_classification(n_samples=10**4, n_features=10 ,random_state=42)\n\nModel regresji logistycznej możemy zapisać jako sieć neuronowa\n\nimport torch\n\nclass LogisticRegression(torch.nn.Module):\n\n    def __init__(self, inputSize, outputSize):\n        super(LogisticRegression, self).__init__()\n        self.layers = torch.nn.Sequential(\n            torch.nn.Linear(inputSize, outputSize),\n            torch.nn.Sigmoid()\n        )\n\n    def forward(self, x):\n        logits = self.layers(x)\n        return logits\n\nPodobnie jak w przypadku regresji liniowej musimy przetworzyć nasze dane do obiektów torch.\n\nX_train = torch.from_numpy(X.astype(np.float32))\ny_train = torch.from_numpy(y.astype(np.float32))\ny_train = y_train.view(y_train.shape[0], 1)\n\n\nmodel = LogisticRegression(X_train.shape[1], y_train.shape[1])\n\nlearningRate = 0.01\ncriterion = torch.nn.BCELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n\n# petla uczaca \nnum_epochs = 500\n\nfor epoch in range(num_epochs):\n    # forward pass and loss\n    model.train()\n    y_predicted = model(X_train)\n    loss = criterion(y_predicted, y_train)\n    \n    loss.backward()\n    optimizer.step()\n    optimizer.zero_grad()\n    model.eval()\n\n    if (epoch+1) % 50 == 0:\n        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n\n\n\nmodel.eval()\nwith torch.no_grad():\n    y_predicted = model(X_train)  # no need to call model.forward()\n    y_predicted_cls = y_predicted.round()   # round off to nearest class\n    acc = y_predicted_cls.eq(y_train).sum() / float(y_train.shape[0])  # accuracy\n    print(f'accuracy = {acc:.4f}')\n    print(f\"predykcja dla wiersza 0:{y_predicted[0]}, wartosc prawdziwa: {y_train[0]}\")\n\nepoch: 50, loss = 0.5021\nepoch: 100, loss = 0.4391\nepoch: 150, loss = 0.4031\nepoch: 200, loss = 0.3801\nepoch: 250, loss = 0.3642\nepoch: 300, loss = 0.3525\nepoch: 350, loss = 0.3436\nepoch: 400, loss = 0.3365\nepoch: 450, loss = 0.3308\nepoch: 500, loss = 0.3261\naccuracy = 0.8850\npredykcja dla wiersza 0:tensor([0.8551]), wartosc prawdziwa: tensor([1.])",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "ćwiczenia do W2",
      "Modele uczenia maszynowego"
    ]
  },
  {
    "objectID": "info.html",
    "href": "info.html",
    "title": "Narzędzia",
    "section": "",
    "text": "W terminalu (Windows CMD) wpisz\npython\nJeśli nie odnaleziono komendy uruchom polecenie:\npython3\nZwróć uwagę, aby Twoja wersja nie była niższa niż 3.X Aby wyjść z powłoki pythona użyj funkcji exit()\nPython 3.10.9 (main, Dec 15 2022, 17:11:09) [Clang 14.0.0 (clang-1400.0.29.202)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; exit()\n\n\npython3 -m venv &lt;name of env&gt;\n\nsource &lt;name of env&gt;/bin/activate\n\n# Przykład\npython3 -m venv venv\nsource venv/bin/activate\n# . venv/bin/activate\n(venv) $ \nInstalacja podstawowych bibliotek i jupyterlab.\npip install --no-cache --upgrade pip setuptools\n\npip install pip install pennylane jupyter matplotlib\n# jeśli masz plik requirements.txt z potrzebnymi bibliotekami\npip install -r requirements.txt\n# uruchom \njupyterlab\nW przeglądarce internetowej wpisz: localhost:8888\nPo ponownym uruchomieniu przejdź do katalogu w którym utworzyłeś środowisko, następnie uruchom środowisko i jupyterlab.\nsource &lt;name of env&gt;/bin/activate\njupyterlab\n\n\n\nNajprostrzym sposobem korzystania z biblioteki PennyLane jest wykorzystanie środowiska Google Colab. W nowym notatniku uruchom następujący kod:\n!pip install pennylane\nAby zainstalować bibliotekę PennyLane na własnym komputerze zaleca się utworzenie nowego środowiska wirtualnego Python (Zalecam Python3.10 lub 3.11).\npython3.11 -m venv venv\nsource venv/bin/activate\n(venv) pip install pennylane jupyter matplotlib\n(venv) jupyter notebook \nRealizację instalacji na środowisku windows i Linux możesz wykonać zgodnie z~filmem.\nPolecam również zaznajomić się z podstawami biblioteki PennyLane.\n\n\n\nKurs podstaw pythona Tomas Beuzen polecam.\nUtwórz konto na Kaggle, przejdź do zakładki Courses i przerób cały moduł Pythona. Zawiera on:\n\nwyrażenia i zmienne\nfunkcje\nwarunki i flow programu\nlisty\npętle\nstringi i słowniki\ndodawanie i używanie zewnętrznych bibliotek",
    "crumbs": [
      "Sylabus",
      "Narzędzia"
    ]
  },
  {
    "objectID": "info.html#python",
    "href": "info.html#python",
    "title": "Narzędzia",
    "section": "",
    "text": "W terminalu (Windows CMD) wpisz\npython\nJeśli nie odnaleziono komendy uruchom polecenie:\npython3\nZwróć uwagę, aby Twoja wersja nie była niższa niż 3.X Aby wyjść z powłoki pythona użyj funkcji exit()\nPython 3.10.9 (main, Dec 15 2022, 17:11:09) [Clang 14.0.0 (clang-1400.0.29.202)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; exit()\n\n\npython3 -m venv &lt;name of env&gt;\n\nsource &lt;name of env&gt;/bin/activate\n\n# Przykład\npython3 -m venv venv\nsource venv/bin/activate\n# . venv/bin/activate\n(venv) $ \nInstalacja podstawowych bibliotek i jupyterlab.\npip install --no-cache --upgrade pip setuptools\n\npip install pip install pennylane jupyter matplotlib\n# jeśli masz plik requirements.txt z potrzebnymi bibliotekami\npip install -r requirements.txt\n# uruchom \njupyterlab\nW przeglądarce internetowej wpisz: localhost:8888\nPo ponownym uruchomieniu przejdź do katalogu w którym utworzyłeś środowisko, następnie uruchom środowisko i jupyterlab.\nsource &lt;name of env&gt;/bin/activate\njupyterlab\n\n\n\nNajprostrzym sposobem korzystania z biblioteki PennyLane jest wykorzystanie środowiska Google Colab. W nowym notatniku uruchom następujący kod:\n!pip install pennylane\nAby zainstalować bibliotekę PennyLane na własnym komputerze zaleca się utworzenie nowego środowiska wirtualnego Python (Zalecam Python3.10 lub 3.11).\npython3.11 -m venv venv\nsource venv/bin/activate\n(venv) pip install pennylane jupyter matplotlib\n(venv) jupyter notebook \nRealizację instalacji na środowisku windows i Linux możesz wykonać zgodnie z~filmem.\nPolecam również zaznajomić się z podstawami biblioteki PennyLane.\n\n\n\nKurs podstaw pythona Tomas Beuzen polecam.\nUtwórz konto na Kaggle, przejdź do zakładki Courses i przerób cały moduł Pythona. Zawiera on:\n\nwyrażenia i zmienne\nfunkcje\nwarunki i flow programu\nlisty\npętle\nstringi i słowniki\ndodawanie i używanie zewnętrznych bibliotek",
    "crumbs": [
      "Sylabus",
      "Narzędzia"
    ]
  },
  {
    "objectID": "info.html#zacznij-korzystać-z-serwisu-github",
    "href": "info.html#zacznij-korzystać-z-serwisu-github",
    "title": "Narzędzia",
    "section": "Zacznij korzystać z serwisu GitHub",
    "text": "Zacznij korzystać z serwisu GitHub\n\n\n\nTekst na podstawie strony jak korzystać z serwisu github\nPracując nad projektem np. praca magisterska, (samodzielnie lub w zespole) często potrzebujesz sprawdzić jakie zmiany, kiedy i przez kogo zostały wprowadzone do projektu. W zadaniu tym świetnie sprawdza się system kontroli wersji czyli GIT.\nGit możesz pobrać i zainstalować jak zwykły program na dowolnym komputerze. Jednak najczęściej (małe projekty) korzysta się z serwisów z jakimś systemem git. Jednym z najbardziej rozpoznawanych jest GitHub dzięki któremu możesz korzystać z systemu git bez jego instalacji na swoim komputerze.\nW darmowej wersji serwisu GitHub swoje pliki możesz przechowywać w publicznych (dostęp mają wszyscy) repozytoriach.\nSkupimy się wyłącznie na darmowej wersji serwisu GitHub.\ngit --version\n\nStruktura GitHuba\nNa najwyższym poziomie znajdują się konta indywidualne (np http://github.com/sebkaz, bądź zakładane przez organizacje. Użytkownicy indywidualni mogą tworzyć repozytoria publiczne (public ) bądź prywatne (private).\nJeden plik nie powinien przekraczać 100 MB.\nRepo (skrót do repozytorium) tworzymy za pomocą Create a new repository. Każde repo powinno mieć swoją indywidualną nazwę.\n\n\nBranche\nGłówna (tworzona domyślnie) gałąź rapozytorium ma nazwę master.\n\n\nNajważniejsze polecnia do zapamiętania\n\nściąganie repozytorium z sieci\n\ngit clone https://adres_repo.git\n\nW przypadku githuba możesz pobrać repozytorium jako plik zip.\n\n\nTworzenie repozytorium dla lokalnego katalogu\n\n# tworzenie nowego katalogu\nmkdir datamining\n# przejście do katalogu\ncd datamining\n# inicjalizacja repozytorium w katalogu\ngit init\n# powinien pojawić się ukryty katalog .git\n# dodajmy plik\necho \"Info \" &gt;&gt; README.md\n\nPołącz lokalne repozytorium z kontem na githubie\n\ngit remote add origin https://github.com/&lt;twojGit&gt;/nazwa.git\n\nObsługa w 3 krokach\n\n# sprawdź zmiany jakie zostały dokonane\ngit status\n# 1. dodaj wszystkie zmiany\ngit add .\n# 2. zapisz bierzący stan wraz z informacją co zrobiłeś\ngit commit -m \" opis \"\n# 3. potem już zostaje tylko\ngit push origin master\nWarto obejrzeć Youtube course.\nCiekawe i proste wprowadzenie mozna znaleźć tutaj",
    "crumbs": [
      "Sylabus",
      "Narzędzia"
    ]
  },
  {
    "objectID": "checks/cw5.html",
    "href": "checks/cw5.html",
    "title": "Parameterized Quantum Circuit",
    "section": "",
    "text": "Parametryzowane algorytmy kwantowe, czyli takie w których realizujemy obwody przez bramki parametryzowane (liczbami) są podstawowym budulcem algorytmów kwantowego uczenia maszynowego. Bardzo często mozna się spotkać z innymi nazwami: parameterized trial states, variational forms, lub ansatzes.\nPonizszy przykład przedstawia obwód z dwoma bramkami parametryzowanymi jedną liczbą \\(\\theta\\). Do oznaczenia parametru wykorzystano obiekt Parameter.\nfrom qiskit.circuit import QuantumCircuit, Parameter\n\ntheta = Parameter('angle') # niezdefiniowany parametr\n\nqc = QuantumCircuit(2)\nqc.rz(theta, 0)\nqc.crz(theta, 0, 1)\nqc.draw('mpl')\nprint(qc.parameters)\n\nParameterView([Parameter(angle)])\nJezeli chcemy zastosować wiele parametrów dla róznych bramek mozemy uzyc klasy kilku obiektów na podstawie klasy Parameters lub zastosować klasę ParameterVector.\nfrom qiskit.circuit import ParameterVector\ntheta_list = ParameterVector('theta', length=2)\n\nqc = QuantumCircuit(2)\nqc.rz(theta_list[0], 0)\nqc.crz(theta_list[1], 0, 1)\nqc.draw('mpl')\nqc.parameters\n\nParameterView([ParameterVectorElement(theta[0]), ParameterVectorElement(theta[1])])\nPoniewaz wszystkie bramki kwantowe uzywane w obwodach są unitarne, parametryzowany obwód równiez moze być opisany jako unitarna operacja wykonywana na n kubitach \\(U_{\\theta}\\) działająca na pewien stan początkowy \\(|\\phi_0\\rangle\\). \\[\n|\\psi_{\\theta}\\rangle = U_{\\theta} |\\phi_0\\rangle\n\\]\nW ogólności realizowane jest to w formie testowej sprwadz publikację.\nPrzetestujmy dwa parametryczne obwody i zobaczmy jakie mozliwosci kodowania stanów one reprezentują."
  },
  {
    "objectID": "checks/cw5.html#entangling-capability",
    "href": "checks/cw5.html#entangling-capability",
    "title": "Parameterized Quantum Circuit",
    "section": "Entangling capability",
    "text": "Entangling capability\nDrugą, wazną cechą obwodów jest mozliwosc wykorzystania splątania. Aby zmierzyć jak bardzo stany są splątane mozemy uzyć miary Meyer’a-Wallach’a. Dla stanów separowalnych miara ta przyjmuje wartość \\(0\\), natomiast dla stanów Bella \\(1\\).\n\nfrom qiskit import QuantumRegister, QuantumCircuit\nq1 = QuantumRegister(4, 'q')\nc1 = QuantumCircuit(q1)\nc1.rz(0,[0,1,2,3])\nc1.rx(0,q1)\nc1.draw('mpl')\n\n\n\n\n\n\n\n\nTen obwód nie ma operacji wprowadzających stan splątany - brak bramek dwukubitowych. Miara M-W = 0.\n\nq2 = QuantumRegister(4, 'q')\nc2 = QuantumCircuit(q1)\nc2.rz(0,[0,1,2,3])\nc2.rx(0,q1)\nc2.cx(0,1)\nc2.cx(2,3)\nc2.cx(1,2)\n\nc2.draw('mpl')\n\n\n\n\n\n\n\n\nW tym przypadku istnieją bramki dwukubitowe wprowadzające stany splątane dlatego miara M-W będzie większa od 0. Więcej info tutaj"
  },
  {
    "objectID": "checks/cw5.html#pqc-dla-ml",
    "href": "checks/cw5.html#pqc-dla-ml",
    "title": "Parameterized Quantum Circuit",
    "section": "PQC dla ML",
    "text": "PQC dla ML\nW QML parametryzowane obwody są uzywane do dwóch głównych zadań.\n\nZakodowanie klasycznych danych na układ kwantowy - dane przekładane są na parametry kątów\nJako model kwantowy gdzie parametry ustalane są z wykorzystaniem klasycznego optymalizatora\n\n\nKodowanie danych - Quantum Feature Map\nAby zrealizować modele uczenia maszynowego na klasycznych danych z wykorzystaniem PQC musimy wykonać i wybrać kilka operacji pozwalających operować na naszych danych za pomocą obwodów kwantowych.\nZadanie to często nazywane jest reprezentacją danych klasycznych w pewnej przestrzeni Hilberta, a więc moze być nazywane embeddingiem danych. Tak jak ma to miejsce dla danych grafowych czy tez w sytuacjii gdy stosujemy rózne metody zmieniające postać danych np. kernel methods w SVM.\nW przypadku obwodów kwantowych ich działanie opiera się na przetworzeniu początkowego stanu kwantowego wyrazanego jako iloczyn tensorowy kubitów. Dlatego naturalnym sposobem jest przedstawienie danych jako wektor w pewnej przestrzeni Hilberta.\nTak przygotowany i sparametryzowany stan mozna wykorzystać np w modelach typu Variational Quantum Circuit, gdzie oprócz stanu budujemy kolejny PQC, tym razem realizujący parametry naszego modelu jako parametry bramek kwantowych. Całość optymalizowana jest za pomocą róznego rodzaju optymalizatorów.\nNasze zadanie sprowadzić mozna do pobrania klasycznego punktu danych \\(\\vec{x}\\) oraz zakodowania go za pomocą bramek (parametryzowanych) w obwodzie kwantowym. \\[\nx_i \\to |\\phi(x_i)\\rangle\n\\]\nQFM (Quantum Feature Map) \\(V(\\Phi(\\vec{x}))\\) przetwarza klasyczne dane na dane kwantowe.\n\\(\\Phi(.)\\) to klasyczna funkcja zastosowana do klasycznych danych.\n\\(V\\) - to parametryzowany obwód zmieniający dane klasyczne na kwantowe.\nTrzy podstawowe czynniki związane z wyborem feature map:\n\ngłębokość obwodu - sekcja bramek kodujących moze być realizowana wiele razy (poprzez parametr reps)\nklasyczna funkcja modyfikująca i kodująca klasyczne dane nadające się do uzytku w obwodach kwantowych\nzbiór bramek kwantowych\n\n\n\nZFeatureMap\nThe first order Pauli Z-evolution circuit. Documentacja\n\\[\n\\Phi_S \\colon x \\to x_i\n\\] Otrzymany obwód nie zawiera oddziaływania między zmiennymi (zakodowanych danych), co wiąze się z brakiem wykorzystania efektu splątania.\n\nfrom qiskit.circuit.library import ZFeatureMap\n\nqc_z = ZFeatureMap(feature_dimension=3, reps=1)\nqc_z.draw('mpl')\n\n\n\n\n\n\n\n\n\nqc_z.decompose().draw('mpl')\n\n\n\n\n\n\n\n\n\n\nZZFeatureMap\nSecond-order Pauli-Z evolution circuit. Documentacja\n\nfrom qiskit.circuit.library import ZZFeatureMap\n\nqc_zz = ZZFeatureMap(feature_dimension=3, reps=1, \n                     entanglement='full',\n                     insert_barriers=True)\nqc_zz.draw('mpl')\n\n\n\n\n\n\n\n\n\nqc_zz.decompose().draw('mpl')\n\n\n\n\n\n\n\n\n\nqc_zz = ZZFeatureMap(feature_dimension=3, reps=1, entanglement='linear',insert_barriers=True)\nqc_zz.draw('mpl')\n\n\n\n\n\n\n\n\n\nqc_zz.decompose().draw('mpl')\n\n\n\n\n\n\n\n\n\n\nPauli Feature Map\nDokumentacja\n\nfrom qiskit.circuit.library import PauliFeatureMap\n\nqc_p = PauliFeatureMap(feature_dimension=3, reps=1, paulis = ['Z','ZZ','ZY'])\nqc_p.draw('mpl')\n\n\n\n\n\n\n\n\n\nqc_p.decompose().draw('mpl')\n\n\n\n\n\n\n\n\nZaobaczmy jakiemu kodowaniu odpowiada PauliFeatureMap dla operatorów Z i ZZ.\n\nqc_p = PauliFeatureMap(feature_dimension=3, reps=1, paulis = ['Z','ZZ'])\ndisplay(qc_p.draw('mpl'))\nqc_p.decompose().draw('mpl')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJeśli mamy juz określony sposób kodowania danych, komputer kwantowy moze je przeanalizować w odpowiedniej przestrzeni Hilberta i np znaleźć hiperplaszczyzne dla procesu klasyfikacji."
  },
  {
    "objectID": "checks/cw5.html#model-circuit",
    "href": "checks/cw5.html#model-circuit",
    "title": "Parameterized Quantum Circuit",
    "section": "Model Circuit",
    "text": "Model Circuit\nKolejnym elementem jest obwód realizujący model. Tutaj równiez istnieje wiele mozliwych implementacji. W ogólności tworzymy parametryzowany operator unitarny \\(U(w)\\) dla którego: \\[\n|\\psi(x:\\theta)\\rangle = U(w)|\\psi(x)\\rangle\n\\]\nJednym z przykładowych modeli w bibliotece Qiskit jest obwód realizowany jako RealAmplitudes. Ilośc parametrów modelu moze być ustalana za pomocą głębokości obwodu - czyli ile razy powtórzymy dany schemat.\n\nfrom qiskit.circuit.library import TwoLocal\n\nqc_twolocal = TwoLocal(num_qubits=3, reps=2, rotation_blocks=['ry','rz'],\n                entanglement_blocks='cz', skip_final_rotation_layer=True,\n                insert_barriers=True)\n\nqc_twolocal.decompose().draw('mpl')\n\n\n\n\n\n\n\n\n\nqc_13 = TwoLocal(3, rotation_blocks='ry',\n                 entanglement_blocks='crz', entanglement='sca',\n                 reps=3, skip_final_rotation_layer=True,\n                 insert_barriers=True)\n\nqc_13.decompose().draw('mpl')\n\n\n\n\n\n\n\n\n\nNLocal\n\nfrom qiskit import QuantumCircuit\nfrom qiskit.circuit import ParameterVector \nfrom qiskit.circuit.library import NLocal\n\n# rotation block:\nrot = QuantumCircuit(2)\nparams = ParameterVector('r', 2)\nrot.ry(params[0], 0)\nrot.rz(params[1], 1)\n\n# entanglement block:\nent = QuantumCircuit(4)\nparams = ParameterVector('e', 3)\nent.crx(params[0], 0, 1)\nent.crx(params[1], 1, 2)\nent.crx(params[2], 2, 3)\n\nqc_nlocal = NLocal(num_qubits=6, rotation_blocks=rot,\n                   entanglement_blocks=ent, entanglement='linear',\n                   skip_final_rotation_layer=True, insert_barriers=True)\n\nqc_nlocal.decompose().draw('mpl')\n\n\n\n\n\n\n\n\n\n\nOptymalizatory\nZainstaluj bibliotekę qiskit-algorithms pip install qiskit-algorithms.\nfrom qiskit-algorithms.optimizers import COBYLA\n\nCOBYLA (Constrained Optimization By Linear Approximation optimizer)\nSPSA (Simultaneous Perturbation Sochastic Approximation optimizer)\nSLSQP (Sequential Least Squares Programming optimizer)"
  },
  {
    "objectID": "checks/cw5.html#przykład-klasyfikacji-danych",
    "href": "checks/cw5.html#przykład-klasyfikacji-danych",
    "title": "Parameterized Quantum Circuit",
    "section": "Przykład Klasyfikacji danych",
    "text": "Przykład Klasyfikacji danych\n\nfrom qiskit.utils import algorithm_globals\nalgorithm_globals.random_seed = 42\n\nimport numpy as np\nnp.random.seed(algorithm_globals.random_seed)\n\n# Tworzymy zbiór danych \nfrom qiskit_machine_learning.datasets import ad_hoc_data\n\nTRAIN_DATA, TRAIN_LABELS, TEST_DATA, TEST_LABELS = (\n    ad_hoc_data(training_size=20,\n                test_size=5,\n                n=2,\n                gap=0.3,\n                one_hot=False)\n)\n\n\nlen(TRAIN_DATA), len(TRAIN_LABELS), len(TEST_DATA), len(TEST_LABELS)\n\n(40, 40, 10, 10)\n\n\n\nTRAIN_DATA[0], TRAIN_LABELS[0]\n\n(array([4.90088454, 4.1469023 ]), 0)\n\n\nDo zakodowania danych w stanie kwantowym uzyjemy: ZZFeatureMap o głębokości 2.\n\nfrom qiskit.circuit.library import ZZFeatureMap\n\nFEATURE_MAP = ZZFeatureMap(feature_dimension=2, reps=2)\n\nJako model wykorzystamy TwoLocal z bramkami ry rz i cz do splątania.\n\nfrom qiskit.circuit.library import TwoLocal\nVAR_FORM = TwoLocal(2, ['ry', 'rz'], 'cz', reps=2)\n\nAD_HOC_CIRCUIT = FEATURE_MAP.compose(VAR_FORM)\nAD_HOC_CIRCUIT.measure_all()\nAD_HOC_CIRCUIT.decompose().draw('mpl')\n\n\n\n\n\n\n\n\n\ndef circuit_instance(data, variational):\n    \"\"\"Assigns parameter values to `AD_HOC_CIRCUIT`.\n    Args:\n        data (list): Data values for the feature map\n        variational (list): Parameter values for `VAR_FORM`\n    Returns:\n        QuantumCircuit: `AD_HOC_CIRCUIT` with parameters assigned\n    \"\"\"\n    parameters = {}\n    for i, p in enumerate(FEATURE_MAP.ordered_parameters):\n        parameters[p] = data[i]\n    for i, p in enumerate(VAR_FORM.ordered_parameters):\n        parameters[p] = variational[i]\n    return AD_HOC_CIRCUIT.assign_parameters(parameters)\n\nponiewaz wynikami są bitstringi musimy podać ich interpretacje i przeliczać je na klasę rozwiązań. Jednym z przykładowych rozwiązań jest wykorzystanie funkcji parity.\n\ndef parity(bitstring):\n    \"\"\"Returns 1 if parity of `bitstring` is even, otherwise 0.\"\"\"\n    hamming_weight = sum(int(k) for k in list(bitstring))\n    return (hamming_weight+1) % 2\n\nPomocniczo zdefiniujemy funkcję obliczającą prawdopodobieństwo (częstotliwość) dla danej klasy wynikowej. Nasz obwód będzie uruchamiany wiele razy, dzięki czemu uzyskamy zliczenia w róznych eksperymentach.\n\ndef label_probability(results):\n    \"\"\"Converts a dict of bitstrings and their counts,\n    to parities and their counts\"\"\"\n    shots = sum(results.values())\n    probabilities = {0: 0, 1: 0}\n    for bitstring, counts in results.items():\n        label = parity(bitstring)\n        probabilities[label] += counts / shots\n    return probabilities\n\nPosiadając powyzsze elementy mozemy zdefiniować funkcję realizującą klasyfikację.\n\nfrom qiskit import BasicAer, execute\n\ndef classification_probability(data, variational):\n    \"\"\"Classify data points using given parameters.\n    Args:\n        data (list): Set of data points to classify\n        variational (list): Parameters for `VAR_FORM`\n    Returns:\n        list[dict]: Probability of circuit classifying\n                    each data point as 0 or 1.\n    \"\"\"\n    circuits = [circuit_instance(d, variational) for d in data]\n    backend = BasicAer.get_backend('qasm_simulator')\n    results = execute(circuits, backend).result()\n    classification = [\n        label_probability(results.get_counts(c)) for c in circuits]\n    return classification\n\nPoniewaz będziemy chcieli trenować model będziemy potrzebowali zdefiniować funkcję straty i kosztu\n\ndef cross_entropy_loss(classification, expected):\n    \"\"\"Calculate accuracy of predictions using cross entropy loss.\n    Args:\n        classification (dict): Dict where keys are possible classes,\n                               and values are the probability our\n                               circuit chooses that class.\n        expected (int): Correct classification of the data point.\n\n    Returns:\n        float: Cross entropy loss\n    \"\"\"\n    p = classification.get(expected)  # Prob. of correct classification\n    return -np.log(p + 1e-10)\n\ndef cost_function(data, labels, variational):\n    \"\"\"Evaluates performance of our circuit with `variational`\n    parameters on `data`.\n\n    Args:\n        data (list): List of data points to classify\n        labels (list): List of correct labels for each data point\n        variational (list): Parameters to use in circuit\n\n    Returns:\n        float: Cost (metric of performance)\n    \"\"\"\n    classifications = classification_probability(data, variational)\n    cost = 0\n    for i, classification in enumerate(classifications):\n        cost += cross_entropy_loss(classification, labels[i])\n    cost /= len(data)\n    return cost\n\nMozemy teraz przypisac optymalizator\n\nclass OptimizerLog:\n    \"\"\"Log to store optimizer's intermediate results\"\"\"\n    def __init__(self):\n        self.evaluations = []\n        self.parameters = []\n        self.costs = []\n    def update(self, evaluation, parameter, cost, _stepsize, _accept):\n        \"\"\"Save intermediate results. Optimizer passes five values\n        but we ignore the last two.\"\"\"\n        self.evaluations.append(evaluation)\n        self.parameters.append(parameter)\n        self.costs.append(cost)\n\n# Set up the optimization\nfrom qiskit_algorithms.optimizers  import SPSA\nlog = OptimizerLog()\noptimizer = SPSA(maxiter=100, callback=log.update)\n\nLosujemy parametry początkowe, i wskazujemy optymalizowaną funkcję\n\ninitial_point = np.random.random(VAR_FORM.num_parameters)\ndef objective_function(variational):\n    \"\"\"Cost function of circuit parameters on training data.\n    The optimizer will attempt to minimize this.\"\"\"\n    return cost_function(TRAIN_DATA, TRAIN_LABELS, variational)\n\nuruchamiamy całą procedurę\n\n# Run the optimization\nresult = optimizer.minimize(objective_function, initial_point)\n\nopt_var = result.x\nopt_value = result.fun\n\nimport matplotlib.pyplot as plt\nfig = plt.figure()\nplt.plot(log.evaluations, log.costs)\nplt.xlabel('Steps')\nplt.ylabel('Cost')\nplt.show()\n\n\n\n\n\n\n\n\nDla zbioru testowego mozemy sprawdzic jakosc przewidywań\n\ndef test_classifier(data, labels, variational):\n    \"\"\"Gets classifier's most likely predictions and accuracy of those\n    predictions.\n\n    Args:\n        data (list): List of data points to classify\n        labels (list): List of correct labels for each data point\n        variational (list): List of parameter values for classifier\n\n    Returns:\n        float: Average accuracy of classifier over `data`\n        list: Classifier's label predictions for each data point\n    \"\"\"\n    probability = classification_probability(data, variational)\n    predictions = [0 if p[0] &gt;= p[1] else 1 for p in probability]\n    accuracy = 0\n    # pylint: disable=invalid-name\n    for i, prediction in enumerate(predictions):\n        if prediction == labels[i]:\n            accuracy += 1\n    accuracy /= len(labels)\n    return accuracy, predictions\n\naccuracy, predictions = test_classifier(TEST_DATA, TEST_LABELS, opt_var)\naccuracy\n\n1.0\n\n\n\nfrom matplotlib.lines import Line2D\nplt.figure(figsize=(9, 6))\n\nfor feature, label in zip(TRAIN_DATA, TRAIN_LABELS):\n    COLOR = 'C0' if label == 0 else 'C1'\n    plt.scatter(feature[0], feature[1],\n                marker='o', s=100, color=COLOR)\n\nfor feature, label, pred in zip(TEST_DATA, TEST_LABELS, predictions):\n    COLOR = 'C0' if pred == 0 else 'C1'\n    plt.scatter(feature[0], feature[1],\n                marker='s', s=100, color=COLOR)\n    if label != pred:  # mark wrongly classified\n        plt.scatter(feature[0], feature[1], marker='o', s=500,\n                    linewidths=2.5, facecolor='none', edgecolor='C3')\n\nlegend_elements = [\n    Line2D([0], [0], marker='o', c='w', mfc='C1', label='A', ms=10),\n    Line2D([0], [0], marker='o', c='w', mfc='C0', label='B', ms=10),\n    Line2D([0], [0], marker='s', c='w', mfc='C1', label='predict A',\n           ms=10),\n    Line2D([0], [0], marker='s', c='w', mfc='C0', label='predict B',\n           ms=10),\n    Line2D([0], [0], marker='o', c='w', mfc='none', mec='C3',\n           label='wrongly classified', mew=2, ms=15)\n]\n\nplt.legend(handles=legend_elements, bbox_to_anchor=(1, 1),\n           loc='upper left')\n\nplt.title('Training & Test Data')\nplt.xlabel('x')\nplt.ylabel('y')\nplt.show()"
  },
  {
    "objectID": "checks/grover.html",
    "href": "checks/grover.html",
    "title": "Klasyfikacja z wykorzystaniem Algorytmu Grovera",
    "section": "",
    "text": "# dane testowe\n\ndef generate_data():\n    data = {'A': [(0.2, 0.5), (0.1, 0.4), (0.4, 0.8)],\n            'B': [(0.7, 0.2), (0.6, 0.3), (0.8, 0.1)]}\n    return data\n\n\ngenerate_data()\n\n\nfrom qiskit import QuantumCircuit, assemble, transpile\nfrom qiskit.visualization import plot_histogram\n\n# Tworzenie obwodu kwantowego dla algorytmu Grovera\ndef grover_circuit():\n\n    qc = QuantumCircuit(2, 2)\n\n    # Inicjalizacja superpozycji równomiernej\n    qc.h([0, 1])\n    qc.barrier()\n    # Faza odwracająca dla klasyfikacji\n    qc.cz(0, 1)\n\n    # Inwersja przez odbicie średniej\n    qc.h([0, 1])\n    qc.z([0, 1])\n    qc.cz(0, 1)\n    qc.h([0, 1])\n\n    return qc\n\nW algorytmie Grovera chodzi o przyspieszenie wyszukiwania w niesortowanym zbiorze danych przy użyciu kwantowego mechanizmu wzmacniania amplitud. W kontekście klasyfikacji, można użyć algorytmu Grovera do znalezienia punktu w przestrzeni danych, który spełnia określone warunki, co pozwoli na przypisanie go do jednej z klas.\nW przykładzie klasyfikacji z algorytmem Grovera:\n\nInicjalizacja superpozycji: Pierwszy krok to stworzenie superpozycji stanów kwantowych, co jest osiągane przez zastosowanie bramki Hadamarda (qc.h()) do wszystkich kubitów.\nFaza odwracająca: Następnie używamy bramki fazowej (w tym przypadku bramki cz) do odwrócenia fazy amplitudy stanu reprezentującego poprawne odpowiedzi.\nInwersja przez odbicie średniej: Kolejnym krokiem jest inwersja amplitudy stanu, co jest osiągane przez zastosowanie bramek Hadamarda, bramek fazowych i bramek cz.\nPomiar wyników: Na końcu dokonujemy pomiaru wszystkich kubitów, co skutkuje otrzymaniem pewnego wyniku, który odpowiada jednemu z możliwych stanów kubitów.\n\nW kontekście klasyfikacji, możemy użyć informacji z wyników pomiarów, aby przyporządkować punkt danych do jednej z klas. Na przykład, w tym przypadku, gdy wynik to ‘00’, punkt jest przypisany do klasy A, a w przeciwnym razie do klasy B.\nW implementacji, funkcja grover_circuit tworzy kwantowy obwód realizujący opisane kroki algorytmu Grovera. W funkcji classify_data, dla każdego punktu danych z danego zbioru, jest on wprowadzany do obwodu kwantowego, a wyniki pomiaru są analizowane w celu przypisania punktu do odpowiedniej klasy.\nWarto zauważyć, że implementacja jest w pełni symulacyjna, a prawdziwe korzyści z algorytmu Grovera można uzyskać na prawdziwym komputerze kwantowym, zwłaszcza w przypadku większych zbiorów danych.\n\n# Klasyfikacja danych przy użyciu algorytmu Grovera\ndef classify_data(data, quantum_circuit):\n    classified_points = {'A': [], 'B': []}\n\n    for category, points in data.items():\n        print(points)\n        for point in points:\n            print(f\"wyniki dla point:  {point}\")\n            # Przygotowanie obwodu kwantowego dla każdego punktu danych\n            qc = QuantumCircuit(2, 2)\n\n            # Wprowadzenie danych do obwodu\n            for idx, coord in enumerate(point):\n                theta = 2 * coord * 3.14159\n                print(f\"theta: {theta} dla coord: {coord}\")\n                qc.u(theta, 0, 0, idx)\n                \n            qc.compose(grover_circuit(), qubits=[0, 1], inplace=True)\n            # Pomiar wyników\n            qc.measure([0, 1], [0, 1])\n            display(qc.draw('mpl'))\n            # Symulacja obwodu\n            backend = Aer.get_backend('qasm_simulator')\n            result = backend.run(qc, shots=1000).result()\n            counts = result.get_counts(qc)\n   \n            # Klasyfikacja wyniku\n            most_frequent_result = max(counts, key=counts.get)\n            if most_frequent_result == '00':\n                classified_points[category].append(point)\n            else:\n                classified_points[category].append(point)\n\n\n    return classified_points\n\n\ndata = generate_data()\nclassified_points = classify_data(data, grover_circuit)"
  },
  {
    "objectID": "checks/cw4.html",
    "href": "checks/cw4.html",
    "title": "Algorytmy kwantowe - przegląd",
    "section": "",
    "text": "Wyobraźmy sobie, ze ktoś ukrywa dwie monety w rękach. Poniewaz kazda moneta ma dwie strony (niezalezne) dwie ręcę mogą ukryć 4 mozliwe sytuacje. Jeśli w obu rękach mamy te same strony mozemy powiedziec o stałej funkcji, która przyjmuje lewą rękę a zwraca prawą. Jeśli wynik ulega zmianie mozemy powiedziec o funkcji zbalansowanej.\nW przypadku monet, nawet jeśli odsłonimy monetę w lewej ręce nie jesteśmy w stanie stwierdzić, bez sprawdzenia, co jest w prawej ręce. A teraz wyobraź sobie 100 takich rąk. Aby mieć pewność czy masz doczynienia z funkcją stałą musisz (czy chcesz czy nie) sprawdzić wszystkie mozliwości - wystarczy jedna róznica, aby funkcja była zbalansowana.\nCo powiesz jeśli stwierdzę, ze kwantowy komputer moze rozwiązać problem otwierając wszystkie ręcę za jednym razem?\nDla funkcji boolowskiej \\(f:\\{0,1\\} \\rightarrow \\{0, 1\\}\\) mówimy, ze \\(f\\) jest zbalansowana jeśli \\(f(0) \\neq f(1)\\) lub stała jeśli \\(f(0) = f(1)\\).\n\\[\nf(0) = 0 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n\\] \\[\nf(1) = 0 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n\\] Taka funkcja moze być reprezentowana jako macierz: \\[\nf = \\begin{pmatrix} 1 \\,\\, 1 \\\\0 \\,\\, 0 \\end{pmatrix}\n\\]\nJednak, aby była uzyteczna dla obliczeń kwantowych musi być odwracalna i unitarna.\nAby sprawdzić i jednoznacznie stwierdzić czy funkcja, którą się posługujemy jest stała czy zbalansowana w klasycznym przypadku musimy sprawdzić oba wyniki \\(f(0)\\) i \\(f(1)\\).\nBardzo często tego typu modelowanie (funkcję) nazywa się black box lub oracle.\nTworzymy dwa rejestry kwantowe - input \\(|x\\rangle\\) i output \\(|y\\rangle\\)\nDefiniujemy rejestr outputu jako wynik działania XOR na rejestrze inputu: \\[\nU_f: |x\\rangle ,|y\\rangle \\to |x\\rangle, |y \\oplus f(x)\\rangle\n\\] \\[\nU^{-1}_f: |x\\rangle, |y \\oplus f(x)\\rangle \\to |x\\rangle ,|y\\rangle\n\\]\n\nfrom qiskit import QuantumCircuit\nfrom qiskit.visualization import plot_bloch_multivector\nfrom qiskit.quantum_info import Statevector\n\nKrok 1: tworzymy obwod kwantowy dla dwóch kubitów: - pierwszy w stanie 0 - drugi w stanie 1\n\n# krok 1 2 kubitowy circuit\nqc = QuantumCircuit(2,1)\nqc.i(0)\nqc.x(1)\nqc.draw(output='mpl')\n\n\n\n\n\n\n\n\nKrok 2: hadamard na oba kubity\n\n# krok 2 hadamard na oba kubity - tworzymy superpozycje aby działać na 4 stanach jednocześnie\n\nqc.h(0)\nqc.h(1)\nqc.draw(output='mpl')\n\n\n\n\n\n\n\n\n\nstate = Statevector(qc)\ndisplay(plot_bloch_multivector(state, reverse_bits=True))\n\n\n\n\n\n\n\n\n\nstate.draw('latex')\n\n\\[\\frac{1}{2} |00\\rangle+\\frac{1}{2} |01\\rangle- \\frac{1}{2} |10\\rangle- \\frac{1}{2} |11\\rangle\\]\n\n\nPo zastosowaniu bramek hadamarda, otrzymujemy: \\[\n\\frac{1}{2}(|00\\rangle + |01\\rangle - |10\\rangle - |11\\rangle)  \\,\\,\\,\\,\\,\\,\\,\\, Eq. 1\n\\]\nZauwazmy ze drugi kubit jest w stanie - (\\(H|1\\rangle\\)), mozemy zdefiniować powyzsze rownanie jako:\n\\[ \\frac{(-1)^{f(0)}|0\\rangle+(-1)^{f(1)}|1\\rangle}{\\sqrt{2}}\\cdot{\\frac{(|0\\rangle-|1\\rangle)}{\\sqrt{2}}}\\]\nJeśli \\(f\\) jest stała, wtedy \\(f(0)=0\\) i \\((-1)^0=1\\) oraz \\(f(1)=0\\)\notrzymujemy:\n\\[\\pm{\\frac{(|0\\rangle+|1\\rangle)}{\\sqrt{2}}}{\\frac{(|0\\rangle-|1\\rangle)}{\\sqrt{2}}}\\]\nW przeciwnym przypadku (\\(f\\) jest zbalansowana): \\[\\pm{\\frac{(|0\\rangle-|1\\rangle)}{\\sqrt{2}}}{\\frac{(|0\\rangle-|1\\rangle)}{\\sqrt{2}}}\\]\nDla stałej funkcji pierwszy kubit jest ustawiony jako: \\[{\\frac{(|0\\rangle+|1\\rangle)}{\\sqrt{2}}}\\] ponowne zastosowanie bramki H zwroci nam stan \\(|0\\rangle\\).\nAnalogicznie, dla zbalansowanej funkcji dostaniemy stan \\(|1\\rangle\\).\nNa podstawie tej informacji, mierząc TYLKO pierwszy kubit (po zastosowaniu bramki H) otrzymamy stan \\(|0\\rangle\\) albo \\(|1\\rangle\\) co daje jednoznaczą odpowiedź z jaką funkcją mamy do czynienia.\nNastępnym krokiem jest zastosowanie bramki działającej na dwóch kubitach. \\[\nU_f: \\ket{x} ,\\ket{y} \\to \\ket{x}, \\ket{y \\oplus f(x)}\n\\] Zakładając \\(f(x)=x\\) wyrocznię (oracle) mozna zrealizować jako bramkę CNOT.\nJeśli \\(f(x)=0\\) wyrocznią jest bramka Id.\n\nqc.cx(0,1)\nqc.draw(output='mpl')\n\n\n\n\n\n\n\n\n\nqc.h(0)\nqc.h(1)\nqc.draw(output='mpl')\n\n\n\n\n\n\n\n\n\nstate = Statevector(qc)\ndisplay(plot_bloch_multivector(state, reverse_bits=True))\n\n\n\n\n\n\n\n\n\nstate.draw('latex')\n\n\\[ |11\\rangle\\]\n\n\n\nfrom qiskit import execute, Aer\n\nqc.measure(0,0)\ndisplay(qc.draw(output='mpl'))\n\nbackend = Aer.get_backend('qasm_simulator')\nresult = execute(qc, backend, shots=1000).result()\ncounts = result.get_counts(qc)\n\n\n\n\n\n\n\n\n\nfrom qiskit.visualization import plot_histogram\ndisplay(plot_histogram(counts))\n\n\n\n\n\n\n\n\n\n\nqc2 = QuantumCircuit(2,1)\nqc2.h(0)\nqc2.x(1)\nqc2.h(0)\nqc2.h(1)\nqc2.measure(0,0)\ndisplay(qc2.draw(output='mpl'))\nbackend = Aer.get_backend('qasm_simulator')\nresult2 = execute(qc2, backend, shots=1000).result()\ncounts2 = result2.get_counts(qc2)\ndisplay(plot_histogram(counts2))"
  },
  {
    "objectID": "checks/cw4.html#deutsch-algorithm",
    "href": "checks/cw4.html#deutsch-algorithm",
    "title": "Algorytmy kwantowe - przegląd",
    "section": "",
    "text": "Wyobraźmy sobie, ze ktoś ukrywa dwie monety w rękach. Poniewaz kazda moneta ma dwie strony (niezalezne) dwie ręcę mogą ukryć 4 mozliwe sytuacje. Jeśli w obu rękach mamy te same strony mozemy powiedziec o stałej funkcji, która przyjmuje lewą rękę a zwraca prawą. Jeśli wynik ulega zmianie mozemy powiedziec o funkcji zbalansowanej.\nW przypadku monet, nawet jeśli odsłonimy monetę w lewej ręce nie jesteśmy w stanie stwierdzić, bez sprawdzenia, co jest w prawej ręce. A teraz wyobraź sobie 100 takich rąk. Aby mieć pewność czy masz doczynienia z funkcją stałą musisz (czy chcesz czy nie) sprawdzić wszystkie mozliwości - wystarczy jedna róznica, aby funkcja była zbalansowana.\nCo powiesz jeśli stwierdzę, ze kwantowy komputer moze rozwiązać problem otwierając wszystkie ręcę za jednym razem?\nDla funkcji boolowskiej \\(f:\\{0,1\\} \\rightarrow \\{0, 1\\}\\) mówimy, ze \\(f\\) jest zbalansowana jeśli \\(f(0) \\neq f(1)\\) lub stała jeśli \\(f(0) = f(1)\\).\n\\[\nf(0) = 0 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n\\] \\[\nf(1) = 0 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\n\\] Taka funkcja moze być reprezentowana jako macierz: \\[\nf = \\begin{pmatrix} 1 \\,\\, 1 \\\\0 \\,\\, 0 \\end{pmatrix}\n\\]\nJednak, aby była uzyteczna dla obliczeń kwantowych musi być odwracalna i unitarna.\nAby sprawdzić i jednoznacznie stwierdzić czy funkcja, którą się posługujemy jest stała czy zbalansowana w klasycznym przypadku musimy sprawdzić oba wyniki \\(f(0)\\) i \\(f(1)\\).\nBardzo często tego typu modelowanie (funkcję) nazywa się black box lub oracle.\nTworzymy dwa rejestry kwantowe - input \\(|x\\rangle\\) i output \\(|y\\rangle\\)\nDefiniujemy rejestr outputu jako wynik działania XOR na rejestrze inputu: \\[\nU_f: |x\\rangle ,|y\\rangle \\to |x\\rangle, |y \\oplus f(x)\\rangle\n\\] \\[\nU^{-1}_f: |x\\rangle, |y \\oplus f(x)\\rangle \\to |x\\rangle ,|y\\rangle\n\\]\n\nfrom qiskit import QuantumCircuit\nfrom qiskit.visualization import plot_bloch_multivector\nfrom qiskit.quantum_info import Statevector\n\nKrok 1: tworzymy obwod kwantowy dla dwóch kubitów: - pierwszy w stanie 0 - drugi w stanie 1\n\n# krok 1 2 kubitowy circuit\nqc = QuantumCircuit(2,1)\nqc.i(0)\nqc.x(1)\nqc.draw(output='mpl')\n\n\n\n\n\n\n\n\nKrok 2: hadamard na oba kubity\n\n# krok 2 hadamard na oba kubity - tworzymy superpozycje aby działać na 4 stanach jednocześnie\n\nqc.h(0)\nqc.h(1)\nqc.draw(output='mpl')\n\n\n\n\n\n\n\n\n\nstate = Statevector(qc)\ndisplay(plot_bloch_multivector(state, reverse_bits=True))\n\n\n\n\n\n\n\n\n\nstate.draw('latex')\n\n\\[\\frac{1}{2} |00\\rangle+\\frac{1}{2} |01\\rangle- \\frac{1}{2} |10\\rangle- \\frac{1}{2} |11\\rangle\\]\n\n\nPo zastosowaniu bramek hadamarda, otrzymujemy: \\[\n\\frac{1}{2}(|00\\rangle + |01\\rangle - |10\\rangle - |11\\rangle)  \\,\\,\\,\\,\\,\\,\\,\\, Eq. 1\n\\]\nZauwazmy ze drugi kubit jest w stanie - (\\(H|1\\rangle\\)), mozemy zdefiniować powyzsze rownanie jako:\n\\[ \\frac{(-1)^{f(0)}|0\\rangle+(-1)^{f(1)}|1\\rangle}{\\sqrt{2}}\\cdot{\\frac{(|0\\rangle-|1\\rangle)}{\\sqrt{2}}}\\]\nJeśli \\(f\\) jest stała, wtedy \\(f(0)=0\\) i \\((-1)^0=1\\) oraz \\(f(1)=0\\)\notrzymujemy:\n\\[\\pm{\\frac{(|0\\rangle+|1\\rangle)}{\\sqrt{2}}}{\\frac{(|0\\rangle-|1\\rangle)}{\\sqrt{2}}}\\]\nW przeciwnym przypadku (\\(f\\) jest zbalansowana): \\[\\pm{\\frac{(|0\\rangle-|1\\rangle)}{\\sqrt{2}}}{\\frac{(|0\\rangle-|1\\rangle)}{\\sqrt{2}}}\\]\nDla stałej funkcji pierwszy kubit jest ustawiony jako: \\[{\\frac{(|0\\rangle+|1\\rangle)}{\\sqrt{2}}}\\] ponowne zastosowanie bramki H zwroci nam stan \\(|0\\rangle\\).\nAnalogicznie, dla zbalansowanej funkcji dostaniemy stan \\(|1\\rangle\\).\nNa podstawie tej informacji, mierząc TYLKO pierwszy kubit (po zastosowaniu bramki H) otrzymamy stan \\(|0\\rangle\\) albo \\(|1\\rangle\\) co daje jednoznaczą odpowiedź z jaką funkcją mamy do czynienia.\nNastępnym krokiem jest zastosowanie bramki działającej na dwóch kubitach. \\[\nU_f: \\ket{x} ,\\ket{y} \\to \\ket{x}, \\ket{y \\oplus f(x)}\n\\] Zakładając \\(f(x)=x\\) wyrocznię (oracle) mozna zrealizować jako bramkę CNOT.\nJeśli \\(f(x)=0\\) wyrocznią jest bramka Id.\n\nqc.cx(0,1)\nqc.draw(output='mpl')\n\n\n\n\n\n\n\n\n\nqc.h(0)\nqc.h(1)\nqc.draw(output='mpl')\n\n\n\n\n\n\n\n\n\nstate = Statevector(qc)\ndisplay(plot_bloch_multivector(state, reverse_bits=True))\n\n\n\n\n\n\n\n\n\nstate.draw('latex')\n\n\\[ |11\\rangle\\]\n\n\n\nfrom qiskit import execute, Aer\n\nqc.measure(0,0)\ndisplay(qc.draw(output='mpl'))\n\nbackend = Aer.get_backend('qasm_simulator')\nresult = execute(qc, backend, shots=1000).result()\ncounts = result.get_counts(qc)\n\n\n\n\n\n\n\n\n\nfrom qiskit.visualization import plot_histogram\ndisplay(plot_histogram(counts))\n\n\n\n\n\n\n\n\n\n\nqc2 = QuantumCircuit(2,1)\nqc2.h(0)\nqc2.x(1)\nqc2.h(0)\nqc2.h(1)\nqc2.measure(0,0)\ndisplay(qc2.draw(output='mpl'))\nbackend = Aer.get_backend('qasm_simulator')\nresult2 = execute(qc2, backend, shots=1000).result()\ncounts2 = result2.get_counts(qc2)\ndisplay(plot_histogram(counts2))"
  },
  {
    "objectID": "checks/cw4.html#szyfrowanie",
    "href": "checks/cw4.html#szyfrowanie",
    "title": "Algorytmy kwantowe - przegląd",
    "section": "Szyfrowanie",
    "text": "Szyfrowanie\n\nBB84 - Kawantowa dystrybucja klucza\nKwantowa dystrybucja klucza z ang. Quantum Key Distribution – QKD.\nPytania nad którymi warto się zastanowić:\n\nJak dzielić klucz bez jego fizycznego wysyłania do odbiorcy przez sieć?\nJak zakodować tekst z uzyciem klucza (To juz znamy z XOR)?\nDlaczego QKD działa?\nJak zasymulować algorytm BB84 w qiskit?\n\nRozwazmy klasyczną Alicję i Boba, którzy chcą podzielić się poufną informacją. Zawartość przekazywanej wiadomości nie ma znaczenia.\n\n\nTworzenie klucza\nAlicja i Bob wymieniają się inforamcją o bazach i patrzą tylko na te kubity dla których pomiary wykonywane były w tej samej bazie. Prawdopodobieństwo, ze ich bazy się zgadzają wynosi 1/2.\n\nfrom qiskit import QuantumRegister, ClassicalRegister, QuantumCircuit\nq = QuantumRegister(10)\nc = ClassicalRegister(10)\n\nqc = QuantumCircuit(q,c)\nqc.h(q)\nqc.barrier()\nqc.measure(q,c)\nqc.draw('mpl')\n\n\n\n\n\n\n\n\n\njob = execute(qc, Aer.get_backend('qasm_simulator'), shots=1)\ncounts = job.result().get_counts()\ncounts\n\n{'1100001100': 1}\n\n\n\nwiadomosc = list(counts)[0]\nwiadomosc_odw = wiadomosc[::-1]\n\nMoze przekazać je bezpośrednio do Boba “kablem”. Jednak w trakcie przekazywania informacji moze przejąć ją kazdy (Eve), kto tylko podłączy się “gdzieś w środku”. Przejmie bity i ich kopię prześle do Boba.\nPoniewaz znamy juz zasady kwantowego generowania obwodów zobaczmy czy dodanie bramki hadamarda cos zmieni. Alicja po wygenerowaniu losowej informacji przetwarza kazdy pojedynczy bit bramką Hadamarda. Bob podczas odczytu korzysta z faktu, iz ponowne zastosowanie bramki Hadamarda pozwoli odzyskać zakodowany bit.\n\nfrom random import randrange\nfrom qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, execute, Aer\n\nq = QuantumRegister(10)\nc = ClassicalRegister(10)\n\nqc = QuantumCircuit(q,c)\n\nfor i, bit in enumerate(wiadomosc_odw):\n    if bit == '1':\n        qc.x(q[i])\n    else:\n        qc.id(q[i])\n\nqc.h(q)\nqc.barrier()\n\nqc.h(q)\nqc.barrier()\n\nqc.measure(q,c)\ndisplay(qc.draw('mpl'))\n\njob = execute(qc, Aer.get_backend('qasm_simulator'), shots=1)\ncounts = job.result().get_counts()\nprint(f\"Alicja: {wiadomosc}, Bob: {counts}\")\n\n\n\n\n\n\n\n\nAlicja: 1100001100, Bob: {'1100001100': 1}\n\n\nSkoro Bob w prosty sposób moze odzyskać informację Eve równiez moze zastosować analogiczny proces. Najpierw zastosuje bramkę H, odczyta informację i wygeneruje kopię informacji klasycznej przemnozoną przez bramki Hadamarda. Bob nadal odbierze prawidłową inforamcję.\nCzy istnieje jakaś mozliwosc zabezpieczenia sie przed odzyskaniem informacji przez Eve? Pokazaliśmy właśnie, ze sama bramka H nie wystarczy.\nPomysł Alicji jest następujący:\n\nZastosujmy bramki hadamarda do losowo wybranych bitów informacji.\n\nCzy widzisz analogię z losowaniem bazy ??\nPostępując w ten sposób Eve nie ma mozliwosci zdecydowac dla których bitów powinna zastosować H a dla ktorych nie. A to znaczy, ze rowniez nie ma mozliwosci wysłać skopiowanej informacji dla Boba. Stanu kubitu nie da się sklonować.\nPytanie co ma zrobić Bob. Przekazanie informacji, które bity zostały potraktowane bramką H, w sposób klasyczny nie ma sensu.\nOdpowiedzią jest schemat znany jako BB84 zaproponowany przez Chales’a Bennett’a i Gilles’a Brassard’a w 1984.\nZałózmy, ze kazdy (Alicja i Bob) mają własne generatory losowego przypisywania bramek H.\n\nq = QuantumRegister(10)\nc = ClassicalRegister(10)\n\nqc = QuantumCircuit(q,c)\n# Alicja \nfor i, bit in enumerate(wiadomosc_odw):\n    if bit == '1':\n        qc.x(q[i])\n    else:\n        qc.id(q[i])\n\nfor i in range(10):\n    if randrange(2) == 0:\n        qc.h(q[i])\n\nqc.barrier()\n# Bob\nbob_pattern = []\nfor i in range(10):\n    if randrange(2) == 0:\n        qc.h(q[i])\n        bob_pattern.append('H')\n    else:\n        bob_pattern.append('-')\nqc.barrier()\n\nqc.measure(q,c)\ndisplay(qc.draw('mpl'))\n\njob = execute(qc, Aer.get_backend('qasm_simulator'), shots=1)\ncounts = job.result().get_counts()\nprint(f\"Alicja: {wiadomosc}, Bob: {counts}\")\nprint(\"bob's hadamard pattern\",bob_pattern)\n\n\n\n\n\n\n\n\nAlicja: 1100001100, Bob: {'1100001101': 1}\nbob's hadamard pattern ['H', '-', '-', 'H', 'H', '-', 'H', 'H', '-', '-']\n\n\nJakie mozliwosci się pojawiają\n\nOboje sosują H do swoich bitów albo oboje ich nie stosują - dzięki temu Bob odzyskuje prawidłowy Bit.\nJedno stosuje a drugie nie stosuje bramki H. Tutaj niezaleznie, od opcji Bob zawsze zmierzy losowo 0 lub 1.\n\nPrawdopodobieństwo, ze oboje wybrali to samo = \\(1/2\\)\nTrochę inne podejście:\nAlicja genruje dwa losowe stringi bitowe (zawierają tylko 0 i 1). - pierwszy string koduje dwie bazy: 0 to baza obliczeniowa a 1 to baza Hadamarda. - drugi koduje stany kubitów: w bazie hadamarda 0 to stan “+” a 1 to stan “-”, w bazie obliczeniowej – wiadomo.\nAlicja przesyła do Boba 10 kubitów.\n\nfrom qiskit import QuantumCircuit, execute, Aer\nfrom qiskit.visualization import plot_histogram, plot_bloch_multivector\nfrom numpy.random import randint\nimport numpy as np\nfrom qiskit.providers.aer import QasmSimulator\n%matplotlib inline\n\n\nnum_qubits = 10 \nalice_basis = np.random.randint(2, size=num_qubits)\nalice_state = np.random.randint(2, size=num_qubits)\nbob_basis = np.random.randint(2, size=num_qubits)\n\nprint(f\"Alice's State:\\t {np.array2string(alice_state)}\")\nprint(f\"Alice's Bases:\\t {np.array2string(alice_basis)}\")\nprint(f\"Bob's Bases:\\t {np.array2string(bob_basis)}\")\n\nAlice's State:   [1 0 1 0 0 1 1 0 0 1]\nAlice's Bases:   [1 0 1 0 0 0 0 0 1 1]\nBob's Bases:     [1 0 0 1 0 1 1 1 0 1]\n\n\n\nzawsze gdy chcemy przeslac 1 w kubicie alicja aplikuje bramkę X do odpowiedniego kubitu. Dla 0 nie musi podejmować zadnego działania (lub id).\nJeśli ma zakodować coś w bazie Hadamarda uzywa bramki Hadamarda na odpowiedni kubit\nwysyła przygotowane kubity do Boba\nBob mierzy kubity zgodnie z przygotowanym przez siebie stringiem baz. Jeśli ma zmierzyć coś w bazie Hadamarda aplikuje bramkę H. Jeśli w bazie obliczeniowej nie robi niczego.\n\nfilm\n\ndef bb84_circuit(state, basis, measurement_basis):\n   \n    #state: array of 0s and 1s denoting the state to be encoded\n    #basis: array of 0s and 1s denoting the basis to be used for encoding\n                #0 -&gt; Computational Basis\n                #1 -&gt; Hadamard Basis\n    #meas_basis: array of 0s and 1s denoting the basis to be used for measurement\n                #0 -&gt; Computational Basis\n                #1 -&gt; Hadamard Basis\n    \n    num_qubits = len(state)\n    \n    circuit = QuantumCircuit(num_qubits)\n\n    # Sender prepares qubits\n    for i in range(len(basis)):\n        if state[i] == 1:\n            circuit.x(i)\n        if basis[i] == 1:\n            circuit.h(i)\n   \n\n    # Measuring action performed by Bob\n    for i in range(len(measurement_basis)):\n        if measurement_basis[i] == 1:\n            circuit.h(i)\n\n       \n    circuit.measure_all()\n    \n    return circuit\n\n\ncircuit = bb84_circuit(alice_state, alice_basis, bob_basis)\nkey = execute(circuit.reverse_bits(),backend=QasmSimulator(),shots=1).result().get_counts().most_frequent()\nencryption_key = ''\nfor i in range(num_qubits):\n    if alice_basis[i] == bob_basis[i]:\n         encryption_key += str(key[i])\nprint(f\"Key: {encryption_key}\")\n\nKey: 1001\n\n\nOther, a nice version from book\n\nimport random\nfrom qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, Aer, execute\n\nNUMBER_OF_CIRCUITS = 100\nDOES_EVE_EXIST = True\nCHECK_MARK = u'\\u2713'\n\ndef create_circuits(how_many, does_eve_exist):\n    circuits = []\n    for i in range(how_many):\n        circuits.append(make_new_circuit(does_eve_exist))\n    return circuits\n\ndef make_new_circuit(eve_exists):\n    circ = create_registers(eve_exists)\n    alice_q = circ.qubits[0]\n    bob_q = circ.qubits[1]\n    bob_c = circ.clbits[0]\n    circ = setup_alice(circ)\n    circ.swap(alice_q, bob_q)\n    if eve_exists:\n        circ = setup_eve(circ)\n    circ = setup_bob(circ)\n    return circ\n\ndef create_registers(eve_exists):\n    alice_q = QuantumRegister(1, 'alice_q')\n    bob_q = QuantumRegister(1, 'bob_q')\n    bob_c = ClassicalRegister(1, 'bob_c')\n    if eve_exists:\n        eve_c = ClassicalRegister(1, 'eve_c')\n        circ = QuantumCircuit(alice_q, bob_q, bob_c, eve_c)\n    else:\n        circ = QuantumCircuit(alice_q, bob_q, bob_c)\n    return circ\n\n\ndef setup_alice(circ):\n    alice_q = circ.qubits[0]\n    if random.getrandbits(1):\n        circ.x(alice_q)\n    if random.getrandbits(1):\n        circ.h(alice_q)\n    return circ\n\ndef setup_bob(circ):\n    bob_q = circ.qubits[1]\n    bob_c = circ.clbits[0]\n    if random.getrandbits(1):\n        circ.h(bob_q)\n    circ.measure(bob_q, bob_c)\n    return circ\n\ndef setup_eve(circ):\n    bob_q = circ.qubits[1]\n    eve_c = circ.clbits[1]\n    circ.barrier()\n    circ.measure(bob_q, eve_c)\n    circ.barrier()\n    return circ\n\ndef run_the_job(circuits):\n    device = Aer.get_backend('qasm_simulator')\n    job = execute(circuits, backend=device, shots=1, memory=True)\n    return job.result()\n\ndef print_alice_bits(circuits):\n    print('alice bits: ', end='')\n    for circ in circuits:\n        bit = 1 if 'x' in circ.count_ops() else 0\n        print(bit, end='')\n    print('')\n\ndef print_bob_bits(circuits, result):\n    print('bob bits  : ', end='')\n    for circ in circuits:\n        memory = result.get_memory(circ)\n        print(bob_bit_value(circ, memory), end='')\n    print('')\n\ndef bob_bit_value(circ, memory):\n    return memory[0][0]\n\ndef had_agreement(circ):\n    gate_counts = circ.count_ops()\n    return not ('h' in gate_counts and gate_counts['h'] == 1)\n\ndef print_had_agreements(circuits):\n    number_of_agreements = 0\n    print('hads agree? ', end='')\n    for circ in circuits:\n        if had_agreement(circ):\n            print(CHECK_MARK, end='')\n            number_of_agreements += 1\n        else:\n            print(' ', end='')\n    print('')\n    return number_of_agreements\n\ndef print_bit_agreements(circuits, result,number_of_agreements):\n    number_tested = 0\n    is_eve_detected = False\n    i = 0\n    print('bits agree? ', end='')\n    while number_tested &lt; number_of_agreements // 2:\n        if had_agreement(circuits[i]):\n            if bit_value_agreement(circuits[i], result):\n                print(CHECK_MARK, end='')\n                number_tested += 1\n            else:\n                is_eve_detected = True\n                print('X')\n                break\n        else:\n            print(' ', end='')\n        i += 1\n    print()\n    return i, is_eve_detected\n\ndef bit_value_agreement(circ, result):\n    memory = result.get_memory(circ)\n    return alice_bit_value(circ) == int(\n        bob_bit_value(circ, memory))\n\ndef alice_bit_value(circ):\n    return 1 if 'x' in circ.count_ops() else 0\n\ndef print_key(circuits, number_of_circuits, how_many_for_testing):\n    print('key      :', end='')\n    for i in range(how_many_for_testing + 1):\n        print(' ', end='')\n    for i in range(i, NUMBER_OF_CIRCUITS):\n        if had_agreement(circuits[i]):\n            print(alice_bit_value(circuits[i]), end='')\n        else:\n            print(' ', end='')\n\n\ncircuits = create_circuits(NUMBER_OF_CIRCUITS, DOES_EVE_EXIST) # 1\nresult = run_the_job(circuits) # 2\nprint_alice_bits(circuits) # 3\nprint_bob_bits(circuits, result) # 4\nnumber_of_agreements = print_had_agreements(circuits) # 5\nhow_many_for_testing, is_eve_detected = print_bit_agreements(circuits, result,number_of_agreements) # 6\nif is_eve_detected:  # 7\n    print('INTRUDER ALERT!')\nelse:\n    print_key (circuits, NUMBER_OF_CIRCUITS, how_many_for_testing)\n\nalice bits: 0101111111011100100000010011000110111101101111000111010101011011110010001001011100010001011010110000\nbob bits  : 0100110000110001000000010010001010000101111111001111110111001011101011001001011001010100001000100010\nhads agree? ✓✓✓✓ ✓✓  ✓✓  ✓ ✓✓✓✓✓ ✓✓ ✓  ✓✓   ✓✓ ✓   ✓✓✓✓ ✓   ✓✓ ✓    ✓ ✓✓ ✓✓   ✓✓✓   ✓     ✓    ✓✓  ✓✓ ✓✓✓✓  ✓ ✓✓\nbits agree? ✓✓✓X\n\nINTRUDER ALERT!"
  },
  {
    "objectID": "checks/cw4.html#kwantowa-teleportacja",
    "href": "checks/cw4.html#kwantowa-teleportacja",
    "title": "Algorytmy kwantowe - przegląd",
    "section": "Kwantowa teleportacja",
    "text": "Kwantowa teleportacja\nQuantum teleportation czyli kwantowa teleportacja to technika przekazu informacji (kwantowej) między wysyłającym i odbierającym. Jak poprzednio mozemy przyjąć, ze Alicja wysyła wiadomość do Boba. Informacja, którą chce przesłać Alicja to stan \\(|\\psi\\rangle=\\alpha |0\\rangle +\\beta |1\\rangle\\).\nZgodnie z twierdzeniem o zakazie klonowania, nie mozna wykonac dokładnej kopii dowolnego stanu kwantowego. Oznacza to, ze Alicja nie moze przygotować swojego stanu i go sklonować w celu wysłania go do Boba.\nUzyjemy dwóch klasycznych bitów informacji oraz splątanej pary kubitów. Ponadto trzeba pamiętać, ze w chwili kiedy Alicja wysyła swój Kubit niszczy jego stan u siebie.\n\nThe Quantum Teleportation Protocol\n\nimport numpy as np\nimport random\nfrom qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, execute, Aer\nfrom qiskit.result import marginal_counts\n\nPotrzebujemy obwodu składającego się z 3 kubitów: 1. qubit Alicji 2. qubit splatany 1 (Eva-Alicja) 3. qubit splatany 2 (Eva-Bob)\ni 3 klasycznych rejestrów.\n\ndef create_registers():\n    alice_q = QuantumRegister(1, 'alice (q)')\n    eva_alice_q = QuantumRegister(1, 'eva/alice (q)')\n    eva_bob_q = QuantumRegister(1, 'eva/bob (q)')\n    bob_c = ClassicalRegister(3, 'bob (c)')\n    return QuantumCircuit(alice_q, eva_alice_q, eva_bob_q, bob_c)\n\n\nqc = create_registers()\nqc.draw('mpl')\n\n\n\n\n\n\n\n\nPrzygotujmy losowy stan Alicji, który prześlemy\n\ndef generate_amplitudes():\n    alpha = np.sqrt(random.uniform(0,1))\n    beta = np.sqrt(1 - alpha**2)\n    return alpha, beta\n\ngenerate_amplitudes()\n\n(0.5455988535218319, 0.8380464730763221)\n\n\nDodajemy bramki\n\ndef add_gates(circ, alpha, beta):\n    # stan alicji q0\n    circ.initialize([alpha, beta], 0)\n    circ.barrier()\n    # stan splątany q1 i q2\n    circ.h(1)\n    circ.cnot(1,2)\n    circ.barrier()\n    #  alicja stosuje bramki łacząc swoj kubit i otrzymany kubit od evy\n    circ.cnot(0,1)\n    circ.h(0)\n    circ.barrier()\n    # alicja mierzy kubity i przesyla info do Boba\n    circ.measure(0,0)\n    circ.measure(1,1)\n    # realizacja boba\n    with circ.if_test((1, 1)):\n        circ.x(2)\n    with circ.if_test((0, 1)):\n        circ.z(2)\n    circ.measure(2, 2)\n    return circ\n\n\nalpha, beta = generate_amplitudes()\nprint(f'alpha = {alpha:.4f},  beta = {beta:.4f}')\ncirc = create_registers()\ncirc = add_gates(circ, alpha, beta)\ndisplay(circ.draw('mpl', cregbundle=False))\n\nalpha = 0.7765,  beta = 0.6301\n\n\n\n\n\n\n\n\n\n\ndevice = Aer.get_backend(\"qasm_simulator\")\nshots = 1000\njob = device.run(circ, shots=shots)\nresult = job.result()\ncounts = result.get_counts(circ)\ncounts_m = marginal_counts(counts, [2])\nnumber_of_0s = counts_m.get('0')\nnumber_of_1s = counts_m.get('1')\nalpha = np.sqrt(number_of_0s / shots)\nbeta = np.sqrt(number_of_1s / shots)\nprint(\"stan =  ({:.4f}, {:.4f})\".format(alpha, beta))\n\nstan =  (0.7880, 0.6156)\n\n\nStep 4: Bob dekoder\nBob, który posiada kubit 3 q2 (wcześniej splątany) stosuje następujące bramki w zaleznosci od klasycznej informacji, którą orzymał:\n\\[00 \\to Identity \\]\n\\[01 \\to Apply 𝑋 gate \\]\n\\[ 10 \\to Apply Z gate \\]\n\\[ 11 \\to Apply 𝑍𝑋 gate \\]"
  },
  {
    "objectID": "checks/cw4.html#shor",
    "href": "checks/cw4.html#shor",
    "title": "Algorytmy kwantowe - przegląd",
    "section": "Shor",
    "text": "Shor\n\n\ndef initialize_qubits(given_circuit, n, m):\n\n    given_circuit.h(range(n))\n    given_circuit.x(n+m-1)\n\nfrom qiskit import QuantumCircuit\n\ndef c_amod15(a, x):\n    if a not in [2,7,8,11,13]:\n        raise ValueError(\"'a' must be 2,7,8,11,13\")\n    U = QuantumCircuit(4)        \n    for iteration in range(x):\n        if a in [2,13]:\n            U.swap(0,1)\n            U.swap(1,2)\n            U.swap(2,3)\n        if a in [7,8]:\n            U.swap(2,3)\n            U.swap(1,2)\n            U.swap(0,1)\n        if a == 11:\n            U.swap(1,3)\n            U.swap(0,2)\n        if a in [7,11,13]:\n            for q in range(4):\n                U.x(q)\n    U = U.to_gate()\n    U.name = \"%i^%i mod 15\" % (a, x)\n    c_U = U.control()\n    return c_U\n\ndef modular_exponentiation(circuit, n, m, a):\n    for x in range(n):\n        exponent = 2**x\n        circuit.append(c_amod15(a, exponent), [x] + list(range(n, n+m)))\n\nfrom qiskit.circuit.library import QFT\n\ndef inverse_qft(circuit, measurement_qubits):\n    circuit.append(QFT( len(measurement_qubits), do_swaps=False).inverse(), measurement_qubits)\n\ndef shors_algorithm(n, m, a):\n    qc = QuantumCircuit(n+m, n)\n    initialize_qubits(qc, n, m)\n    qc.barrier()\n    modular_exponentiation(qc, n, m, a)\n    qc.barrier()\n    inverse_qft(qc, range(n))\n    qc.measure(range(n), range(n))\n    return qc\n    \nn = 4; m = 4; a = 7\nfinal_circuit = shors_algorithm(n, m, a)\nfinal_circuit.draw('mpl')\n\n\n\n\n\n\n\n\n\nsimulator = Aer.get_backend('qasm_simulator')\ncounts = execute(final_circuit, backend=simulator, shots=1000).result().get_counts(final_circuit)\n\n\nfor measured_value in counts:\n    print(f\"{int(measured_value[::-1], 2)}\")\n\n9\n14\n10\n15\n11\n13\n6\n12\n8\n7\n0\n4\n5\n\n\n\nfrom math import gcd\nfor i in counts:\n    measured_value = int(i[::-1], 2)\n    if measured_value % 2 != 0:\n        print(\"Measured value not even\")\n        continue #measured value should be even as we are doing a^(r/2) mod N and r/2 should be int\n    x = int((a ** (measured_value/2)) % 15)\n    if (x + 1) % 15 == 0:\n        continue\n    factors = gcd(x + 1, 15), gcd(x - 1, 15) #we saw earlier that a^(r/2)+1 or a^(r/2)-1 should be a factor of 15\n    print(factors)\n\nMeasured value not even\n(1, 3)\n(1, 3)\nMeasured value not even\nMeasured value not even\nMeasured value not even\n(1, 3)\n(5, 3)\n(1, 15)\nMeasured value not even\n(1, 15)\n(5, 3)\nMeasured value not even"
  },
  {
    "objectID": "checks/qaoa.html",
    "href": "checks/qaoa.html",
    "title": "QUBO",
    "section": "",
    "text": "Bramki kwantowe realizowane są w modelu bramkowym przez operatory unitarne reprezentowane przez macierze.\n\\[\nU U^{\\dagger} = U^{\\dagger} U = I\n\\]\nKazda macierz unitarna moze być przedstawiona jako:\n\\[\nU(H,t) = e^{-i H t}\n\\] gdzie \\(H\\) to macierz Hermitowska (\\(H=H^{\\dagger}\\))\nW ogólności, implementacja obwodu kwantowego, który dokładnie realizuje macierz unitarną dla zadanego Hamiltonianiu jest bardzo trudnym zadaniem. Hamiltonian taki zazwyczaj składa się z sumy wielu niekomutujących części.\n\\[\nH = H_1 + H_2 + \\dots + H_n\n\\]\nMozemy wykorzystać wzór Trotter'a-Suzuki który przybliza dowolną sumę macierzy \\[\ne^{A + B} \\approx \\left( e^{A/n} e^{B/n} \\right)^n\n\\]\ndlatego dla \\(H=\\sum_k H_k\\) otrzymujemy \\[ U(H,t,n) = \\prod_{j=1}^n \\prod_k e^{-i H_k t/n} \\]\n\nQUBO\nKombinatoryczne problemy opytmalizacyjne realizowane są na wielu płaszczyznach naukowych i aplikacyjnych:\n\nlogistyka,\nplanowanie,\noptymalizacja portfolio,\n…\n\nCombinatorial optimization problems are problems involving a large number of yes/no decisions with each set of decisions yielding a corresponding objective function value, like a cost or profit value.\nBecause of the combinatorial explosion of the solution space with the number of variables, finding good solutions is extremely difficult.\nThe QUBO model unifies a rich variety of NP-hard combinatorial optimization problems:\n\nQuadratic Assignment Problems\nCapital Budgeting Problems\nTask allocation Problems\nMaximum–Cut Problems\n\nQUBO objective function:\n\\[\nF(q) = \\sum_a v_a q_a + \\sum_{a &lt; b} \\omega_{a b} q_a q_b\n\\] gdzie \\(q_a \\in \\{0,1\\}\\), \\(v_a\\) oraz \\(\\omega_a\\) to rzeczywiste współczynniki dla liniowej i kwadratowej części.\nThe QUBO objective function is NP-hard in nature.\nWprowadzmy zamianę zmiennych: \\[\nz_a = 2q_a-1\n\\] gdzie \\(z \\in {-1,1}\\)\n\\[\nF(z) = \\sum_a h_a z_a + \\sum_{a &lt; b} J_{a b} z_a z_b\n\\]\nOne popular method of encoding an optimization problem to be solved using QAOA, is to first formulate the problem as an Ising Objective function. The Ising model is a popular statistical mechanics model, associated primarily with ferromagnetism. Because it has been shown to be NP-Complete in nature, the objective function associated with it can be used to represent hard problems.\n\nMax-Cut\nMax-Cut is an NP-complete problem, with applications in clustering, network science, and statistical physics.\nGiven a graph \\(G(V,E)\\), we seek partition of \\(V\\) into two subsets with maximum cut.\nIn short, we have to color every node either blue or red and we score a point whenever an edge connects two nodes with different colors. We then would like to find the solution with the highest score.\n\nAgain, the problem in this specific graph coloring problem is that there are \\(2^N\\) possible solutions for \\(N\\) nodes (an exponential explosion in possibilities), making it impossible to enumerate all possible candidates for relevant system sizes.\nThe solution of Max-Cut, even if approximate, has practical application in machine scheduling, image recognition or for the layout of electronic circuits.\nWe can encode the Maximum Cut problem as a minimization problem of an Ising Hamiltonian, where the (classical) cost function reads: \\[ H_C = \\sum_{a &lt; b} J_{a b} z_a z_b \\]\nIsing matrix \\(J\\) encoding the weights of the edges.\nIn short, the cost Hamiltonian assigns a number to every bitstring \\(z=(z_1,z_2,\\dots,z_n)\\) , and we would like to find the lowest number possible. This will be the optimal assignment and solution to our problem.\nIt is important to note here that we still don’t know if quantum computing can help solve NP-Complete problems efficiently. Our hope for quantum algorithms, at the very least, is to be able to compete with classical heuristics when it comes to certain classes of hard problems.\nThe quantum Ising Hamiltonian, which naturally maps the Ising objective to qubits:\n\\[\\hat{C} = \\sum_{a &lt; b} J_{a b} \\hat{\\sigma}_a^z \\hat{\\sigma}_b^z \\] which can be written as a matrix of size \\((2^N, 2^N)\\) with diagonal elements only corresponding to all possible classical values for the cost function \\(\\hat{C}\\).\nBecause qubits are 2-dim vectors \\(\\sigma_a^z\\) correspond to 2x2 matrix with two eigenvalue \\(\\{1,-1\\}\\) and two eigenvectors \\[|0&gt; = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\\] \\[|1&gt; = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\\]\nSo\n\\[ \\sigma^z = \\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}\\]\nand\n\\[ \\sigma^z_a = \\left( \\otimes_{i=1}^{a-1} I \\right) \\otimes \\left( \\sigma^z \\right) \\otimes \\left(\\otimes_{i=a+1}^{n} I \\right)\\]\nThe other type of Hamiltonian in the QAOA process is a summation of individual Pauli X operators for each qubit involved in the process, which intuitively represents \\[\\hat{B}=\\sum_a \\sigma^x_a\\] transverse field in the Ising model \\[ \\sigma^x = \\begin{pmatrix} 0 & 1 \\\\ 1 & 0 \\end{pmatrix}\\]\n\\[ \\sigma^x_a = \\left( \\otimes_{i=1}^{a-1} I \\right) \\otimes \\left( \\sigma^x \\right) \\otimes \\left(\\otimes_{i=a+1}^{n} I \\right)\\]\nThe ground state of this Hamiltonian corresponds to the optimal solution of the classical combinatorial problem.\nFinding this ground state is generically hard.\n\n\nRealizacja kodu w pythonie\nFunctional programming breaks down an application into a set of functions. Ideally, functions only take inputs and produce outputs and have no internal state that affects the output produced for a given input.\nIn that sense, the QAOA algorithm is a function that solves a problem by optimizeing a set of params. In other words, we aim to find the best values for these params.\nTo decide which params are best, we assess them based on the result we obtain from computeing a (quantum) circuit that uses these params to encode the problem (problem_circuit) and its solution (ansatz_circuit).\nThis is what Qiskit’s description refers to as a variational algorithm.\nIt uses a classical optimization algorithm that makes queries to a quantum computer.\n\ndef qaoa(problem, optimize, assess, compute,\n  to_circuit, problem_circuit, ansatz_circuit):\n\n    return optimize(\n        lambda params: assess(problem, compute(to_circuit(problem, params,\n              problem_circuit, ansatz_circuit)))\n    )\n\n\nfrom qiskit import Aer, execute\n\ndef compute(circuit):\n    return execute(circuit, \n                   Aer.get_backend('qasm_simulator'), \n                   shots=1000).result().get_counts()\n\n\nfrom qiskit import QuantumCircuit\n\ndef to_circuit(problem, params, problem_circuit, ansatz_circuit):\n    \n    cnt_qubits = problem.size\n    \n    qc_qaoa = QuantumCircuit(cnt_qubits)\n\n    # initial_state\n    qc_qaoa.h(range(cnt_qubits))\n    \n    # append problem circuit\n    qc_qaoa.append(problem_circuit(problem, params[0]), range(cnt_qubits))\n    \n    # append ansatz circuit\n    qc_qaoa.append(ansatz_circuit(problem, params[1]), range(cnt_qubits))\n    qc_qaoa.measure_all()\n    \n    return qc_qaoa"
  },
  {
    "objectID": "checks/other/pennylane.html",
    "href": "checks/other/pennylane.html",
    "title": "Pennylane",
    "section": "",
    "text": "Codebook\nPennyLane Challenges"
  },
  {
    "objectID": "checks/QGAN.html",
    "href": "checks/QGAN.html",
    "title": "Quantum Generative Adversarial Networks",
    "section": "",
    "text": "Based on A Basic Introduction to Quantum GAN’s - Javier Marin (Maedium Article)\nhttps://pennylane.ai/qml/demos/tutorial_quantum_gans\nQuantum computing , just becomes vastly simpler once you take the physics out of it.\nQuantum circuit that are like recipes or instruction manuals for quantum computer.\nTabular Quantum GAN - on quantum circuit"
  },
  {
    "objectID": "checks/QGAN.html#obrazy",
    "href": "checks/QGAN.html#obrazy",
    "title": "Quantum Generative Adversarial Networks",
    "section": "Obrazy",
    "text": "Obrazy\n\nimport math\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\nimport pennylane as qml\n\n# Pytorch imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\n\n# Set the random seed for reproducibility\nseed = 42\ntorch.manual_seed(seed)\nnp.random.seed(seed)\nrandom.seed(seed)\n\n\nclass DigitsDataset(Dataset):\n    \"\"\"Pytorch dataloader for the Optical Recognition of Handwritten Digits Data Set\"\"\"\n\n    def __init__(self, csv_file, label=0, transform=None):\n        \"\"\"\n        Args:\n            csv_file (string): Path to the csv file with annotations.\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied\n                on a sample.\n        \"\"\"\n        self.csv_file = csv_file\n        self.transform = transform\n        self.df = self.filter_by_label(label)\n\n    def filter_by_label(self, label):\n        # Use pandas to return a dataframe of only zeros\n        df = pd.read_csv(self.csv_file)\n        df = df.loc[df.iloc[:, -1] == label]\n        return df\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n\n        image = self.df.iloc[idx, :-1] / 16\n        image = np.array(image)\n        image = image.astype(np.float32).reshape(8, 8)\n\n        if self.transform:\n            image = self.transform(image)\n\n        # Return image and label\n        return image, 0\n\n\nimage_size = 8  # Height / width of the square images\nbatch_size = 1\n\ntransform = transforms.Compose([transforms.ToTensor()])\ndataset = DigitsDataset(csv_file=\"optdigits.tra\", transform=transform)\ndataloader = torch.utils.data.DataLoader(\n    dataset, batch_size=batch_size, shuffle=True, drop_last=True\n)\n\n\nplt.figure(figsize=(8,2))\n\nfor i in range(8):\n    image = dataset[i][0].reshape(image_size,image_size)\n    plt.subplot(1,8,i+1)\n    plt.axis('off')\n    plt.imshow(image.numpy(), cmap='gray')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nclass Discriminator(nn.Module):\n    \"\"\"Fully connected classical discriminator\"\"\"\n\n    def __init__(self):\n        super().__init__()\n\n        self.model = nn.Sequential(\n            # Inputs to first hidden layer (num_input_features -&gt; 64)\n            nn.Linear(image_size * image_size, 64),\n            nn.ReLU(),\n            # First hidden layer (64 -&gt; 16)\n            nn.Linear(64, 16),\n            nn.ReLU(),\n            # Second hidden layer (16 -&gt; output)\n            nn.Linear(16, 1),\n            nn.Sigmoid(),\n        )\n\n    def forward(self, x):\n        return self.model(x)\n\n\n# Quantum variables\nn_qubits = 5  # Total number of qubits / N\nn_a_qubits = 1  # Number of ancillary qubits / N_A\nq_depth = 6  # Depth of the parameterised quantum circuit / D\nn_generators = 4  # Number of subgenerators for the patch method / N_G\n\n\n# Quantum simulator\ndev = qml.device(\"default.qubit\", wires=n_qubits)\n# Enable CUDA device if available\n#device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\ndevice = \"cpu\"\n\n\ndevice\n\n'cpu'\n\n\n\n@qml.qnode(dev, diff_method=\"parameter-shift\")\ndef quantum_circuit(noise, weights):\n\n    weights = weights.reshape(q_depth, n_qubits)\n\n    # Initialise latent vectors\n    for i in range(n_qubits):\n        qml.RY(noise[i], wires=i)\n\n    # Repeated layer\n    for i in range(q_depth):\n        # Parameterised layer\n        for y in range(n_qubits):\n            qml.RY(weights[i][y], wires=y)\n\n        # Control Z gates\n        for y in range(n_qubits - 1):\n            qml.CZ(wires=[y, y + 1])\n\n    return qml.probs(wires=list(range(n_qubits)))\n\n\ndef partial_measure(noise, weights):\n    # Non-linear Transform\n    probs = quantum_circuit(noise, weights)\n    probsgiven0 = probs[: (2 ** (n_qubits - n_a_qubits))]\n    probsgiven0 /= torch.sum(probs)\n\n    # Post-Processing\n    probsgiven = probsgiven0 / torch.max(probsgiven0)\n    return probsgiven\n\n\nclass PatchQuantumGenerator(nn.Module):\n    \"\"\"Quantum generator class for the patch method\"\"\"\n\n    def __init__(self, n_generators, q_delta=1):\n        \"\"\"\n        Args:\n            n_generators (int): Number of sub-generators to be used in the patch method.\n            q_delta (float, optional): Spread of the random distribution for parameter initialisation.\n        \"\"\"\n\n        super().__init__()\n\n        self.q_params = nn.ParameterList(\n            [\n                nn.Parameter(q_delta * torch.rand(q_depth * n_qubits), requires_grad=True)\n                for _ in range(n_generators)\n            ]\n        )\n        self.n_generators = n_generators\n\n    def forward(self, x):\n        # Size of each sub-generator output\n        patch_size = 2 ** (n_qubits - n_a_qubits)\n\n        # Create a Tensor to 'catch' a batch of images from the for loop. x.size(0) is the batch size.\n        images = torch.Tensor(x.size(0), 0).to(device)\n\n        # Iterate over all sub-generators\n        for params in self.q_params:\n\n            # Create a Tensor to 'catch' a batch of the patches from a single sub-generator\n            patches = torch.Tensor(0, patch_size).to(device)\n            for elem in x:\n                q_out = partial_measure(elem, params).float().unsqueeze(0)\n                patches = torch.cat((patches, q_out))\n\n            # Each batch of patches is concatenated with each other to create a batch of images\n            images = torch.cat((images, patches), 1)\n\n        return images\n\n\nlrG = 0.3  # Learning rate for the generator\nlrD = 0.01  # Learning rate for the discriminator\nnum_iter = 500  # Number of training iterations\n\n\ndiscriminator = Discriminator().to(device)\ngenerator = PatchQuantumGenerator(n_generators).to(device)\n\n# Binary cross entropy\ncriterion = nn.BCELoss()\n\n# Optimisers\noptD = optim.SGD(discriminator.parameters(), lr=lrD)\noptG = optim.SGD(generator.parameters(), lr=lrG)\n\nreal_labels = torch.full((batch_size,), 1.0, dtype=torch.float, device=device)\nfake_labels = torch.full((batch_size,), 0.0, dtype=torch.float, device=device)\n\n# Fixed noise allows us to visually track the generated images throughout training\nfixed_noise = torch.rand(8, n_qubits, device=device) * math.pi / 2\n\n# Iteration counter\ncounter = 0\n\n# Collect images for plotting later\nresults = []\n\nwhile True:\n    for i, (data, _) in enumerate(dataloader):\n\n        # Data for training the discriminator\n        data = data.reshape(-1, image_size * image_size)\n        real_data = data.to(device)\n\n        # Noise follwing a uniform distribution in range [0,pi/2)\n        noise = torch.rand(batch_size, n_qubits, device=device) * math.pi / 2\n        fake_data = generator(noise)\n\n        # Training the discriminator\n        discriminator.zero_grad()\n        outD_real = discriminator(real_data).view(-1)\n        outD_fake = discriminator(fake_data.detach()).view(-1)\n\n        errD_real = criterion(outD_real, real_labels)\n        errD_fake = criterion(outD_fake, fake_labels)\n        # Propagate gradients\n        errD_real.backward()\n        errD_fake.backward()\n\n        errD = errD_real + errD_fake\n        optD.step()\n\n        # Training the generator\n        generator.zero_grad()\n        outD_fake = discriminator(fake_data).view(-1)\n        errG = criterion(outD_fake, real_labels)\n        errG.backward()\n        optG.step()\n\n        counter += 1\n\n        # Show loss values\n        if counter % 10 == 0:\n            print(f'Iteration: {counter}, Discriminator Loss: {errD:0.3f}, Generator Loss: {errG:0.3f}')\n            test_images = generator(fixed_noise).view(8,1,image_size,image_size).cpu().detach()\n\n            # Save images every 50 iterations\n            if counter % 50 == 0:\n                results.append(test_images)\n\n        if counter == num_iter:\n            break\n    if counter == num_iter:\n        break\n\nIteration: 10, Discriminator Loss: 1.329, Generator Loss: 0.811\nIteration: 20, Discriminator Loss: 1.331, Generator Loss: 0.809\nIteration: 30, Discriminator Loss: 1.296, Generator Loss: 0.814\nIteration: 40, Discriminator Loss: 1.276, Generator Loss: 0.789\nIteration: 50, Discriminator Loss: 1.248, Generator Loss: 0.806\nIteration: 60, Discriminator Loss: 1.270, Generator Loss: 0.754\nIteration: 70, Discriminator Loss: 1.239, Generator Loss: 0.729\nIteration: 80, Discriminator Loss: 1.306, Generator Loss: 0.694\nIteration: 90, Discriminator Loss: 1.271, Generator Loss: 0.712\nIteration: 100, Discriminator Loss: 1.316, Generator Loss: 0.641\nIteration: 110, Discriminator Loss: 1.224, Generator Loss: 0.654\nIteration: 120, Discriminator Loss: 1.271, Generator Loss: 0.680\nIteration: 130, Discriminator Loss: 1.229, Generator Loss: 0.678\nIteration: 140, Discriminator Loss: 1.235, Generator Loss: 0.692\nIteration: 150, Discriminator Loss: 1.176, Generator Loss: 0.702\nIteration: 160, Discriminator Loss: 1.299, Generator Loss: 0.659\nIteration: 170, Discriminator Loss: 1.241, Generator Loss: 0.663\nIteration: 180, Discriminator Loss: 1.211, Generator Loss: 0.671\nIteration: 190, Discriminator Loss: 1.301, Generator Loss: 0.708\nIteration: 200, Discriminator Loss: 1.275, Generator Loss: 0.606\nIteration: 210, Discriminator Loss: 1.237, Generator Loss: 0.644\nIteration: 220, Discriminator Loss: 1.216, Generator Loss: 0.764\nIteration: 230, Discriminator Loss: 1.182, Generator Loss: 0.697\nIteration: 240, Discriminator Loss: 1.344, Generator Loss: 0.610\nIteration: 250, Discriminator Loss: 1.158, Generator Loss: 0.721\nIteration: 260, Discriminator Loss: 1.320, Generator Loss: 0.669\nIteration: 270, Discriminator Loss: 1.276, Generator Loss: 0.662\nIteration: 280, Discriminator Loss: 1.324, Generator Loss: 0.643\nIteration: 290, Discriminator Loss: 1.334, Generator Loss: 0.642\nIteration: 300, Discriminator Loss: 1.153, Generator Loss: 0.718\nIteration: 310, Discriminator Loss: 1.175, Generator Loss: 0.706\nIteration: 320, Discriminator Loss: 1.337, Generator Loss: 0.639\nIteration: 330, Discriminator Loss: 1.227, Generator Loss: 0.757\nIteration: 340, Discriminator Loss: 1.059, Generator Loss: 0.797\nIteration: 350, Discriminator Loss: 1.050, Generator Loss: 0.807\nIteration: 360, Discriminator Loss: 1.078, Generator Loss: 0.782\nIteration: 370, Discriminator Loss: 1.268, Generator Loss: 0.658\nIteration: 380, Discriminator Loss: 1.248, Generator Loss: 0.632\nIteration: 390, Discriminator Loss: 1.080, Generator Loss: 0.871\nIteration: 400, Discriminator Loss: 1.216, Generator Loss: 0.636\nIteration: 410, Discriminator Loss: 1.019, Generator Loss: 0.818\nIteration: 420, Discriminator Loss: 1.238, Generator Loss: 0.595\nIteration: 430, Discriminator Loss: 1.219, Generator Loss: 0.695\nIteration: 440, Discriminator Loss: 1.156, Generator Loss: 0.877\nIteration: 450, Discriminator Loss: 0.870, Generator Loss: 0.926\nIteration: 460, Discriminator Loss: 1.082, Generator Loss: 0.795\nIteration: 470, Discriminator Loss: 0.966, Generator Loss: 0.745\nIteration: 480, Discriminator Loss: 1.078, Generator Loss: 0.814\nIteration: 490, Discriminator Loss: 0.992, Generator Loss: 0.790\nIteration: 500, Discriminator Loss: 1.291, Generator Loss: 0.703\n\n\n\nfig = plt.figure(figsize=(10, 5))\nouter = gridspec.GridSpec(5, 2, wspace=0.1)\n\nfor i, images in enumerate(results):\n    inner = gridspec.GridSpecFromSubplotSpec(1, images.size(0),\n                    subplot_spec=outer[i])\n\n    images = torch.squeeze(images, dim=1)\n    for j, im in enumerate(images):\n\n        ax = plt.Subplot(fig, inner[j])\n        ax.imshow(im.numpy(), cmap=\"gray\")\n        ax.set_xticks([])\n        ax.set_yticks([])\n        if j==0:\n            ax.set_title(f'Iteration {50+i*50}', loc='left')\n        fig.add_subplot(ax)\n\nplt.show()"
  },
  {
    "objectID": "checks/QGAN.html#dane-tabelaryczne",
    "href": "checks/QGAN.html#dane-tabelaryczne",
    "title": "Quantum Generative Adversarial Networks",
    "section": "dane tabelaryczne",
    "text": "dane tabelaryczne\n\nimport pennylane as qml\n\n# Quantum variables\nn_qubits = 5  # Total number of qubits / N\nn_a_qubits = 1  # Number of ancillary qubits / N_A\nq_depth = 6  # Depth of the parameterised quantum circuit / D\nn_generators = 4  # Number of subgenerators for the patch method / N_G\n\ndev = qml.device('default.qubit', wires=n_qubits)\n\n@qml.qnode(dev, diff_method=\"parameter-shift\")\ndef qc(noise, weight):\n    weights = weights.reshape(q_depth, n_qubits)\n\n    for i in range(n_qubits):\n        qml.RY(noise[i], wires=i)\n\n    for i in range(q_depth):\n        for y in range(n_qubits):\n            qml.RY(weights[i][y], wires=y)\n        for y in range(n_qubits-1):\n            qml.CZ(wires=[y,y+1])\n    return qml.probs(wires=list(range(n_qubits)))\n\ndef partial_measure(noise, weights):\n    # Non-linear Transform\n    probs = quantum_circuit(noise, weights)\n    probsgiven0 = probs[: (2 ** (n_qubits - n_a_qubits))]\n    probsgiven0 /= torch.sum(probs)\n\n    # Post-Processing\n    probsgiven = probsgiven0 / torch.max(probsgiven0)\n    return probsgiven\n\n\nclass PatchQGenerator(nn.Module):\n    \"\"\"Quantum generator class for the patch method\"\"\"\n\n    def __init__(self, n_generators, output_dim, q_delta=1):\n\n        super().__init__()\n\n        self.q_params = nn.ParameterList(\n            [\n                nn.Parameter(q_delta * torch.rand(q_depth * n_qubits), requires_grad=True)\n                for _ in range(n_generators)\n            ]\n        )\n        self.n_generators = n_generators\n        self.output_dim = output_dim\n\n    def forward(self, x):\n        # Size of each sub-generator output\n        patch_size = 2 ** (n_qubits - n_a_qubits)\n        total_patches = (self.output_dim + patch_size -1) // patch_size\n        fake = torch.Tensor(x.size(0), 0).to(device)\n\n        # Iterate over all sub-generators\n        for params in self.q_params:\n\n            # Create a Tensor to 'catch' a batch of the patches from a single sub-generator\n            patches = torch.Tensor(0, patch_size).to(device)\n            for elem in x:\n                q_out = partial_measure(elem, params).float().unsqueeze(0)\n                patches = torch.cat((patches, q_out))\n\n            fake = torch.cat((fake, patches), 1)\n            fake = fake[:, :self.output_dim]\n\n        return fake\n\n\ninput_dim = data.shape[1]\n\ndiscriminator = Discriminator().to(device)\ngenerator = PatchQGenerator(n_generators).to(device)\n\n# Binary cross entropy\ncriterion = nn.BCELoss()\n\n# Optimisers\noptD = optim.Adam(discriminator.parameters(), lr=lrD)\noptG = optim.Adam(generator.parameters(), lr=lrG)\n\nreal_labels = torch.full((batch_size,), 1.0, dtype=torch.float, device=device)\nfake_labels = torch.full((batch_size,), 0.0, dtype=torch.float, device=device)\n\n# Fixed noise allows us to visually track the generated images throughout training\nfixed_noise = torch.rand(8, n_qubits, device=device) * math.pi / 2\n\n# Iteration counter\ncounter = 0\n\n# Collect images for plotting later\nresults = []\n\nwhile True:\n    for i, (data, _) in enumerate(dataloader):\n\n        # Data for training the discriminator\n        real_data = data.to(device)\n        noise = torch.rand(batch_size, n_qubits, device=device) * math.pi / 2\n        fake_data = generator(noise)\n\n        # Training the discriminator\n        discriminator.zero_grad()\n        outD_real = discriminator(real_data).view(-1)\n        outD_fake = discriminator(fake_data.detach()).view(-1)\n\n        errD_real = criterion(outD_real, real_labels)\n        errD_fake = criterion(outD_fake, fake_labels)\n        # Propagate gradients\n        errD_real.backward()\n        errD_fake.backward()\n\n        errD = (errD_real + errD_fake)/2\n        optD.step()\n\n        # Training the generator\n        generator.zero_grad()\n        outD_fake = discriminator(fake_data).view(-1)\n        errG = criterion(outD_fake, real_labels)\n        errG.backward()\n        optG.step()\n\n        counter += 1\n\n        # Show loss values\n        if counter % 20 == 0:\n            print(f'Iteration: {counter}, Discriminator Loss: {errD:0.3f}, Generator Loss: {errG:0.3f}')\n\n        if counter == num_iter:\n            break\n    if counter == num_iter:\n        break"
  },
  {
    "objectID": "checks/PQC_optim.html",
    "href": "checks/PQC_optim.html",
    "title": "Wstęp do kwantowego uczenia maszynowego",
    "section": "",
    "text": "import pennylane as qml\nfrom pennylane import numpy as np\n\n\ndev = qml.device('default.qubit', wires=2)\n\n@qml.qnode(dev)\ndef circuit(params):\n    qml.RX(params[0], wires=0)\n    qml.RY(params[1], wires=1)\n    qml.CNOT(wires=[0,1])\n    return qml.expval(qml.PauliZ(1))\n\n\nparams = np.array([0.1, 0.2], requires_grad=True)\nprint(\"Expectation value of circuit:\", circuit(params))\n\nExpectation value of circuit: 0.9751703272018161\n\n\n\nprint(\"Drawing of circuit:\\n\")\nprint(qml.draw_mpl(circuit)(params))\n\nDrawing of circuit:\n\n(&lt;Figure size 500x300 with 1 Axes&gt;, &lt;Axes: &gt;)\n\n\n\n\n\n\n\n\n\n\nopt = qml.GradientDescentOptimizer(stepsize=0.01)\n\niterations = 100\n\ncosts = []\n\nfor _ in range(iterations):\n    params, cost = opt.step_and_cost(circuit, params)\n    costs.append(cost)\n\n\nimport matplotlib.pyplot as plt\n\ncosts.append(circuit(params))\nplt.plot(costs, \"-o\")\nplt.xlabel(\"Iterations\")\nplt.ylabel(\"Cost\")\n\nprint(\"Minimized circuit output:\", circuit(params))\nprint(\"Optimized parameters:\", params)\n\nMinimized circuit output: -0.9999999215488692\nOptimized parameters: [1.79012316e-04 3.14123930e+00]"
  },
  {
    "objectID": "ksiazki.html",
    "href": "ksiazki.html",
    "title": "Literatura",
    "section": "",
    "text": "Klasyczne przetwarzanie informacji, działanie komputerów.\n\nRichard P. Feynman, Przetwarzanie informacji, z serii Feynmana wykłady, PWN 2022\nT. G. Wong, Introduction to Classical and Quantum Computing. Rooted Grove 2022.\n\n\n\n\n\n\n\nC. Bernhardt, Obliczenia kwantowe dla każdego. PWN 2020\nT. G. Wong, Introduction to Classical and Quantum Computing. Rooted Grove 2022.\nP. Gawron, M. Cholewa, … Rewolucja stanu. Fantastyczne wprowadzenie do informatyki kwantowej. Quantumz.io 2021\nM. Le Bellac, Wstęp do informatyki kwantowej. PWN 2011\nR. S. Sutor, Dancing with Qubits. Second edition, Packt 2024\n\n\n\n\n\n\n\nM. Schuld, F. Petruccione, Machine Learning with Quantum Computers, Springer 2021.\nA. Jacquier, O. Kondratyev, Quantum Machine Learning and Optimisation in Finance. On the Road to Quantum Advantage.\nA. Saxena, J. Mancilla, I. Montalban, C. Pere, Financial Modeling Using Quantum Computing. Packt 2023\n\n\n\n\n\n\n\nA. Geron, Uczenie maszynowe z użyciem Scikit-Learn i TensorFlow. Helion 2024\nS. Zajac, Modelowanie dla biznesu, Analityka w czasie rzeczywistym - narzędzia informatyczne i biznesowe. SGH 2022\nS. Raschka, Build a Large Language Model from scratch, Manning 2024\nL. Moroney, Sztuczna inteligencja i uczenie maszynowe dla programistów. Praktyczny przewodnik po sztucznej inteligencji. Helion 2021. Zobacz opis lub Kup e-book\nBruce, Bruce, Gedeck, Statystyka praktyczna w data science. Wydanie II. Helion. 2021."
  },
  {
    "objectID": "ksiazki.html#książki",
    "href": "ksiazki.html#książki",
    "title": "Literatura",
    "section": "",
    "text": "Klasyczne przetwarzanie informacji, działanie komputerów.\n\nRichard P. Feynman, Przetwarzanie informacji, z serii Feynmana wykłady, PWN 2022\nT. G. Wong, Introduction to Classical and Quantum Computing. Rooted Grove 2022.\n\n\n\n\n\n\n\nC. Bernhardt, Obliczenia kwantowe dla każdego. PWN 2020\nT. G. Wong, Introduction to Classical and Quantum Computing. Rooted Grove 2022.\nP. Gawron, M. Cholewa, … Rewolucja stanu. Fantastyczne wprowadzenie do informatyki kwantowej. Quantumz.io 2021\nM. Le Bellac, Wstęp do informatyki kwantowej. PWN 2011\nR. S. Sutor, Dancing with Qubits. Second edition, Packt 2024\n\n\n\n\n\n\n\nM. Schuld, F. Petruccione, Machine Learning with Quantum Computers, Springer 2021.\nA. Jacquier, O. Kondratyev, Quantum Machine Learning and Optimisation in Finance. On the Road to Quantum Advantage.\nA. Saxena, J. Mancilla, I. Montalban, C. Pere, Financial Modeling Using Quantum Computing. Packt 2023\n\n\n\n\n\n\n\nA. Geron, Uczenie maszynowe z użyciem Scikit-Learn i TensorFlow. Helion 2024\nS. Zajac, Modelowanie dla biznesu, Analityka w czasie rzeczywistym - narzędzia informatyczne i biznesowe. SGH 2022\nS. Raschka, Build a Large Language Model from scratch, Manning 2024\nL. Moroney, Sztuczna inteligencja i uczenie maszynowe dla programistów. Praktyczny przewodnik po sztucznej inteligencji. Helion 2021. Zobacz opis lub Kup e-book\nBruce, Bruce, Gedeck, Statystyka praktyczna w data science. Wydanie II. Helion. 2021."
  },
  {
    "objectID": "ksiazki.html#strony-www",
    "href": "ksiazki.html#strony-www",
    "title": "Literatura",
    "section": "Strony WWW",
    "text": "Strony WWW\n\nPeter Shor Wykład\n\n\nPakiety Python\n\nQiskit\nPennyLane\n\n\n\nEdytory tekstu\n\nVisual Studio Code\nSublime Text\nNotepad++\n\n\n\nMarkdown\n\nMD"
  },
  {
    "objectID": "labs/cw5.html",
    "href": "labs/cw5.html",
    "title": "Optymalizacja z Variational Quantum Algorithms",
    "section": "",
    "text": "Wariacyjne algorytmy kwantowe są odpowiedzią na problem klasycznych algorytmów wykorzystywanych w obliczeniach kwantowych - mianowicie algorytmy te (np wzmacnianie amplitudy) wymagają duzej liczby kubitów.\nZamiast realizować zadania za pomocą ustalonej sekwencji ustaolnych bramek algorytmy VQA definiowane są za pomocą ansatz \\(W(\\theta)\\), który mozemy uznać za template (wzór) opisujący jakie bramki działają na który kubit. Dodatkowo kazdy ansatz moze byc wykonywany wiele razy (w jednym algorytmie) tworzą w ten sposób osobne warstwy (layers). Nazwa variational bierze się z tego, iz część bramek mozna realizować jako bramki obrotów zaleznych od parametrów.",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Optymalizacja z Variational Quantum Algorithms"
    ]
  },
  {
    "objectID": "labs/cw5.html#vqe",
    "href": "labs/cw5.html#vqe",
    "title": "Optymalizacja z Variational Quantum Algorithms",
    "section": "VQE",
    "text": "VQE\nAlgorytmy wariacyjne zostały zaproponowane w celu znalezienia stanu podstawowego, stanu o najnizszej energii (najmniejsza wartość własna z odpowiadaijącym wekrtorem własnym).\nStan podstawowy \\(\\ket{\\psi}\\) to stan dla którego wartość oczekiwana operatora jest minimalna. \\[ \\bra{\\psi} H \\ket{\\psi} \\]\nAlgorytm VQE propnuje aby stan podstawowy zrealizować jako ansatz.\n$ = W () $ Zamiast szukać stanu podstawowego $ $ znajdujemy prametr \\(\\theta\\) dla którego wartość oczekiwana jest minimalna.\n\\[ C(\\theta) = \\bra{\\psi \\left(\\theta\\right)}  H \\ket{\\psi \\left(\\theta\\right)}  \\]\nObliczenie wartości oczekiwanej dowolnego hamiltonianu nie musi być trudne ale wymaga duzej ilości powtórzeń dla niewielkiej liczby kubitów aby uzyskać odpowiednią statystykę.\nW wielu praktycznych przypadkach mozemy wyrazić nasz operator jako sumę jedno lub dwu kubitowych obserwabli. \\[ H = \\sum_{j=1}^{J} h_j H_j \\]\nW ogólności macierze Pauliego tworzą bazę dla macierzy 2x2 i dzieki temu zawsze mozemy zapisać ten wzór jako:\n\\[ H = \\sum_{i=1}^{n} \\sum_{\\alpha={x,y,z,1}} h^i_{\\alpha} \\sigma^i_{\\alpha} + \\] \\[ +\\sum_{i,j=1}^{n} \\sum_{\\alpha, \\beta={x,y,z,1}} h^{ij}_{\\alpha \\beta} \\sigma^i_{\\alpha}\\sigma^j_{\\beta} + \\]",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Optymalizacja z Variational Quantum Algorithms"
    ]
  },
  {
    "objectID": "labs/cw5.html#obwód-kwantowy-z-optymalizacją",
    "href": "labs/cw5.html#obwód-kwantowy-z-optymalizacją",
    "title": "Optymalizacja z Variational Quantum Algorithms",
    "section": "Obwód kwantowy z optymalizacją",
    "text": "Obwód kwantowy z optymalizacją\n\nNapisz obwód kwantowy, który zawierać będzie tylko bramkę \\(R_X\\) dla dowolnego parametru \\(\\theta\\)\noblicz i uzasadnij, że wartość oczekiwana dla stanu \\(\\ket{\\psi} = R_X \\, \\ket{0}\\) \\[&lt;Z&gt; = cos^2(\\theta /2)- sin^2(\\theta /2) = cos(\\theta)\\]\n\nZałóżmy, że nasz problem obliczeniowy sprowadza się do wygenerowania wartości oczekiwanej o wartości 0.5.\n\\[\n\\textbf{&lt;Z&gt;} = \\bra{\\psi} \\textbf{Z} \\ket{\\psi} = 0.5\n\\]\nNapisz program znajdujący rozwiązanie - szukający wagę \\(\\theta\\) dla naszego obwodu\n\nZdefiniuj funkcję kosztu, którą bedziemy minimalizować \\((Y - y)^2\\)\nzainicjuj rozwiązanie \\(theta=0.01\\) i przypisz do tablicy array np.array(0.01, requires_grad=True)\nJako opt wybierz spadek po gradiencie : opt = qml.GradientDescentOptimizer(stepsize=0.1)\nuzyj poniższego kodu do wygenerowania pętli obiczeń\n\n\n# Rozwiązanie \n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=1)\n\n@qml.qnode(dev)\ndef par_c(theta):\n    qml.RX(theta, wires=0)\n    return qml.expval(qml.PauliZ(0))\n\n\ndef cost_fn(theta):\n    return (par_c(theta) - 0.5)**2\n\ntheta = np.array(0.01, requires_grad=True)\n\nopt = qml.GradientDescentOptimizer(stepsize=0.1)\n\nepochs = 100\n\nfor epoch in range(epochs):\n    theta = opt.step(cost_fn, theta)\n\n    if epoch % 10 == 0:\n        print(f\"epoka: {epoch}, theta: {theta}, koszt: {cost_fn(theta)}\")\n\nprint(f\"Optymalizacja zakonczona dla theta={theta}, koszt: {cost_fn(theta)}\")\n\nepoka: 0, theta: 0.010999883335916642, koszt: 0.24993950555333252\nepoka: 10, theta: 0.028520883980330904, koszt: 0.2495934725570593\nepoka: 20, theta: 0.07380240366299132, koszt: 0.24728524869432472\nepoka: 30, theta: 0.18848123038996684, koszt: 0.23260358196368314\nepoka: 40, theta: 0.44553231822816797, koszt: 0.1619107886095973\nepoka: 50, theta: 0.7954652635692223, koszt: 0.03998102446252434\nepoka: 60, theta: 0.9838691671205075, koszt: 0.002894983645374295\nepoka: 70, theta: 1.0340365114010706, koszt: 0.00012891702079013002\nepoka: 80, theta: 1.0445781695789977, koszt: 5.138079127884816e-06\nepoka: 90, theta: 1.0466807535250837, koszt: 2.002500944777545e-07\nOptymalizacja zakonczona dla theta=1.0470778036429096, koszt: 1.0753863888581739e-08\n\n\nJeszcze jeden przykład\n\nNapisz obwód kwantowy, który zawierać będzie bramkę \\(R_X\\) dla parametru \\(\\theta_1\\) oraz \\(R_Y\\) dla parametru \\(\\theta_2\\)\noblicz i uzasadnij, że wartość oczekiwana dla stanu \\(\\ket{\\psi} = R_Y(\\theta_2) R_X(\\theta_1) \\, \\ket{0}\\)\n\n\\[&lt;Z&gt;  = \\cos(\\theta_1) \\cos(\\theta_2)\\]\nMozliwe wartości średniej zawierają się w przedziale \\(-1\\), \\(1\\).\nPrzyjmij załozenie, ze optymalne rozwiązanie realizowane jest dla wartości oczekiwanej = 0.4\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=1)\n\n@qml.qnode(dev)\ndef par_c(theta):\n    qml.RX(theta[0], wires=0)\n    qml.RY(theta[1], wires=0)\n    return qml.expval(qml.PauliZ(0))\n\n\ndef cost_fn(theta):\n    return (par_c(theta) - 0.4)**2\n\ntheta = np.array([0.01, 0.02], requires_grad=True)\n\nopt = qml.GradientDescentOptimizer(stepsize=0.1)\n\nepochs = 100\n\nfor epoch in range(epochs):\n    theta = opt.step(cost_fn, theta)\n\n    if epoch % 10 == 0:\n        print(f\"epoka: {epoch}, theta: {theta}, koszt: {cost_fn(theta)}\")\n\nprint(f\"Optymalizacja zakonczona dla theta={theta}, koszt: {cost_fn(theta)}\")\n\nepoka: 0, theta: [0.01119924 0.02239872], koszt: 0.3596238551650218\nepoka: 10, theta: [0.03468299 0.06939827], koszt: 0.35640059384126277\nepoka: 20, theta: [0.10485556 0.21069384], koszt: 0.3277736421372642\nepoka: 30, theta: [0.26595847 0.55025891], koszt: 0.17843868824086426\nepoka: 40, theta: [0.41114867 0.91214351], koszt: 0.02593550926609833\nepoka: 50, theta: [0.45600131 1.05610411], koszt: 0.0017612620807984237\nepoka: 60, theta: [0.46619699 1.09390217], koszt: 0.00010074458607215528\nepoka: 70, theta: [0.4685347  1.10295946], koszt: 5.557697121461739e-06\nepoka: 80, theta: [0.469078   1.10508776], koszt: 3.040948516747214e-07\nepoka: 90, theta: [0.46920476 1.10558565], koszt: 1.6607272093790385e-08\nOptymalizacja zakonczona dla theta=[0.46923296 1.10569646], koszt: 1.2125189676042736e-09\n\n\n\nZadanie\nCelem jest znalezienie najmnieszej wartości własnej dla Hamiltonianu \\(H = Z_0 Z_1 + Z_0\\)\nTego typu hamiltoniany opisują układy fizyczne np. systemy spinowe.\n\\(Z_0 Z_1\\) - mozna interpretować jako krawedz miedzy dwoma wierzchołkami.\n\\(Z_0\\) - efekty lokalne wierzchołka 0\n\nimport pennylane as qml\nfrom pennylane import numpy as np \nimport random\n\ndev = qml.device(\"default.qubit\", wires=2)\n\nH = qml.PauliZ(0) @ qml.PauliZ(1) + qml.PauliZ(0)\n\n@qml.qnode(dev)\ndef circuit(params):\n    qml.RY(params[0], wires=0)\n    qml.RY(params[1], wires=1)\n    qml.CNOT(wires=[0,1])\n    return qml.expval(H)\n\ndef cost_fn(params):\n    return circuit(params)\n\ninit_param = [random.uniform(0, 2*3.1415) for _ in range(2)]\n\nparams = np.array(init_param, requires_grad=True)\n\nopt = qml.GradientDescentOptimizer(stepsize=0.01)\n\nepochs = 500\nfor epoch in range(epochs):\n    params = opt.step(cost_fn, params)\n\n    if epoch % 50 == 0:\n        print(f\"epoka: {epoch}, theta: {params}, koszt: {cost_fn(params)}\")\n\nprint(f\"Optymalizacja zakonczona dla theta={params}, koszt: {cost_fn(params)}\")\n\nepoka: 0, theta: [3.78581375 2.84095803], koszt: -1.7547165517420802\nepoka: 50, theta: [3.54018563 2.95882169], koszt: -1.9049518343552694\nepoka: 100, theta: [3.38481311 3.03081671], koszt: -1.9644380440438454\nepoka: 150, theta: [3.28921059 3.0745284 ], koszt: -1.9868762791995278\nepoka: 200, theta: [3.23100688 3.10100859], koszt: -1.9951817904668534\nepoka: 250, theta: [3.19571201 3.11703688], koszt: -1.998234427307502\nepoka: 300, theta: [3.17434033 3.12673578], koszt: -1.9993534812964953\nepoka: 350, theta: [3.16140634 3.13260405], koszt: -1.9997633181211054\nepoka: 400, theta: [3.15358031 3.13615447], koszt: -1.9999133620707328\nepoka: 450, theta: [3.14884531 3.13830251], koszt: -1.999968287085212\nOptymalizacja zakonczona dla theta=[3.14602489 3.13958199], koszt: -1.9999881562738895",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Optymalizacja z Variational Quantum Algorithms"
    ]
  },
  {
    "objectID": "labs/cw5.html#qubo---quadratic-unconstrained-binary-optimization",
    "href": "labs/cw5.html#qubo---quadratic-unconstrained-binary-optimization",
    "title": "Optymalizacja z Variational Quantum Algorithms",
    "section": "QUBO - Quadratic unconstrained binary optimization",
    "text": "QUBO - Quadratic unconstrained binary optimization\nWiki info\nArtykuł\nArtykuł 2 - bardzo dobry przykład uzycia\nLista problemów zdefiniowanych jako problem QUBO\n\nlogistyka,\nplanowanie,\noptymalizacja portfolio,\n…\n\nCombinatorial optimization problems are problems involving a large number of yes/no decisions with each set of decisions yielding a corresponding objective function value, like a cost or profit value.\nBecause of the combinatorial explosion of the solution space with the number of variables, finding good solutions is extremely difficult.\nThe QUBO model unifies a rich variety of NP-hard combinatorial optimization problems:\n\nQuadratic Assignment Problems\nCapital Budgeting Problems\nTask allocation Problems\nMaximum–Cut Problems\n\nQUBO objective function:\n\\[\nF(q) = \\sum_a v_a x_a + \\sum_{a &lt; b} \\omega_{a b} x_a x_b\n\\] gdzie \\(q_a \\in \\{0,1\\}\\), \\(v_a\\) oraz \\(\\omega_a\\) to rzeczywiste współczynniki dla liniowej i kwadratowej części.\nRozwiązanie QUBO jest problemem NP-trudnym.\nWprowadźmy zamianę zmiennych: \\[\nx_i = 1/2 (1 - z_i)\n\\] gdzie \\(z \\in {-1,1}\\)\n\\[\nF(z) = \\sum_a h_a z_a + \\sum_{a &lt; b} J_{a b} z_a z_b\n\\]\nJak to zagadnienie wrzucić na komputer kwantowy\nKorzystając z zamiany zmiennych \\[f(z_1,...,z_5)  = 6 - \\frac{1}{2} z_1 z_4 - \\frac{1}{2} z_2 z_3 - \\frac{1}{2} z_4 z_5 - \\frac{1}{2} z_3 z_4 \\]\nMozemy teraz przygotować “Hamiltonian” dla tej konfiguracji - zamieniamy zmienne \\(z_i\\) na macierze Pauliego \\(Z_i\\)\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\n# H = 6* qml.Identity(1) - \\ \n# 0.5 * qml.PauliZ(1) @ qml.PauliZ(4) - \\\n# 0.5 * qml.PauliZ(2) @ qml.PauliZ(3) - \\\n# 0.5 * qml.PauliZ(4) @ qml.PauliZ(5) - \\\n# 0.5 * qml.PauliZ(3) @ qml.PauliZ(4)\n\n# bo chcemy minimalizować \nH = - 6 * qml.Identity(0) +  \\\n    0.5 * qml.PauliZ(0) @ qml.PauliZ(3) + \\\n    0.5 * qml.PauliZ(1) @ qml.PauliZ(2) +  0.5 * qml.PauliZ(3) @ qml.PauliZ(4) +  0.5 * qml.PauliZ(2) @ qml.PauliZ(3)\n\nprint(H, H.wires)\n\ndev = qml.device(\"default.qubit\",  H.wires)\n\n@qml.qnode(dev)\ndef circuit(params):\n    for param, wire in zip(params, H.wires):\n        qml.RY(param, wires=wire)\n    return qml.expval(H)\n\n-6 * I(0) + (0.5 * Z(0)) @ Z(3) + (0.5 * Z(1)) @ Z(2) + (0.5 * Z(3)) @ Z(4) + (0.5 * Z(2)) @ Z(3) &lt;Wires = [0, 3, 1, 2, 4]&gt;\n\n\nZałózmy, ze wszystkie osoby poszly w ten sam dzień\n\ncircuit([0,0,0,0,0])\n\ntensor(-4., requires_grad=True)\n\n\n\nparams = np.random.rand(len(H.wires))\nopt = qml.GradientDescentOptimizer(stepsize=0.5)\nepochs = 200\n\nfor epoch in range(epochs):\n    params = opt.step(circuit, params)\n\n    if epoch % 50 == 0:\n        print(f\"epoka: {epoch}, theta: {params}, koszt: {circuit(params)}\")\n\nprint(f\"Optymalizacja zakonczona dla theta={params}, koszt: {circuit(params)}\")\n\nepoka: 0, theta: [0.80227878 0.34407939 0.62771339 0.27812424 0.48717075], koszt: -4.415161534719515\nepoka: 50, theta: [5.55966795e-06 3.14159265e+00 3.14158384e+00 2.88840393e-13\n 3.08092869e-06], koszt: -7.999999999970489\nepoka: 100, theta: [3.14856036e-12 3.14159265e+00 3.14159265e+00 2.56541804e-28\n 1.74479664e-12], koszt: -8.0\nepoka: 150, theta: [1.78309792e-18 3.14159265e+00 3.14159265e+00 2.27854894e-43\n 9.88116124e-19], koszt: -8.0\nOptymalizacja zakonczona dla theta=[1.34640929e-24 3.14159265e+00 3.14159265e+00 4.04751599e-58\n 7.46122080e-25], koszt: -8.0\n\n\n\ndev = qml.device(\"default.qubit\",  H.wires, shots=1)\n\n@qml.qnode(dev)\ndef results(params):\n    for param, wire in zip(params, H.wires):\n        qml.RY(param, wires=wire)\n    return qml.sample()\n\n\nresults(params)\n\narray([0, 1, 1, 0, 0])\n\n\nBramki kwantowe realizowane są w modelu bramkowym przez operatory unitarne reprezentowane przez macierze.\n\\[\nU U^{\\dagger} = U^{\\dagger} U = I\n\\]\nKazda macierz unitarna moze być przedstawiona jako:\n\\[\nU(H,t) = e^{-i H t}\n\\] gdzie \\(H\\) to macierz Hermitowska (\\(H=H^{\\dagger}\\))\nW ogólności, implementacja obwodu kwantowego, który dokładnie realizuje macierz unitarną dla zadanego Hamiltonianiu jest bardzo trudnym zadaniem. Hamiltonian taki zazwyczaj składa się z sumy wielu niekomutujących części.\n\\[\nH = H_1 + H_2 + \\dots + H_n\n\\]\nRozwazmy pierwszy prosty przypadek gdzie nasza macierz \\(H\\) realizowana jest przez operator Pauliego \\(Z\\).\nChcielibyśmy znaleźć tzn poziom podstawowy operatora \\(H\\), czyli jego wektor własny dla którego ma on najmniejszą wartość własną. Takie podejście powinno kojarzyć się nam z wymogiem minimalizacji funkcji straty. \\[ H\\ket{E_0} = E_0\\ket{E_0} \\]\nW przypadku gdy \\(H = Z\\) mamy dwa stany \\(\\ket{0}\\) i \\(\\ket{1}\\)\n\\[ Z\\ket{0} = 1 \\ket{0} \\]\n\\[ Z\\ket{1} = -1 \\ket{1} \\]\nCzyli stanem o najmniejszej wartości własnej jest stan \\(\\ket{1}\\).\nZałózmy, ze nie znamy tej informacji!!!\nAlgorytm QAOA\n\nPrzygotuj obwód i zastosuj bramkę Hadamarda - stan superpozycji (\\(\\ket{+} = H\\ket{0}\\))\nDokonujemy ewolucji czasowej naszego operatora \\(Z\\) \\[ e^{-itZ}\\ket{+}  = \\frac{1}{\\sqrt{2}}(e^{-it}\\ket{0} + e^{it}\\ket{1})\\]\nZastosujmy dodatkowo bramkę \\(R_X(-\\theta)\\) \\[  R_x(- \\theta) \\frac{1}{\\sqrt{2}}(e^{-it}\\ket{0} + e^{it}\\ket{1})\\] \\[  \\frac{1}{\\sqrt{2}}\\left( (e^{-it} cos(\\theta /2 + i e^{it}sin(\\theta /2)) \\ket{0} + (ie^{-it} sin(\\theta /2 + e^{it} cos(\\theta /2))\\ket{1}) \\right)\\]\n\nDla $t = /4 $ oraz \\(\\theta = \\pi /2\\) otrzymujemy stan \\(\\ket{1}\\)\nNazewnictwo:\n\nCost Hamiltonian: \\(H_{cost} = Z\\)\n\nMixer Hamiltonian: \\(H_{mixer} = X\\) bo \\(R_x(t) = e^{-itX}\\)\n\nMozemy wykorzystać wzór Trotter'a-Suzuki który przybliza dowolną sumę macierzy \\[\ne^{A + B} \\approx \\left( e^{A/n} e^{B/n} \\right)^n\n\\]\ndlatego dla \\(H=\\sum_k H_k\\) otrzymujemy \\[ U(H,t,n) = \\prod_{j=1}^n \\prod_k e^{-i H_k t/n} \\]",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Optymalizacja z Variational Quantum Algorithms"
    ]
  },
  {
    "objectID": "labs/cw5.html#quantum-approximate-optimization-algorithm",
    "href": "labs/cw5.html#quantum-approximate-optimization-algorithm",
    "title": "Optymalizacja z Variational Quantum Algorithms",
    "section": "Quantum Approximate Optimization Algorithm",
    "text": "Quantum Approximate Optimization Algorithm\nQAOA mozna zastosować do nietrywialnych problemów kombinatorycznych (optymalizacyjnych).\nJest on przykładem realizacji VQA czyli wariacyjnych algorytmów kwantowych opartych na (PQC) parametryzowanych obwodów kwantowych.\nMozna uruchomić go na współcześnie dostępnych komputerach kwantowych. Nie wymaga skomplikowanych bramek.\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\nfrom pennylane import qaoa\n\nimport matplotlib.pyplot as plt \n# import cmath\n\n\ncost_H = qml.Hamiltonian(\n    [1,1,1],\n    [qml.PauliZ(0), qml.PauliZ(1), qml.PauliZ(2)]\n    ) # minimum dla |111&gt; \nmixer_H  = qml.Hamiltonian(\n    [1,1,1],\n    [qml.PauliX(0), qml.PauliX(1), qml.PauliX(2)]\n    ) \n\nwires = cost_H.wires\nprint(wires)\n\n# circuit - one layer = H_cos + H mix\n\nnum_layers = 5 \n\ndef qoao_layer(gamma, alpha):\n    qaoa.cost_layer(gamma, cost_H)\n    qaoa.mixer_layer(alpha, mixer_H)\n\ndef circuit(params):\n    for w in wires:\n        qml.Hadamard(w)\n    qml.layer(qoao_layer, num_layers, params[0], params[1]) # potwarza layer n razy\n\ndev = qml.device('default.qubit', wires=wires)\n\n@qml.qnode(dev)\ndef cost_function(params):\n    circuit(params)\n    return qml.expval(cost_H)\n\n&lt;Wires = [0, 1, 2]&gt;\n\n\n\nparams = np.array([[0.5]*num_layers, [0.5]*num_layers], requires_grad=True)\n\n\nopt = qml.GradientDescentOptimizer()\nepochs = 100\n\nfor epoch in range(epochs):\n    params = opt.step(cost_function, params)\n\n\nprint(f\"Optymalizacja zakonczona dla theta={params}, koszt: {cost_function(params)}\")\n\nOptymalizacja zakonczona dla theta=[[0.44741266 0.59627289 0.48116583 0.23007397 0.25139093]\n [0.25139093 0.23007397 0.48116583 0.59627289 0.44741266]], koszt: -2.999999999999984\n\n\n\n@qml.qnode(dev)\ndef circuit_state(params):\n    circuit(params)\n    return qml.state()\n\n\nnp.round_(circuit_state(params),  decimals=5)\n\ntensor([-0.+0.j,  0.-0.j,  0.-0.j, -0.-0.j, -0.+0.j, -0.-0.j,  0.-0.j,\n        -1.-0.j], requires_grad=True)\n\n\n\n@qml.qnode(dev)\ndef probability_circuit(gamma, alpha):\n    circuit([gamma, alpha])\n    return qml.probs(wires=wires)\n\n\nprobs = probability_circuit(params[0], params[1])\n\n\nplt.bar(range(2 ** len(wires)), probs)\nplt.show()\n\n\n\n\n\n\n\n\n\n\"{0:b}\".format(7)\n\n'111'\n\n\n\nMax-cut\n\nfrom pennylane import qaoa\nfrom pennylane import numpy as np\nfrom matplotlib import pyplot as plt\nimport networkx as nx\n\n\nedges = [(0, 1), (1, 2),(2,3),(3,0)]\ngraph = nx.Graph(edges)\nnx.draw(graph, with_labels=True)\nplt.show()\n\n\n\n\n\n\n\n\n\ncost_h, mixer_h = qaoa.min_vertex_cover(graph, constrained=False)\n\nprint(\"Cost Hamiltonian\", cost_h)\nprint(\"Mixer Hamiltonian\", mixer_h)\n\nCost Hamiltonian 0.75 * (Z(0) @ Z(1)) + 0.75 * Z(0) + 0.75 * Z(1) + 0.75 * (Z(0) @ Z(3)) + 0.75 * Z(0) + 0.75 * Z(3) + 0.75 * (Z(1) @ Z(2)) + 0.75 * Z(1) + 0.75 * Z(2) + 0.75 * (Z(2) @ Z(3)) + 0.75 * Z(2) + 0.75 * Z(3) + -1.0 * Z(0) + -1.0 * Z(1) + -1.0 * Z(2) + -1.0 * Z(3)\nMixer Hamiltonian 1 * X(0) + 1 * X(1) + 1 * X(2) + 1 * X(3)\n\n\n\ndef qaoa_layer(gamma, alpha):\n    qaoa.cost_layer(gamma, cost_h)\n    qaoa.mixer_layer(alpha, mixer_h)\n\n\nwires = cost_h.wires\ndepth = 2\n\n\ndef circuit(params, **kwargs):\n    for w in wires:\n        qml.Hadamard(wires=w)\n    qml.layer(qaoa_layer, depth, params[0], params[1])\n\n\ndev = qml.device(\"default.qubit\", wires=wires)\n\n\n@qml.qnode(dev)\ndef cost_function(params):\n    circuit(params)\n    return qml.expval(cost_h)\n\n\noptimizer = qml.GradientDescentOptimizer()\nsteps = 70\nparams = np.array([[0.5, 0.5], [0.5, 0.5]], requires_grad=True)\n\n\nfor i in range(steps):\n    params = optimizer.step(cost_function, params)\n\nprint(\"Optimal Parameters\")\nprint(params)\n\nOptimal Parameters\n[[0.63141524 1.02160759]\n [0.51521978 0.86666078]]\n\n\n\n@qml.qnode(dev)\ndef probability_circuit(gamma, alpha):\n    circuit([gamma, alpha])\n    return qml.probs(wires=wires)\n\n\nprobs = probability_circuit(params[0], params[1])\n\n\nplt.bar(range(2 ** len(wires)), probs)\nplt.show()\n\n\n\n\n\n\n\n\n\n('{0:04b}'.format(6), '{0:04b}'.format(9))\n\n('0110', '1001')",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Optymalizacja z Variational Quantum Algorithms"
    ]
  },
  {
    "objectID": "labs/cw3.html",
    "href": "labs/cw3.html",
    "title": "Bramki jednokubitowe",
    "section": "",
    "text": "Znasz już bramkę Hadamarda, bramkę \\(X\\) oraz bramki rotacji (\\(R_x\\), \\(R_y\\), \\(R_z\\))\nDla przypomnienia :\nBramka \\(X\\):\n\\[\n\\textbf{X} = \\begin{bmatrix} 0 \\,\\, 1 \\\\ 1 \\,\\, 0 \\end{bmatrix}\n\\]\n\\[\n\\textbf{X} \\ket{0} = \\begin{bmatrix} 0\\,\\, 1 \\\\ 1 \\, 0 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} =  \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\ket{1}\n\\] oraz \\[\n\\textbf{X} \\ket{0} = \\begin{bmatrix} 0\\,\\, 1 \\\\ 1 \\, 0 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} =  \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\ket{0}\n\\]\nBramka \\(H\\):\n\\[\n\\textbf{H}= \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1\\,\\,\\,\\,\\,\\,\\, 1 \\\\ 1 \\, -1 \\end{bmatrix}\n\\]\ndla której\n\\[\n\\textbf{H} \\ket{0} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1\\,\\,\\,\\,\\,\\,\\, 1 \\\\ 1 \\, -1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\frac{1}{\\sqrt{2}} \\left( \\ket{0} + \\ket{1} \\right) = \\ket{+}\n\\] oraz \\[\n\\textbf{H} \\ket{1} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1\\,\\,\\,\\,\\,\\,\\, 1 \\\\ 1 \\, -1 \\end{bmatrix}  \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\frac{1}{\\sqrt{2}} \\left( \\ket{0} - \\ket{1} \\right) = \\ket{-}\n\\]",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Bramki jednokubitowe"
    ]
  },
  {
    "objectID": "labs/cw3.html#podstawowe-bramki-jednokubitowe",
    "href": "labs/cw3.html#podstawowe-bramki-jednokubitowe",
    "title": "Bramki jednokubitowe",
    "section": "",
    "text": "Znasz już bramkę Hadamarda, bramkę \\(X\\) oraz bramki rotacji (\\(R_x\\), \\(R_y\\), \\(R_z\\))\nDla przypomnienia :\nBramka \\(X\\):\n\\[\n\\textbf{X} = \\begin{bmatrix} 0 \\,\\, 1 \\\\ 1 \\,\\, 0 \\end{bmatrix}\n\\]\n\\[\n\\textbf{X} \\ket{0} = \\begin{bmatrix} 0\\,\\, 1 \\\\ 1 \\, 0 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} =  \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\ket{1}\n\\] oraz \\[\n\\textbf{X} \\ket{0} = \\begin{bmatrix} 0\\,\\, 1 \\\\ 1 \\, 0 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} =  \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\ket{0}\n\\]\nBramka \\(H\\):\n\\[\n\\textbf{H}= \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1\\,\\,\\,\\,\\,\\,\\, 1 \\\\ 1 \\, -1 \\end{bmatrix}\n\\]\ndla której\n\\[\n\\textbf{H} \\ket{0} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1\\,\\,\\,\\,\\,\\,\\, 1 \\\\ 1 \\, -1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\frac{1}{\\sqrt{2}} \\left( \\ket{0} + \\ket{1} \\right) = \\ket{+}\n\\] oraz \\[\n\\textbf{H} \\ket{1} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1\\,\\,\\,\\,\\,\\,\\, 1 \\\\ 1 \\, -1 \\end{bmatrix}  \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\frac{1}{\\sqrt{2}} \\left( \\ket{0} - \\ket{1} \\right) = \\ket{-}\n\\]",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Bramki jednokubitowe"
    ]
  },
  {
    "objectID": "labs/cw3.html#losowy-bit",
    "href": "labs/cw3.html#losowy-bit",
    "title": "Bramki jednokubitowe",
    "section": "Losowy bit",
    "text": "Losowy bit\nklasycznie\n# generator liczb losowych\nfrom random import randrange\n''.join([str(randrange(2)) for i in range(8)])\nlub\n# mozna takze zrealizowac jako rzut monetą \n\nimport random\nfor n in range(5):\n    if random.random()&lt;0.5:       #if the random number is less than 0.5 print heads\n        print('HEADS')\n    else:\n        print('TAILS')\nKWANTOWO\n\nUżyj default.qubit jako klasyczny symulator w funkcji device\nzmień funkcję qc w obwód kwantowy korzystając z dekoratora @qml.qnode\nzdefinuj funkcję qc z jednym kubitem\nna kubicie wykorzystaj bramkę Hadamarda\nwyświetl stan po pomiarze pojedynczego kubitu\nwyświetl prawdopodobieństwa otrzymania stanu 0 i 1\nuruchom obwód 3 razy (do dev dodaj parametr , shots=3) i sprawdź wyniki otrzymywane przez metodę qml.counts() link\nuruchom powyzszą prcedurę 100 razy\n\nDo jakiego zdarzenia losowego podobne są wyniki?",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Bramki jednokubitowe"
    ]
  },
  {
    "objectID": "labs/cw3.html#losowy-bajt",
    "href": "labs/cw3.html#losowy-bajt",
    "title": "Bramki jednokubitowe",
    "section": "Losowy bajt",
    "text": "Losowy bajt\n\nbajt to 8 bitów - jaki zakres wartości jesteś w stanie przechowywać w 8 kubitach ?\nwygeneruj losowy bajt z wykorzystaniem tylko bramki X\n\nif randrange(2) == 0:\n        qc.x(i)\n\nwygeneruj losowy bajt z wykorzystaniem bramek hadamarda\nwygeneruj 10 prób w pełni losowego bajtu - odkoduj wyniki w systemie int\noblicz różnicę dwóch bajtów dla których pierwsze cztery bity to 0, piąty bit pierwszego bajtu to 0 a drugiego bajtu to 1 . pozostałe bity są równe 1",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Bramki jednokubitowe"
    ]
  },
  {
    "objectID": "labs/cw3.html#losowa-liczba-w-zakresie-0-15",
    "href": "labs/cw3.html#losowa-liczba-w-zakresie-0-15",
    "title": "Bramki jednokubitowe",
    "section": "Losowa liczba w zakresie 0-15",
    "text": "Losowa liczba w zakresie 0-15\n\nZa pomocą odpowiedniego obwodu kwantowego wylosuj liczbę z zakresu 0-15\nWykorzystaj 1000 wykonań modelu i narysuj histogram wyników dla poszczególnych liczb 0-15",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Bramki jednokubitowe"
    ]
  },
  {
    "objectID": "labs/cw3.html#wartość-oczekiwana-operatora-z-na-obwodzie",
    "href": "labs/cw3.html#wartość-oczekiwana-operatora-z-na-obwodzie",
    "title": "Bramki jednokubitowe",
    "section": "Wartość oczekiwana operatora Z na obwodzie",
    "text": "Wartość oczekiwana operatora Z na obwodzie\nRozszerz wygenerowany obwód dla losowego bitu i dodaj parametryzowaną bramkę \\(R_x\\) z kątem ustawionym jako pi/4\nOblicz wartość oczekiwaną operatora \\(&lt;\\sigma_z&gt;\\) wykorzystując qml.expval(qml.PauliZ(0))\nBramka (i operator) Z, w bazie obliczeniowej dany jest macierzą: \\[\n\\textbf{Z} = \\begin{bmatrix} 1 \\,\\,\\,\\,\\,\\,\\,\\, 0 \\\\ 0 \\,\\, -1 \\end{bmatrix}\n\\]\nOperator ten mierzy różnicę pomiędzy prawdopodobieństwem, że kubit jest w stanie \\(\\ket{0}\\) a prawdopodobieństwem, że jest w stanie \\(\\ket{1}\\)\nW ogólności wartość oczekiwana (wartość średnia wyniku pomiaru w bazie operatora Z) dana jest wzorem: \\[\n\\textbf{&lt;Z&gt;} = \\bra{\\psi} \\textbf{Z} \\ket{\\psi}\n\\]\nNiech \\[\n\\ket{\\psi} = \\alpha\\ket{0} + \\beta\\ket{1}\n\\] wtedy \\[\n\\bra{\\psi} = \\alpha^*\\bra{0} + \\beta^*\\bra{1}\n\\]\nMożemy obliczyć: \\[\n\\bra{\\psi} \\textbf{Z} \\ket{\\psi}  = (\\alpha^*\\bra{0} + \\beta^*\\bra{1} ) \\,\\,\\, Z \\,\\,\\,(\\alpha\\ket{0} + \\beta\\ket{1}) = |\\alpha|^2 - |\\beta|^2\n\\] Czyli dla kubitu w stanie \\(\\ket{0}\\) \\[\n\\textbf{&lt;Z&gt;} = 1  \n\\] Dla kubitu w stanie \\(\\ket{1}\\) \\[\n\\textbf{&lt;Z&gt;} = -1  \n\\] Dla kubitu w superpozycji \\(\\ket{0} +\\ket{1}\\) \\[\n\\textbf{&lt;Z&gt;} = 0  \n\\]",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Bramki jednokubitowe"
    ]
  },
  {
    "objectID": "labs/cw3.html#gra-w-obracanie-monety",
    "href": "labs/cw3.html#gra-w-obracanie-monety",
    "title": "Bramki jednokubitowe",
    "section": "Gra w obracanie monety",
    "text": "Gra w obracanie monety\nWykorzystując powyżej zdefiniowane bramki możemy zrealizowa następującą grę:\n\nW grze bierze udział dwóch graczy. Gracze dysponują monetą, której nie widzą w trakcie gry (np. jest zamknięta w pudełku). Natomiast wiedzą, że początkowo moneta ułożona jest orłem do góry (w stanie \\(\\ket{0}\\)) Gra polega na wykonaniu trzech ruchów na przemian. Każdy ruch polega na odwróceniu monety bądź pozostawieniu jej w takim stanie w jakim była. Gracze nie wiedzą jaki ruch wykonuje przeciwnik. Po ostatnim ruchu pudełko zostaje otwarte i gracze sprawdzają w jakiej pozycji jest moneta. Pierwszy gracz wygrywa jeśli moneta jest w pozycji orła, a drugi jeśli przeciwnie.\n\nSzansa wygranej wynosi dla każdego \\(50\\%\\) i jak można sprawdzic nie istnieje strategia wygrywająca.\nZweryfikuj powyższy wynik wykorzystując obwód kwantowy.\ndef klasycze_strategie():\n    wyniki = []\n    for ruch_1 in ['I','X']:\n        for ruch_2 in ['I','X']:\n            for ruch_3 in ['I','X']:\n                strategia = ruch_1 + ruch_2 + ruch_3\n                ob = obwod(strategia)\n                stats = sedzia(ob())\n                wyniki.append((strategia, stats))\n    return wyniki\nUtwórz odpowiedni obwód parametryzowany stringiem “strategia” oraz dodaj funkcję sędziego.",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Bramki jednokubitowe"
    ]
  },
  {
    "objectID": "labs/cw3.html#obracanie-monety-przypadek-kwantowy",
    "href": "labs/cw3.html#obracanie-monety-przypadek-kwantowy",
    "title": "Bramki jednokubitowe",
    "section": "Obracanie monety przypadek kwantowy",
    "text": "Obracanie monety przypadek kwantowy\nMożliwe operacje pozostawienia kubitu w takim samym stanie - bramka I, zmiany stanu na przeciwny bramka X.\nCzyli pierwszy gracz ustala pierwszą bramkę, drugi drugą i ponownie pierwszy trzecią. Otwarcie pudełka to pomiar stanu kubitu.\n\nPrzeanalizuj wynik dla sekwencji I X I\n\nA co jeśli pierwszy gracz wie, że działa na kubicie?\n\nCzy może sprawic on, że wygra zawsze? (skoro wie, że działa na kubicie może użyc innych bramek)\n\nzmodyfikuj kod obwodu i sprawdź strategię w której pierwszy gracz zawsze użyje dwóch bramek Hadamarda.\n\ndef kwantowa_strategia():\n    wyniki = []\n    for ruch_1 in ['H']:\n        for ruch_2 in ['I','X']:\n            for ruch_3 in ['H']:\n                strategia = ruch_1 + ruch_2 + ruch_3\n                ob = obwod(strategia)\n                stats = sedzia(ob())\n                wyniki.append((strategia, stats))\n    return wyniki",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Bramki jednokubitowe"
    ]
  },
  {
    "objectID": "labs/cw6.html",
    "href": "labs/cw6.html",
    "title": "Przykłady prostych modeli uczenia maszynowego",
    "section": "",
    "text": "import pennylane as qml \nimport pennylane.numpy as np \nimport matplotlib.pyplot as plt\n\nX = np.linspace(0, 2*np.pi , 10)\nX.requires_grad = False\n\nY = np.sin(X)\n\n\nX\n\n\nY\n\n\nX_test = np.linspace(0.2, 2*np.pi+0.2, 5)\nY_test = np.sin(X_test)\n\n\ndev = qml.device('default.qubit', wires=1)\n\n@qml.qnode(dev)\ndef qc(datapoint, params):\n    # zakodujemy dane w bramke RX \n    qml.RX(datapoint, wires=0)\n    # model to ogólna bramka unitarna zalezna od 3 parametrów\n    qml.Rot(params[0], params[1], params[2], wires=0)\n    # bedziemy zwracali wartosc oczekiwana operatora Z \n    return qml.expval(qml.PauliZ(wires=0))\n\ndef loss_func(predictions):\n    total_losses = 0 \n    for i in range(len(Y)):\n        output = Y[i]\n        prediction = predictions[i]\n        loss = (prediction - output)**2\n        total_losses += loss\n    return total_losses\n\ndef cost_fn(params):\n    predictions = [qc(x, params) for x in X]\n    cost = loss_func(predictions)\n    return cost\n\nopt = qml.GradientDescentOptimizer()\n\nparams = np.array([0.01, 0.1, 0.01], requires_grad=True)\n\n\nepochs = 100\n\nfor epoch in range(epochs):\n    params, prev_cost = opt.step_and_cost(cost_fn, params)\n    if (epoch+1)%10 == 0:\n        print(f\"Step = {epoch+1} Cost = {cost_fn(params)} for params: {params}\")\n\nStep = 10 Cost = 9.037222062479499 for params: [-0.14333094  0.32519527  0.01      ]\nStep = 20 Cost = 3.39452528591374 for params: [-0.5135331   0.96321395  0.01      ]\nStep = 30 Cost = 0.5405856987920626 for params: [-0.79676991  1.40502266  0.01      ]\nStep = 40 Cost = 0.18055568063658878 for params: [-0.9377581   1.52754136  0.01      ]\nStep = 50 Cost = 0.09683220912558343 for params: [-1.02350548  1.55910856  0.01      ]\nStep = 60 Cost = 0.06151965453001599 for params: [-1.08250661  1.56755217  0.01      ]\nStep = 70 Cost = 0.04255032144989283 for params: [-1.12615645  1.56987864  0.01      ]\nStep = 80 Cost = 0.031128244489378672 for params: [-1.16006661  1.57053313  0.01      ]\nStep = 90 Cost = 0.023728811931929196 for params: [-1.18735893  1.57072005  0.01      ]\nStep = 100 Cost = 0.0186699696065793 for params: [-1.20992122  1.57077404  0.01      ]\n\n\n\ntest_predictions = []\nfor x_test in X_test:\n    prediction = qc(x_test,params)\n    test_predictions.append(prediction)\n\nfig = plt.figure()\nax1 = fig.add_subplot(111)\n\nax1.scatter(X, Y, s=30, c='b', marker=\"s\", label='Train outputs')\nax1.scatter(X_test,Y_test, s=60, c='r', marker=\"o\", label='Test outputs')\nax1.scatter(X_test,test_predictions, s=30, c='k', marker=\"x\", label='Test predicitons')\nplt.xlabel(\"Inputs\")\nplt.ylabel(\"Outputs\")\nplt.title(\"QML results\")\n\nplt.legend(loc='upper right');\nplt.show()",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Przykłady prostych modeli uczenia maszynowego"
    ]
  },
  {
    "objectID": "labs/cw6.html#model-regresji",
    "href": "labs/cw6.html#model-regresji",
    "title": "Przykłady prostych modeli uczenia maszynowego",
    "section": "",
    "text": "import pennylane as qml \nimport pennylane.numpy as np \nimport matplotlib.pyplot as plt\n\nX = np.linspace(0, 2*np.pi , 10)\nX.requires_grad = False\n\nY = np.sin(X)\n\n\nX\n\n\nY\n\n\nX_test = np.linspace(0.2, 2*np.pi+0.2, 5)\nY_test = np.sin(X_test)\n\n\ndev = qml.device('default.qubit', wires=1)\n\n@qml.qnode(dev)\ndef qc(datapoint, params):\n    # zakodujemy dane w bramke RX \n    qml.RX(datapoint, wires=0)\n    # model to ogólna bramka unitarna zalezna od 3 parametrów\n    qml.Rot(params[0], params[1], params[2], wires=0)\n    # bedziemy zwracali wartosc oczekiwana operatora Z \n    return qml.expval(qml.PauliZ(wires=0))\n\ndef loss_func(predictions):\n    total_losses = 0 \n    for i in range(len(Y)):\n        output = Y[i]\n        prediction = predictions[i]\n        loss = (prediction - output)**2\n        total_losses += loss\n    return total_losses\n\ndef cost_fn(params):\n    predictions = [qc(x, params) for x in X]\n    cost = loss_func(predictions)\n    return cost\n\nopt = qml.GradientDescentOptimizer()\n\nparams = np.array([0.01, 0.1, 0.01], requires_grad=True)\n\n\nepochs = 100\n\nfor epoch in range(epochs):\n    params, prev_cost = opt.step_and_cost(cost_fn, params)\n    if (epoch+1)%10 == 0:\n        print(f\"Step = {epoch+1} Cost = {cost_fn(params)} for params: {params}\")\n\nStep = 10 Cost = 9.037222062479499 for params: [-0.14333094  0.32519527  0.01      ]\nStep = 20 Cost = 3.39452528591374 for params: [-0.5135331   0.96321395  0.01      ]\nStep = 30 Cost = 0.5405856987920626 for params: [-0.79676991  1.40502266  0.01      ]\nStep = 40 Cost = 0.18055568063658878 for params: [-0.9377581   1.52754136  0.01      ]\nStep = 50 Cost = 0.09683220912558343 for params: [-1.02350548  1.55910856  0.01      ]\nStep = 60 Cost = 0.06151965453001599 for params: [-1.08250661  1.56755217  0.01      ]\nStep = 70 Cost = 0.04255032144989283 for params: [-1.12615645  1.56987864  0.01      ]\nStep = 80 Cost = 0.031128244489378672 for params: [-1.16006661  1.57053313  0.01      ]\nStep = 90 Cost = 0.023728811931929196 for params: [-1.18735893  1.57072005  0.01      ]\nStep = 100 Cost = 0.0186699696065793 for params: [-1.20992122  1.57077404  0.01      ]\n\n\n\ntest_predictions = []\nfor x_test in X_test:\n    prediction = qc(x_test,params)\n    test_predictions.append(prediction)\n\nfig = plt.figure()\nax1 = fig.add_subplot(111)\n\nax1.scatter(X, Y, s=30, c='b', marker=\"s\", label='Train outputs')\nax1.scatter(X_test,Y_test, s=60, c='r', marker=\"o\", label='Test outputs')\nax1.scatter(X_test,test_predictions, s=30, c='k', marker=\"x\", label='Test predicitons')\nplt.xlabel(\"Inputs\")\nplt.ylabel(\"Outputs\")\nplt.title(\"QML results\")\n\nplt.legend(loc='upper right');\nplt.show()",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Przykłady prostych modeli uczenia maszynowego"
    ]
  },
  {
    "objectID": "labs/cw6.html#variational-quantum-classifiers",
    "href": "labs/cw6.html#variational-quantum-classifiers",
    "title": "Przykłady prostych modeli uczenia maszynowego",
    "section": "Variational quantum classifiers",
    "text": "Variational quantum classifiers\nObwód kwantowy, który można trenować na podstawie danych z targetem w cely klasyfikacji nowej próby.\nPublikacje - przykład wariacyjnego algorytmu polegającego na optymalizacji poprzez ewaluacje funkcji parity\nDefinicja funkcji - jej wartość równa się 1 tylko gdy zmienna na której jest stosowana posiada nieparzystą liczbę jedynek. Porównaj z bramką XOR.\nPonieważ funkjca ta przyjmuje tylko ciągi binarne (bit string) możemy rozpatrzyć przykład w którym nasze dane będą zapisane w takim formacie.\nJest to tak zwane kodowanie binarne za pomocą bazwy (basis encoding).\n\nimport pennylane as qml\nimport pennylane.numpy as np\nfrom pennylane.optimize import NesterovMomentumOptimizer\n\n\ndev = qml.device('default.qubit')\n\nAlgorytmy wariacyjne to zazwyczaj jeden (elementarny) obwód, który można wiele razy powtarzać tworząc tzw layer lub block.\n\nn_qubits = 4\ndef layer(layer_weights):\n    for wire in range(n_qubits):\n        qml.Rot(*layer_weights[wire], wires=wire)\n    \n    for wires in ([0,1],[1,2],[2,3],[3,0]):\n        qml.CNOT(wires)\n\nOprócz części modelu musimy mieć możliwość kodować nasze dane. W tym przykładzie będą to bitstringi, które chcemy zakodować w stanie kubitów.\n\\[ x = 0101 \\to \\ket{\\psi} = \\ket{0101}\\]\nMożemy oczywiście sami uzupełniać kubity korzystając z bramki \\(X\\). Lepszym sposobem będzie użycie qml.BasisState(x, wires) dla której wektor wejściowy x to lista złożona ze zbioru \\(\\{0,1\\}\\)\n\ndef state_preparation(x):\n    qml.BasisState(x, wires=range(4))\n\n\n@qml.qnode(dev)\ndef circ(weigths, x):\n    state_preparation(x)\n\n    for layer_weights in weigths:\n        layer(layer_weights=layer_weights)\n\n    return qml.expval(qml.PauliZ(0))\n\nMożemy dodać również parametr klasyczny bias.\n\ndef variational_classifier(weights, bias, x):\n    return circ(weights,x) + bias\n\nObliczenie kosztu\n\ndef loss_fn(labels, predictions):\n    return np.mean((labels - qml.math.stack(predictions))**2)\n\ndef accuracy(labels, predictions):\n    acc = sum(abs(l-p) &lt; 1e-5 for l, p in zip(labels,predictions))\n    acc = acc / len(labels)\n    return acc\n\ndef cost(weights, bias, X, Y):\n    predictions = [variational_classifier(weights, bias, x) for x in X]\n    return loss_fn(Y, predictions)\n\n\ntrain = \"\"\"0 0 0 1 1\n0 0 1 0 1\n0 1 0 0 1\n0 1 0 1 0\n0 1 1 0 0\n0 1 1 1 1\n1 0 0 0 1\n1 0 0 1 0\n1 0 1 1 1\n1 1 1 1 0\"\"\"\n\ntest = \"\"\"0 0 0 0 0\n0 0 1 1 0\n1 0 1 0 0\n1 1 1 0 1\n1 1 0 0 0\n1 1 0 1 1\"\"\"\n\n\ndata= np.loadtxt('parity_train.txt', dtype=int)\n\n\nX = np.array(data[:, :-1])\nY = np.array(data[:, -1])\nY = Y*2 -1\n\n\nfor x,y in zip(X, Y):\n    print(f\"x = {x}, y = {y}\")\n\nx = [0 0 0 1], y = 1\nx = [0 0 1 0], y = 1\nx = [0 1 0 0], y = 1\nx = [0 1 0 1], y = -1\nx = [0 1 1 0], y = -1\nx = [0 1 1 1], y = 1\nx = [1 0 0 0], y = 1\nx = [1 0 0 1], y = -1\nx = [1 0 1 1], y = 1\nx = [1 1 1 1], y = -1\n\n\n\nnp.random.seed(0)\nnum_qubits = 4\nnum_layers = 2\nweights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\nbias_init = np.array(0.0, requires_grad=True)\n\nprint(\"Weights:\", weights_init)\nprint(\"Bias: \", bias_init)\n\nWeights: [[[ 0.01764052  0.00400157  0.00978738]\n  [ 0.02240893  0.01867558 -0.00977278]\n  [ 0.00950088 -0.00151357 -0.00103219]\n  [ 0.00410599  0.00144044  0.01454274]]\n\n [[ 0.00761038  0.00121675  0.00443863]\n  [ 0.00333674  0.01494079 -0.00205158]\n  [ 0.00313068 -0.00854096 -0.0255299 ]\n  [ 0.00653619  0.00864436 -0.00742165]]]\nBias:  0.0\n\n\n\nopt = NesterovMomentumOptimizer(0.5)\nbatch_size = 5\n\n\nweights = weights_init\nbias = bias_init\nfor it in range(100):\n\n    # Update the weights by one optimizer step, using only a limited batch of data\n    batch_index = np.random.randint(0, len(X), (batch_size,))\n    X_batch = X[batch_index]\n    Y_batch = Y[batch_index]\n    weights, bias = opt.step(cost, weights, bias, X=X_batch, Y=Y_batch)\n\n    # Compute accuracy\n    predictions = [np.sign(variational_classifier(weights, bias, x)) for x in X]\n\n    current_cost = cost(weights, bias, X, Y)\n    acc = accuracy(Y, predictions)\n\n    print(f\"Iter: {it+1:4d} | Cost: {current_cost:0.7f} | Accuracy: {acc:0.7f}\")\n\nIter:    1 | Cost: 2.3147651 | Accuracy: 0.5000000\nIter:    2 | Cost: 1.9664866 | Accuracy: 0.5000000\nIter:    3 | Cost: 1.9208589 | Accuracy: 0.5000000\nIter:    4 | Cost: 2.6276126 | Accuracy: 0.5000000\nIter:    5 | Cost: 0.9323119 | Accuracy: 0.6000000\nIter:    6 | Cost: 1.1903549 | Accuracy: 0.5000000\nIter:    7 | Cost: 2.0508989 | Accuracy: 0.4000000\nIter:    8 | Cost: 1.1275531 | Accuracy: 0.6000000\nIter:    9 | Cost: 1.1659803 | Accuracy: 0.6000000\nIter:   10 | Cost: 1.1349618 | Accuracy: 0.6000000\nIter:   11 | Cost: 0.9994063 | Accuracy: 0.6000000\nIter:   12 | Cost: 1.0812559 | Accuracy: 0.6000000\nIter:   13 | Cost: 1.2863155 | Accuracy: 0.6000000\nIter:   14 | Cost: 2.2658259 | Accuracy: 0.4000000\nIter:   15 | Cost: 1.1323724 | Accuracy: 0.6000000\nIter:   16 | Cost: 1.3439737 | Accuracy: 0.8000000\nIter:   17 | Cost: 2.0076168 | Accuracy: 0.6000000\nIter:   18 | Cost: 1.2685760 | Accuracy: 0.5000000\nIter:   19 | Cost: 1.6762475 | Accuracy: 0.5000000\nIter:   20 | Cost: 1.1868237 | Accuracy: 0.6000000\nIter:   21 | Cost: 1.4784687 | Accuracy: 0.6000000\nIter:   22 | Cost: 1.4599473 | Accuracy: 0.6000000\nIter:   23 | Cost: 0.9573269 | Accuracy: 0.6000000\nIter:   24 | Cost: 1.1657424 | Accuracy: 0.5000000\nIter:   25 | Cost: 1.0877087 | Accuracy: 0.4000000\nIter:   26 | Cost: 1.1683687 | Accuracy: 0.6000000\nIter:   27 | Cost: 2.1141689 | Accuracy: 0.6000000\nIter:   28 | Cost: 1.0272966 | Accuracy: 0.5000000\nIter:   29 | Cost: 0.9664085 | Accuracy: 0.5000000\nIter:   30 | Cost: 1.1287654 | Accuracy: 0.6000000\nIter:   31 | Cost: 1.4202360 | Accuracy: 0.4000000\nIter:   32 | Cost: 1.1286000 | Accuracy: 0.5000000\nIter:   33 | Cost: 1.9594333 | Accuracy: 0.4000000\nIter:   34 | Cost: 1.2811832 | Accuracy: 0.4000000\nIter:   35 | Cost: 0.8522775 | Accuracy: 0.7000000\nIter:   36 | Cost: 1.4765281 | Accuracy: 0.6000000\nIter:   37 | Cost: 0.9603287 | Accuracy: 0.6000000\nIter:   38 | Cost: 1.6031314 | Accuracy: 0.6000000\nIter:   39 | Cost: 1.1700888 | Accuracy: 0.4000000\nIter:   40 | Cost: 1.7571779 | Accuracy: 0.4000000\nIter:   41 | Cost: 1.9608116 | Accuracy: 0.6000000\nIter:   42 | Cost: 2.0802752 | Accuracy: 0.6000000\nIter:   43 | Cost: 1.1904884 | Accuracy: 0.3000000\nIter:   44 | Cost: 0.9941585 | Accuracy: 0.6000000\nIter:   45 | Cost: 1.0709609 | Accuracy: 0.5000000\nIter:   46 | Cost: 0.9780625 | Accuracy: 0.6000000\nIter:   47 | Cost: 1.1573709 | Accuracy: 0.6000000\nIter:   48 | Cost: 1.0235239 | Accuracy: 0.6000000\nIter:   49 | Cost: 1.2842469 | Accuracy: 0.5000000\nIter:   50 | Cost: 0.8549226 | Accuracy: 0.6000000\nIter:   51 | Cost: 0.5136787 | Accuracy: 1.0000000\nIter:   52 | Cost: 0.2488031 | Accuracy: 1.0000000\nIter:   53 | Cost: 0.0461277 | Accuracy: 1.0000000\nIter:   54 | Cost: 0.0293518 | Accuracy: 1.0000000\nIter:   55 | Cost: 0.0205454 | Accuracy: 1.0000000\nIter:   56 | Cost: 0.0352514 | Accuracy: 1.0000000\nIter:   57 | Cost: 0.0576767 | Accuracy: 1.0000000\nIter:   58 | Cost: 0.0291305 | Accuracy: 1.0000000\nIter:   59 | Cost: 0.0127137 | Accuracy: 1.0000000\nIter:   60 | Cost: 0.0058108 | Accuracy: 1.0000000\nIter:   61 | Cost: 0.0018002 | Accuracy: 1.0000000\nIter:   62 | Cost: 0.0014089 | Accuracy: 1.0000000\nIter:   63 | Cost: 0.0017489 | Accuracy: 1.0000000\nIter:   64 | Cost: 0.0021282 | Accuracy: 1.0000000\nIter:   65 | Cost: 0.0029876 | Accuracy: 1.0000000\nIter:   66 | Cost: 0.0035331 | Accuracy: 1.0000000\nIter:   67 | Cost: 0.0035540 | Accuracy: 1.0000000\nIter:   68 | Cost: 0.0025639 | Accuracy: 1.0000000\nIter:   69 | Cost: 0.0019459 | Accuracy: 1.0000000\nIter:   70 | Cost: 0.0015856 | Accuracy: 1.0000000\nIter:   71 | Cost: 0.0008439 | Accuracy: 1.0000000\nIter:   72 | Cost: 0.0005960 | Accuracy: 1.0000000\nIter:   73 | Cost: 0.0003122 | Accuracy: 1.0000000\nIter:   74 | Cost: 0.0002446 | Accuracy: 1.0000000\nIter:   75 | Cost: 0.0001745 | Accuracy: 1.0000000\nIter:   76 | Cost: 0.0001215 | Accuracy: 1.0000000\nIter:   77 | Cost: 0.0001141 | Accuracy: 1.0000000\nIter:   78 | Cost: 0.0001538 | Accuracy: 1.0000000\nIter:   79 | Cost: 0.0001871 | Accuracy: 1.0000000\nIter:   80 | Cost: 0.0001330 | Accuracy: 1.0000000\nIter:   81 | Cost: 0.0001380 | Accuracy: 1.0000000\nIter:   82 | Cost: 0.0001336 | Accuracy: 1.0000000\nIter:   83 | Cost: 0.0001483 | Accuracy: 1.0000000\nIter:   84 | Cost: 0.0001234 | Accuracy: 1.0000000\nIter:   85 | Cost: 0.0001359 | Accuracy: 1.0000000\nIter:   86 | Cost: 0.0001268 | Accuracy: 1.0000000\nIter:   87 | Cost: 0.0002270 | Accuracy: 1.0000000\nIter:   88 | Cost: 0.0000865 | Accuracy: 1.0000000\nIter:   89 | Cost: 0.0000774 | Accuracy: 1.0000000\nIter:   90 | Cost: 0.0000759 | Accuracy: 1.0000000\nIter:   91 | Cost: 0.0000607 | Accuracy: 1.0000000\nIter:   92 | Cost: 0.0000523 | Accuracy: 1.0000000\nIter:   93 | Cost: 0.0000536 | Accuracy: 1.0000000\nIter:   94 | Cost: 0.0000444 | Accuracy: 1.0000000\nIter:   95 | Cost: 0.0000384 | Accuracy: 1.0000000\nIter:   96 | Cost: 0.0000497 | Accuracy: 1.0000000\nIter:   97 | Cost: 0.0000263 | Accuracy: 1.0000000\nIter:   98 | Cost: 0.0000229 | Accuracy: 1.0000000\nIter:   99 | Cost: 0.0000339 | Accuracy: 1.0000000\nIter:  100 | Cost: 0.0000174 | Accuracy: 1.0000000\n\n\n\ndata = np.loadtxt(\"parity_test.txt\", dtype=int)\nX_test = np.array(data[:, :-1])\nY_test = np.array(data[:, -1])\nY_test = Y_test * 2 - 1  # shift label from {0, 1} to {-1, 1}\n\npredictions_test = [np.sign(variational_classifier(weights, bias, x)) for x in X_test]\n\nfor x,y,p in zip(X_test, Y_test, predictions_test):\n    print(f\"x = {x}, y = {y}, pred = {p}\")\n\nacc_test = accuracy(Y_test, predictions_test)\nprint(\"Accuracy on unseen data:\", acc_test)\n\nx = [0 0 0 0], y = -1, pred = -1.0\nx = [0 0 1 1], y = -1, pred = -1.0\nx = [1 0 1 0], y = -1, pred = -1.0\nx = [1 1 1 0], y = 1, pred = 1.0\nx = [1 1 0 0], y = -1, pred = -1.0\nx = [1 1 0 1], y = 1, pred = 1.0\nAccuracy on unseen data: 1.0\n\n\nInne kodowanie bitowe\n\nn_wires = 4\ndev = qml.device('default.qubit', wires=n_wires)\n\n@qml.qnode(dev)\ndef basis_circuit_1(features):\n    #qml.BasisEmbedding(features=features, wires=range(len(features)))\n    for i in range(len(features)):\n        if features[i] == 1:\n            qml.X(i)\n    qml.Barrier()\n    qml.Hadamard(1)\n    qml.CNOT([1,3])\n    return qml.state()\n\n\nX = [1,0,1,1]\nimport matplotlib.pyplot as plt\nqml.drawer.use_style(\"pennylane_sketch\")\nfig, ax = qml.draw_mpl(basis_circuit_1)(X)\nplt.show()\n\n\nstate = basis_circuit_1(X)\nstate.real\n\n\n@qml.qnode(dev)\ndef basis_circuit_2(features):\n    for i in range(len(features)):\n        if features[i] == 1: qml.X(i)\n    return [qml.expval(qml.PauliZ(m)) for m in range(len(features))]\n\nX = [1, 0, 1, 1]\n\nimport matplotlib.pyplot as plt\nqml.drawer.use_style(\"pennylane_sketch\")\nfig, ax = qml.draw_mpl(basis_circuit_2)(X)\nplt.show()\n\n\nexpvals = basis_circuit_2(X)\nprint(f'\\nExpectation values: {np.array(expvals)}\\n')\n\n\n@qml.qnode(dev)\ndef basis_circuit_3(features):\n    for i in range(len(features)):\n        if features[i] == 1: qml.X(i)\n    qml.Barrier()\n    qml.Hadamard(1)\n    qml.CNOT([1, 3])\n    return qml.probs(range(len(features)))\n\n\nimport matplotlib.pyplot as plt\nqml.drawer.use_style(\"pennylane_sketch\")\nfig, ax = qml.draw_mpl(basis_circuit_3)(X)\nplt.show()\n\nprobs = basis_circuit_3(X)\nprint('\\n', probs, '\\n')\n\n\n@qml.qnode(dev)\ndef basis_circuit_4(features):\n    for i in range(len(features)):\n        if features[i] == 1: qml.X(i)\n    qml.Barrier()\n    return [qml.probs(range(len(features) // 2)), qml.probs(range(len(features) // 2, len(features)))]\n\n\nprobs = basis_circuit_4(X)\nprint('\\n', probs, '\\n')",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Przykłady prostych modeli uczenia maszynowego"
    ]
  },
  {
    "objectID": "labs/cw6.html#prawdziwe-dane",
    "href": "labs/cw6.html#prawdziwe-dane",
    "title": "Przykłady prostych modeli uczenia maszynowego",
    "section": "prawdziwe dane",
    "text": "prawdziwe dane\nPrzygotowanie stanu dla prawdziwych danych nie zawsze jest tak proste i oczywiste jak w przypadku bitstringow.\nKażdy zbiór zmiennych musi zostać przetworzony na zbiór kątów dla odpowiednich bramek.\n\ndef get_angles(x):\n    beta0 = 2 * np.arcsin(np.sqrt(x[1] ** 2) / np.sqrt(x[0] ** 2 + x[1] ** 2 + 1e-12))\n    beta1 = 2 * np.arcsin(np.sqrt(x[3] ** 2) / np.sqrt(x[2] ** 2 + x[3] ** 2 + 1e-12))\n    beta2 = 2 * np.arcsin(np.linalg.norm(x[2:]) / np.linalg.norm(x))\n\n    return np.array([beta2, -beta1 / 2, beta1 / 2, -beta0 / 2, beta0 / 2])\n\n\ndef state_preparation(a):\n    qml.RY(a[0], wires=0)\n\n    qml.CNOT(wires=[0, 1])\n    qml.RY(a[1], wires=1)\n    qml.CNOT(wires=[0, 1])\n    qml.RY(a[2], wires=1)\n\n    qml.PauliX(wires=0)\n    qml.CNOT(wires=[0, 1])\n    qml.RY(a[3], wires=1)\n    qml.CNOT(wires=[0, 1])\n    qml.RY(a[4], wires=1)\n    qml.PauliX(wires=0)\n\n\nx = np.array([0.53896774, 0.79503606, 0.27826503, 0.0], requires_grad=False)\nang = get_angles(x)\n\n\n@qml.qnode(dev)\ndef test(angles):\n    state_preparation(angles)\n\n    return qml.state()\n\n\nstate = test(ang)\n\nprint(\"x               : \", np.round(x, 6))\nprint(\"angles          : \", np.round(ang, 6))\nprint(\"amplitude vector: \", np.round(np.real(state), 6))\n\nx               :  [0.538968 0.795036 0.278265 0.      ]\nangles          :  [ 0.563975 -0.        0.       -0.975046  0.975046]\namplitude vector:  [ 0.538968  0.795036  0.278265 -0.      ]\n\n\n\ndef square_loss(labels, predictions):\n    # We use a call to qml.math.stack to allow subtracting the arrays directly\n    return np.mean((labels - qml.math.stack(predictions)) ** 2)\n\ndef layer(layer_weights):\n    for wire in range(2):\n        qml.Rot(*layer_weights[wire], wires=wire)\n    qml.CNOT(wires=[0, 1])\n\n\ndef cost(weights, bias, X, Y):\n    # Transpose the batch of input data in order to make the indexing\n    # in state_preparation work\n    predictions = variational_classifier(weights, bias, X.T)\n    return square_loss(Y, predictions)\n\n\ndata = np.loadtxt(\"iris.txt\")\nX = data[:, 0:2]\nprint(f\"First X sample (original)  : {X[0]}\")\n\n# pad the vectors to size 2^2=4 with constant values\npadding = np.ones((len(X), 2)) * 0.1\nX_pad = np.c_[X, padding]\nprint(f\"First X sample (padded)    : {X_pad[0]}\")\n\n# normalize each input\nnormalization = np.sqrt(np.sum(X_pad**2, -1))\nX_norm = (X_pad.T / normalization).T\nprint(f\"First X sample (normalized): {X_norm[0]}\")\n\n# the angles for state preparation are the features\nfeatures = np.array([get_angles(x) for x in X_norm], requires_grad=False)\nprint(f\"First features sample      : {features[0]}\")\n\nY = data[:, -1]\n\nFirst X sample (original)  : [0.4  0.75]\nFirst X sample (padded)    : [0.4  0.75 0.1  0.1 ]\nFirst X sample (normalized): [0.46420708 0.87038828 0.11605177 0.11605177]\nFirst features sample      : [ 0.32973573 -0.78539816  0.78539816 -1.080839    1.080839  ]\n\n\n\nimport matplotlib.pyplot as plt\n\nplt.figure()\nplt.scatter(X[:, 0][Y == 1], X[:, 1][Y == 1], c=\"b\", marker=\"o\", ec=\"k\")\nplt.scatter(X[:, 0][Y == -1], X[:, 1][Y == -1], c=\"r\", marker=\"o\", ec=\"k\")\nplt.title(\"Original data\")\nplt.show()\n\nplt.figure()\ndim1 = 0\ndim2 = 1\nplt.scatter(X_norm[:, dim1][Y == 1], X_norm[:, dim2][Y == 1], c=\"b\", marker=\"o\", ec=\"k\")\nplt.scatter(X_norm[:, dim1][Y == -1], X_norm[:, dim2][Y == -1], c=\"r\", marker=\"o\", ec=\"k\")\nplt.title(f\"Padded and normalised data (dims {dim1} and {dim2})\")\nplt.show()\n\nplt.figure()\ndim1 = 0\ndim2 = 3\nplt.scatter(features[:, dim1][Y == 1], features[:, dim2][Y == 1], c=\"b\", marker=\"o\", ec=\"k\")\nplt.scatter(features[:, dim1][Y == -1], features[:, dim2][Y == -1], c=\"r\", marker=\"o\", ec=\"k\")\nplt.title(f\"Feature vectors (dims {dim1} and {dim2})\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnp.random.seed(0)\nnum_data = len(Y)\nnum_train = int(0.75 * num_data)\nindex = np.random.permutation(range(num_data))\nfeats_train = features[index[:num_train]]\nY_train = Y[index[:num_train]]\nfeats_val = features[index[num_train:]]\nY_val = Y[index[num_train:]]\n\n# We need these later for plotting\nX_train = X[index[:num_train]]\nX_val = X[index[num_train:]]\n\n\nnum_qubits = 2\nnum_layers = 6\n\nweights_init = 0.01 * np.random.randn(num_layers, num_qubits, 3, requires_grad=True)\nbias_init = np.array(0.0, requires_grad=True)\n\n\nopt = NesterovMomentumOptimizer(0.01)\nbatch_size = 5\n\n# train the variational classifier\nweights = weights_init\nbias = bias_init\nfor it in range(60):\n    # Update the weights by one optimizer step\n    batch_index = np.random.randint(0, num_train, (batch_size,))\n    feats_train_batch = feats_train[batch_index]\n    Y_train_batch = Y_train[batch_index]\n    weights, bias, _, _ = opt.step(cost, weights, bias, feats_train_batch, Y_train_batch)\n\n    # Compute predictions on train and validation set\n    predictions_train = np.sign(variational_classifier(weights, bias, feats_train.T))\n    predictions_val = np.sign(variational_classifier(weights, bias, feats_val.T))\n\n    # Compute accuracy on train and validation set\n    acc_train = accuracy(Y_train, predictions_train)\n    acc_val = accuracy(Y_val, predictions_val)\n\n    if (it + 1) % 2 == 0:\n        _cost = cost(weights, bias, features, Y)\n        print(\n            f\"Iter: {it + 1:5d} | Cost: {_cost:0.7f} | \"\n            f\"Acc train: {acc_train:0.7f} | Acc validation: {acc_val:0.7f}\"\n        )\n\nIter:     2 | Cost: 1.6589456 | Acc train: 0.4800000 | Acc validation: 0.5600000\nIter:     4 | Cost: 1.2054273 | Acc train: 0.4933333 | Acc validation: 0.5600000\nIter:     6 | Cost: 0.9740740 | Acc train: 0.4933333 | Acc validation: 0.7200000\nIter:     8 | Cost: 0.9660872 | Acc train: 0.6400000 | Acc validation: 0.6400000\nIter:    10 | Cost: 0.9569019 | Acc train: 0.6000000 | Acc validation: 0.6000000\nIter:    12 | Cost: 0.9445863 | Acc train: 0.4933333 | Acc validation: 0.7200000\nIter:    14 | Cost: 1.0339978 | Acc train: 0.4800000 | Acc validation: 0.5600000\nIter:    16 | Cost: 1.0774217 | Acc train: 0.4933333 | Acc validation: 0.5600000\nIter:    18 | Cost: 0.9984426 | Acc train: 0.4800000 | Acc validation: 0.5600000\nIter:    20 | Cost: 0.8975279 | Acc train: 0.5600000 | Acc validation: 0.7600000\nIter:    22 | Cost: 0.8451699 | Acc train: 0.6400000 | Acc validation: 0.6400000\nIter:    24 | Cost: 0.8337489 | Acc train: 0.5600000 | Acc validation: 0.5200000\nIter:    26 | Cost: 0.7832025 | Acc train: 0.6000000 | Acc validation: 0.6000000\nIter:    28 | Cost: 0.7397515 | Acc train: 0.6133333 | Acc validation: 0.6000000\nIter:    30 | Cost: 0.6690522 | Acc train: 0.6666667 | Acc validation: 0.6400000\nIter:    32 | Cost: 0.5640186 | Acc train: 0.8266667 | Acc validation: 0.8000000\nIter:    34 | Cost: 0.4765597 | Acc train: 0.8933333 | Acc validation: 0.8800000\nIter:    36 | Cost: 0.4144135 | Acc train: 0.9200000 | Acc validation: 0.9600000\nIter:    38 | Cost: 0.3569566 | Acc train: 0.9600000 | Acc validation: 1.0000000\nIter:    40 | Cost: 0.3186159 | Acc train: 0.9866667 | Acc validation: 1.0000000\nIter:    42 | Cost: 0.2853043 | Acc train: 0.9866667 | Acc validation: 1.0000000\nIter:    44 | Cost: 0.2652725 | Acc train: 1.0000000 | Acc validation: 1.0000000\nIter:    46 | Cost: 0.2525848 | Acc train: 1.0000000 | Acc validation: 1.0000000\nIter:    48 | Cost: 0.2444278 | Acc train: 1.0000000 | Acc validation: 1.0000000\nIter:    50 | Cost: 0.2436316 | Acc train: 0.9866667 | Acc validation: 1.0000000\nIter:    52 | Cost: 0.2376316 | Acc train: 1.0000000 | Acc validation: 1.0000000\nIter:    54 | Cost: 0.2307475 | Acc train: 1.0000000 | Acc validation: 1.0000000\nIter:    56 | Cost: 0.2341245 | Acc train: 1.0000000 | Acc validation: 1.0000000\nIter:    58 | Cost: 0.2292663 | Acc train: 1.0000000 | Acc validation: 1.0000000\nIter:    60 | Cost: 0.2241948 | Acc train: 1.0000000 | Acc validation: 1.0000000\n\n\n\nplt.figure()\ncm = plt.cm.RdBu\n\n# make data for decision regions\nxx, yy = np.meshgrid(np.linspace(0.0, 1.5, 30), np.linspace(0.0, 1.5, 30))\nX_grid = [np.array([x, y]) for x, y in zip(xx.flatten(), yy.flatten())]\n\n# preprocess grid points like data inputs above\npadding = 0.1 * np.ones((len(X_grid), 2))\nX_grid = np.c_[X_grid, padding]  # pad each input\nnormalization = np.sqrt(np.sum(X_grid**2, -1))\nX_grid = (X_grid.T / normalization).T  # normalize each input\nfeatures_grid = np.array([get_angles(x) for x in X_grid])  # angles are new features\npredictions_grid = variational_classifier(weights, bias, features_grid.T)\nZ = np.reshape(predictions_grid, xx.shape)\n\n# plot decision regions\nlevels = np.arange(-1, 1.1, 0.1)\ncnt = plt.contourf(xx, yy, Z, levels=levels, cmap=cm, alpha=0.8, extend=\"both\")\nplt.contour(xx, yy, Z, levels=[0.0], colors=(\"black\",), linestyles=(\"--\",), linewidths=(0.8,))\nplt.colorbar(cnt, ticks=[-1, 0, 1])\n\n# plot data\nfor color, label in zip([\"b\", \"r\"], [1, -1]):\n    plot_x = X_train[:, 0][Y_train == label]\n    plot_y = X_train[:, 1][Y_train == label]\n    plt.scatter(plot_x, plot_y, c=color, marker=\"o\", ec=\"k\", label=f\"class {label} train\")\n    plot_x = (X_val[:, 0][Y_val == label],)\n    plot_y = (X_val[:, 1][Y_val == label],)\n    plt.scatter(plot_x, plot_y, c=color, marker=\"^\", ec=\"k\", label=f\"class {label} validation\")\n\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nJeszcze inaczej\n\nimport numpy as np\nimport torch\nfrom torch.nn.functional import relu\n\nfrom sklearn.svm import SVC\nfrom sklearn.datasets import load_iris\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nimport pennylane as qml\nfrom pennylane.templates import AngleEmbedding, StronglyEntanglingLayers\n\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\n\nX, y = load_iris(return_X_y=True)\n\n# pick inputs and labels from the first two classes only,\n# corresponding to the first 100 samples\nX = X[:100]\ny = y[:100]\n\n# scaling the inputs is important since the embedding we use is periodic\nscaler = StandardScaler().fit(X)\nX_scaled = scaler.transform(X)\n\n# scaling the labels to -1, 1 is important for the SVM and the\n# definition of a hinge loss\ny_scaled = 2 * (y - 0.5)\n\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled)\n\n\nn_qubits = len(X_train[0])\nn_qubits\n\n4\n\n\n\ndev_kernel = qml.device(\"default.qubit\", wires=n_qubits)\n\nprojector = np.zeros((2 ** n_qubits, 2 ** n_qubits))\nprojector[0, 0] = 1\n\n@qml.qnode(dev_kernel)\ndef kernel(x1, x2):\n    \"\"\"The quantum kernel.\"\"\"\n    AngleEmbedding(x1, wires=range(n_qubits))\n    qml.adjoint(AngleEmbedding)(x2, wires=range(n_qubits))\n    return qml.expval(qml.Hermitian(projector, wires=range(n_qubits)))\n\n\nkernel(X_train[0], X_train[0])\n\ntensor(1., requires_grad=True)\n\n\n\ndef kernel_matrix(A, B):\n    \"\"\"Compute the matrix whose entries are the kernel\n       evaluated on pairwise data from sets A and B.\"\"\"\n    return np.array([[kernel(a, b) for b in B] for a in A])\n\n\nsvm = SVC(kernel=kernel_matrix).fit(X_train, y_train)\n\n\nwith dev_kernel.tracker:\n    predictions = svm.predict(X_test)\n    accuracy_score(predictions, y_test)\n\nale mozna tez tak\n\n\n@qml.qnode(dev, diff_method=\"parameter-shift\")\ndef quantum_model(x, params):\n    \"\"\"A variational quantum model.\"\"\"\n\n    # embedding\n    AngleEmbedding(x, wires=range(n_qubits))\n\n    # trainable measurement\n    StronglyEntanglingLayers(params, wires=range(n_qubits))\n    return qml.expval(qml.PauliZ(0))\n\ndef quantum_model_plus_bias(x, params, bias):\n    \"\"\"Adding a bias.\"\"\"\n    return quantum_model(x, params) + bias\n\ndef hinge_loss(predictions, targets):\n    \"\"\"Implements the hinge loss.\"\"\"\n    all_ones = torch.ones_like(targets)\n    hinge_loss = all_ones - predictions * targets\n    # trick: since the max(0,x) function is not differentiable,\n    # use the mathematically equivalent relu instead\n    hinge_loss = relu(hinge_loss)\n    return hinge_loss\n\n\ndef quantum_model_train(n_layers, steps, batch_size):\n    \"\"\"Train the quantum model defined above.\"\"\"\n\n    params = np.random.random((n_layers, n_qubits, 3))\n    params_torch = torch.tensor(params, requires_grad=True)\n    bias_torch = torch.tensor(0.0)\n\n    opt = torch.optim.Adam([params_torch, bias_torch], lr=0.1)\n\n    loss_history = []\n    for i in range(steps):\n\n        batch_ids = np.random.choice(len(X_train), batch_size)\n\n        X_batch = X_train[batch_ids]\n        y_batch = y_train[batch_ids]\n\n        X_batch_torch = torch.tensor(X_batch, requires_grad=False)\n        y_batch_torch = torch.tensor(y_batch, requires_grad=False)\n\n        def closure():\n            opt.zero_grad()\n            preds = torch.stack(\n                [quantum_model_plus_bias(x, params_torch, bias_torch) for x in X_batch_torch]\n            )\n            loss = torch.mean(hinge_loss(preds, y_batch_torch))\n\n            # bookkeeping\n            current_loss = loss.detach().numpy().item()\n            loss_history.append(current_loss)\n            if i % 10 == 0:\n                print(\"step\", i, \", loss\", current_loss)\n\n            loss.backward()\n            return loss\n\n        opt.step(closure)\n\n    return params_torch, bias_torch, loss_history\n\n\n\ndef quantum_model_predict(X_pred, trained_params, trained_bias):\n    \"\"\"Predict using the quantum model defined above.\"\"\"\n\n    p = []\n    for x in X_pred:\n\n        x_torch = torch.tensor(x)\n        pred_torch = quantum_model_plus_bias(x_torch, trained_params, trained_bias)\n        pred = pred_torch.detach().numpy().item()\n        if pred &gt; 0:\n            pred = 1\n        else:\n            pred = -1\n\n        p.append(pred)\n    return p\n\n\nn_layers = 2\nbatch_size = 20\nsteps = 100\n\nwith dev.tracker:\n    trained_params, trained_bias, loss_history = quantum_model_train(n_layers, steps, batch_size)\n    pred_test = quantum_model_predict(X_test, trained_params, trained_bias)\n\nprint(\"accuracy on test set:\", accuracy_score(pred_test, y_test))\n\nplt.plot(loss_history)\nplt.ylim((0, 1))\nplt.xlabel(\"steps\")\nplt.ylabel(\"cost\")\nplt.show()\n\nstep 0 , loss 1.046987877386652\nstep 10 , loss 0.6283218587126969\nstep 20 , loss 0.4609234606645739\nstep 30 , loss 0.575389668233003\nstep 40 , loss 0.5128422872323696\nstep 50 , loss 0.4457781583090726\nstep 60 , loss 0.5189765728028315\nstep 70 , loss 0.4848118165707457\nstep 80 , loss 0.4488463923314871\nstep 90 , loss 0.46302412863961334\naccuracy on test set: 0.96",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Przykłady prostych modeli uczenia maszynowego"
    ]
  },
  {
    "objectID": "labs/rozwiazania/cw3 rozw.html",
    "href": "labs/rozwiazania/cw3 rozw.html",
    "title": "Proces optymalizacji",
    "section": "",
    "text": "Znasz już bramkę Hadamarda, bramkę \\(X\\) oraz bramki rotacji (\\(R_x\\), \\(R_y\\), \\(R_z\\))\nDla przypomnienia :\nBramka \\(X\\):\n\\[\n\\textbf{X} = \\begin{bmatrix} 0 \\,\\, 1 \\\\ 1 \\,\\, 0 \\end{bmatrix}\n\\]\n\\[\n\\textbf{X} \\ket{0} = \\begin{bmatrix} 0\\,\\, 1 \\\\ 1 \\, 0 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} =  \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\ket{1}\n\\] oraz \\[\n\\textbf{X} \\ket{1} = \\begin{bmatrix} 0\\,\\, 1 \\\\ 1 \\, 0 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} =  \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\ket{0}\n\\]\nBramka \\(H\\):\n\\[\n\\textbf{H}= \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1\\,\\,\\,\\,\\,\\,\\, 1 \\\\ 1 \\, -1 \\end{bmatrix}\n\\]\ndla której\n\\[\n\\textbf{H} \\ket{0} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1\\,\\,\\,\\,\\,\\,\\, 1 \\\\ 1 \\, -1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = \\frac{1}{\\sqrt{2}} \\left( \\ket{0} + \\ket{1} \\right) = \\ket{+}\n\\] oraz \\[\n\\textbf{H} \\ket{1} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1\\,\\,\\,\\,\\,\\,\\, 1 \\\\ 1 \\, -1 \\end{bmatrix}  \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\frac{1}{\\sqrt{2}} \\left( \\ket{0} - \\ket{1} \\right) = \\ket{-}\n\\]"
  },
  {
    "objectID": "labs/rozwiazania/cw3 rozw.html#zadanie---napisz-jedno-kubitowy-obwód-realizujący-bit-losowy.",
    "href": "labs/rozwiazania/cw3 rozw.html#zadanie---napisz-jedno-kubitowy-obwód-realizujący-bit-losowy.",
    "title": "Proces optymalizacji",
    "section": "Zadanie - napisz jedno kubitowy obwód realizujący bit losowy.",
    "text": "Zadanie - napisz jedno kubitowy obwód realizujący bit losowy.\nklasycznie\n# generator liczb losowych\nfrom random import randrange\n''.join([str(randrange(2)) for i in range(8)])\nlub\n# mozna takze zrealizowac jako rzut monetą \n\nimport random\nfor n in range(5):\n    if random.random()&lt;0.5:       #if the random number is less than 0.5 print heads\n        print('HEADS')\n    else:\n        print('TAILS')\n\nUżyj default.qubit jako klasyczny symulator w funkcji device\nzmień funkcję qc w obwód kwantowy korzystając z dekoratora @qml.qnode\nzdefinuj funkcję qc z jednym kubitem\nna kubicie wykorzystaj bramkę Hadamarda\nwyświetl stan po pomiarze pojedynczego kubitu\nwyświetl prawdopodobieństwa otrzymania stanu 0 i 1\nuruchom obwód 3 razy (do dev dodaj parametr , shots=3) i sprawdź wyniki otrzymywane przez metodę qml.counts() link\nuruchom powyzszą prcedurę 100 razy\n\nDo jakiego zdarzenia losowego podobne są wyniki?"
  },
  {
    "objectID": "labs/rozwiazania/cw3 rozw.html#zadanie---losowy-bajt",
    "href": "labs/rozwiazania/cw3 rozw.html#zadanie---losowy-bajt",
    "title": "Proces optymalizacji",
    "section": "Zadanie - Losowy bajt",
    "text": "Zadanie - Losowy bajt\n\nbajt to 8 bitów - jaki zakres wartości jesteś w stanie przechowywać w 8 kubitach ?\nwygeneruj losowy bajt z wykorzystaniem tylko bramki X\n\nif randrange(2) == 0:\n        qc.x(i)\n\nwygeneruj losowy bajt z wykorzystaniem bramek hadamarda\nwygeneruj 10 prób w pełni losowego bajtu - odkoduj wyniki w systemie int\noblicz różnicę dwóch bajtów dla których pierwsze cztery bity to 0, piąty bit pierwszego bajtu to 0 a drugiego bajtu to 1 . pozostałe bity są równe 1"
  },
  {
    "objectID": "labs/rozwiazania/cw3 rozw.html#losowa-liczba-w-zakresie-0-15",
    "href": "labs/rozwiazania/cw3 rozw.html#losowa-liczba-w-zakresie-0-15",
    "title": "Proces optymalizacji",
    "section": "Losowa liczba w zakresie 0-15",
    "text": "Losowa liczba w zakresie 0-15\n\nZa pomocą odpowiedniego obwodu kwantowego wylosuj liczbę z zakresu 0-15\nWykorzystaj 1000 wykonań modelu i narysuj histogram wyników dla poszczególnych liczb 0- 15\n\n\nfrom random import randrange\n''.join([str(randrange(2)) for i in range(8)])\n\n\n# mozna takze zrealizowac jako rzut monetą \n\nimport random\nfor n in range(5):\n    if random.random()&lt;0.5:       #if the random number is less than 0.5 print heads\n        print('HEADS')\n    else:\n        print('TAILS')\n\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=1)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    return qml.probs(wires=[0])\n\nprobs = qc()\nprint(f\"Prawdopodobieństwa pomiaru: {probs}\")"
  },
  {
    "objectID": "labs/rozwiazania/cw3 rozw.html#zadanie-3",
    "href": "labs/rozwiazania/cw3 rozw.html#zadanie-3",
    "title": "Proces optymalizacji",
    "section": "Zadanie 3",
    "text": "Zadanie 3\nRozszerz wygenerowany obwód dla losowego bitu i dodaj parametryzowaną bramkę \\(R_x\\) z kątem ustawionym jako pi/4\nOblicz wartość oczekiwaną operatora \\(&lt;\\sigma_z&gt;\\) wykorzystując qml.expval(qml.PauliZ(0))\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.RX(np.pi/4, wires=0)\n    return qml.expval(qml.PauliZ(0))\n\nresult = qc()\nprint(f\"Wartość oczekiwana pomiaru: {result}\")\n\nBramka (i operator) Z, w bazie obliczeniowej dany jest macierzą: \\[\n\\textbf{Z} = \\begin{bmatrix} 1 \\,\\,\\,\\,\\,\\,\\,\\, 0 \\\\ 0 \\,\\, -1 \\end{bmatrix}\n\\]\nOperator ten mierzy różnicę pomiędzy prawdopodobieństwem, że kubit jest w stanie \\(\\ket{0}\\) a prawdopodobieństwem, że jest w stanie \\(\\ket{1}\\)\nW ogólności wartość oczekiwana (wartość średnia wyniku pomiaru w bazie operatora Z) dana jest wzorem: \\[\n\\textbf{&lt;Z&gt;} = \\bra{\\psi} \\textbf{Z} \\ket{\\psi}\n\\]\nNiech \\[\n\\ket{\\psi} = \\alpha\\ket{0} + \\beta\\ket{1}\n\\] wtedy \\[\n\\bra{\\psi} = \\alpha^*\\bra{0} + \\beta^*\\bra{1}\n\\]\nMożemy obliczyć: \\[\n\\bra{\\psi} \\textbf{Z} \\ket{\\psi}  = (\\alpha^*\\bra{0} + \\beta^*\\bra{1} ) \\,\\,\\, Z \\,\\,\\,(\\alpha\\ket{0} + \\beta\\ket{1}) = |\\alpha|^2 - |\\beta|^2\n\\] Czyli dla kubitu w stanie \\(\\ket{0}\\) \\[\n\\textbf{&lt;Z&gt;} = 1  \n\\] Dla kubitu w stanie \\(\\ket{1}\\) \\[\n\\textbf{&lt;Z&gt;} = -1  \n\\] Dla kubitu w superpozycji \\(\\ket{0} +\\ket{1}\\) \\[\n\\textbf{&lt;Z&gt;} = 0  \n\\]"
  },
  {
    "objectID": "labs/rozwiazania/cw3 rozw.html#gra-w-obracanie-monety",
    "href": "labs/rozwiazania/cw3 rozw.html#gra-w-obracanie-monety",
    "title": "Proces optymalizacji",
    "section": "Gra w obracanie monety",
    "text": "Gra w obracanie monety\nWykorzystując powyżej zdefiniowane bramki możemy zrealizowa następującą grę:\n\nW grze bierze udział dwóch graczy. Gracze dysponują monetą, której nie widzą w trakcie gry (np. jest zamknięta w pudełku). Natomiast wiedzą, że początkowo moneta ułożona jest orłem do góry (w stanie \\(\\ket{0}\\)) Gra polega na wykonaniu trzech ruchów na przemian. Każdy ruch polega na odwróceniu monety bądź pozostawieniu jej w takim stanie w jakim była. Gracze nie wiedzą jaki ruch wykonuje przeciwnik. Po ostatnim ruchu pudełko zostaje otwarte i gracze sprawdzają w jakiej pozycji jest moneta. Pierwszy gracz wygrywa jeśli moneta jest w pozycji orła, a drugi jeśli przeciwnie.\n\nSzansa wygranej wynosi dla każdego \\(50\\%\\) i jak można sprawdzic nie istnieje strategia wygrywająca.\nZweryfikuj powyższy wynik wykorzystując obwód kwantowy.\ndef klasycze_strategie():\n    wyniki = []\n    for ruch_1 in ['I','X']:\n        for ruch_2 in ['I','X']:\n            for ruch_3 in ['I','X']:\n                strategia = ruch_1 + ruch_2 + ruch_3\n                ob = obwod(strategia)\n                stats = sedzia(ob())\n                wyniki.append((strategia, stats))\n    return wyniki\nUtwórz odpowiedni kod funkcji obwód parametryzowany stringiem “strategia” oraz dodaj funkcję sędziego."
  },
  {
    "objectID": "labs/rozwiazania/cw3 rozw.html#zadanie---a-co-jeśli-zamienimy-monetę-na-kubit",
    "href": "labs/rozwiazania/cw3 rozw.html#zadanie---a-co-jeśli-zamienimy-monetę-na-kubit",
    "title": "Proces optymalizacji",
    "section": "Zadanie - a co jeśli zamienimy monetę na kubit?",
    "text": "Zadanie - a co jeśli zamienimy monetę na kubit?\nMożliwe operacje pozostawienia kubitu w takim samym stanie - bramka I, zmiany stanu na przeciwny bramka X.\nCzyli pierwszy gracz ustala pierwszą bramkę, drugi drugą i ponownie pierwszy trzecią. Otwarcie pudełka to pomiar stanu kubitu.\n\nPrzeanalizuj wynik dla sekwencji I X I\n\nA co jeśli pierwszy gracz wie, że działa na kubicie?\n\nCzy może sprawic on, że wygra zawsze? (skoro wie, że działa na kubicie może użyc innych bramek)\n\nzmodyfikuj kod obwodu i sprawdź strategię w której pierwszy gracz zawsze użyje dwóch bramek Hadamarda.\n\ndef kwantowa_strategia():\n    wyniki = []\n    for ruch_1 in ['H']:\n        for ruch_2 in ['I','X']:\n            for ruch_3 in ['H']:\n                strategia = ruch_1 + ruch_2 + ruch_3\n                ob = obwod(strategia)\n                stats = sedzia(ob())\n                wyniki.append((strategia, stats))\n    return wyniki"
  },
  {
    "objectID": "labs/rozwiazania/cw3 rozw.html#zadanie---obwód-kwantowy-z-optymalizacją",
    "href": "labs/rozwiazania/cw3 rozw.html#zadanie---obwód-kwantowy-z-optymalizacją",
    "title": "Proces optymalizacji",
    "section": "Zadanie - Obwód kwantowy z optymalizacją",
    "text": "Zadanie - Obwód kwantowy z optymalizacją\n\nNapisz nowy obwód kwantowy, który zawierać będzie tylko bramkę \\(R_X\\) dla dowolnego parametru \\(\\theta\\)\noblicz i uzasadnij, że wartość oczekiwana dla stanu \\(\\ket{\\psi} = R_X \\, \\ket{0}\\) \\[&lt;Z&gt; = cos^2(\\theta /2)- sin^2(\\theta /2) = cos(\\theta)\\]\n\nZałóżmy, że nasz problem obliczeniowy sprowadza się do wygenerowania wartości oczekiwanej o wartości 0.5.\n\\[\n\\textbf{&lt;Z&gt;} = \\bra{\\psi} \\textbf{Z} \\ket{\\psi} = 0.5\n\\]\nNapisz program znajdujący rozwiązanie - szukający wagę \\(\\theta\\) dla naszego obwodu\n\nZdefiniuj funkcję kosztu, którą bedziemy minimalizować \\((Y - y)^2\\)\nzainicjuj rozwiązanie \\(theta=0.01\\) i przypisz do tablicy array np.array(0.01, requires_grad=True)\nJako opt wybierz spadek po gradiencie : opt = qml.GradientDescentOptimizer(stepsize=0.1)\nuzyj poniższego kodu do wygenerowania pętli obiczeń\n\n\nepochs = 100\n\nfor epoch in range(epochs):\n    theta = opt.step(cost_fn, theta)\n\n    if epoch % 10 == 0:\n        print(f\"epoka: {epoch}, theta: {theta}, koszt: {cost_fn(theta)}\")\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=1)\n\n@qml.qnode(dev)\ndef par_c(theta):\n    qml.RX(theta, wires=0)\n    return qml.expval(qml.PauliZ(0))\n\n\ndef cost_fn(theta):\n    return (par_c(theta) - 0.5)**2\n\ntheta = np.array(0.01, requires_grad=True)\n\nopt = qml.GradientDescentOptimizer(stepsize=0.1)\n\nepochs = 100\n\nfor epoch in range(epochs):\n    theta = opt.step(cost_fn, theta)\n\n    if epoch % 10 == 0:\n        print(f\"epoka: {epoch}, theta: {theta}, koszt: {cost_fn(theta)}\")\n\nprint(f\"Optymalizacja zakonczona dla theta={theta}, koszt: {cost_fn(theta)}\")\n\n\nepoka: 0, theta: 0.010999883335916642, koszt: 0.24993950555333252\nepoka: 10, theta: 0.028520883980330904, koszt: 0.2495934725570593\nepoka: 20, theta: 0.07380240366299132, koszt: 0.24728524869432472\nepoka: 30, theta: 0.18848123038996684, koszt: 0.23260358196368314\nepoka: 40, theta: 0.44553231822816797, koszt: 0.1619107886095973\nepoka: 50, theta: 0.7954652635692223, koszt: 0.03998102446252434\nepoka: 60, theta: 0.9838691671205075, koszt: 0.002894983645374295\nepoka: 70, theta: 1.0340365114010706, koszt: 0.00012891702079013002\nepoka: 80, theta: 1.0445781695789977, koszt: 5.138079127884816e-06\nepoka: 90, theta: 1.0466807535250837, koszt: 2.002500944777545e-07\nOptymalizacja zakonczona dla theta=1.0470778036429096, koszt: 1.0753863888581739e-08\n\n\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=1)\n\n@qml.qnode(dev, interface=\"torch\")\ndef par_c(theta):\n    qml.RX(theta, wires=0)\n    return qml.expval(qml.PauliZ(0))\n\n\n\ndef cost_fn(theta):\n    target = 0.5\n    return (par_c(theta) - target) ** 2\n\n\nimport torch\nfrom torch.optim import Adam \n\ntheta = torch.tensor(0.01, requires_grad=True)\n\noptimizer = Adam([theta], lr=0.1)\nepochs = 100\n\nfor epoch in range(epochs):\n    optimizer.zero_grad()\n    loss = cost_fn(theta)\n    loss.backward()\n    optimizer.step()\n    if epoch % 10 == 0:\n        print(f\"epoka: {epoch}, theta: {theta}, koszt: {cost_fn(theta)}\")\n    \n\nepoka: 0, theta: 0.1099998876452446, koszt: 0.24399264948886004\nepoka: 10, theta: 1.0454959869384766, koszt: 2.169397961785511e-06\nepoka: 20, theta: 1.0966185331344604, koszt: 0.0018829460500888265\nepoka: 30, theta: 0.9526112079620361, koszt: 0.006329338284936267\nepoka: 40, theta: 1.111649513244629, koszt: 0.0032281231974498922\nepoka: 50, theta: 1.0076401233673096, koszt: 0.0011463367423114523\nepoka: 60, theta: 1.0690317153930664, koszt: 0.00036201344599675586\nepoka: 70, theta: 1.0343401432037354, koszt: 0.000123060304852398\nepoka: 80, theta: 1.0549986362457275, koszt: 4.584717916214815e-05\nepoka: 90, theta: 1.042211651802063, koszt: 1.859027886217772e-05"
  },
  {
    "objectID": "labs/rozwiazania/cw3 rozw.html#modele-klasyfikacji",
    "href": "labs/rozwiazania/cw3 rozw.html#modele-klasyfikacji",
    "title": "Proces optymalizacji",
    "section": "Modele klasyfikacji",
    "text": "Modele klasyfikacji\nDane Titanic\n\nWygeneruj model na bazie jednokubitowego obwodu kwantowego, który dla każdego wiersza danych generuje wynik 0\nUtwórz model na bazie jednokubitowego obwody kwantowego, który dla każdego wiersza danych generuje wynik 1\nUtwórz model na bazie jednokubitowego obwodu kwantowego, który zwraca losową wartość 0 lub 1 z prawdopodobienstwem 1/2.\n3 i 5 kubitów losowo zwracających 0 lub 1 ale wynik na podstawie Parity"
  },
  {
    "objectID": "labs/zaoczne/zad4.html",
    "href": "labs/zaoczne/zad4.html",
    "title": "Wstęp do kwantowego uczenia maszynowego",
    "section": "",
    "text": "Posiadamy 5 przedmiotów a,b,c,d,e, które chcemy zabrać ze sobą. Każda rzecz ma dla nas jakąś wartość którą możemy przypisać do przedmiotu.\nitems_values = {\"a\": 8, \"b\": 47, \"c\": 10, \"d\": 5, \"e\": 16}\nvalues_list = [8, 47, 10, 5, 16]\nChcemy zoptymalizować wartość zabieranych przedmiotów. Jednak nasz plecak ,do którego możemy spakować rzeczy może pomieścić tylko określoną wagę naszych przedmiotów.\nmax_weight = 26\nKażda rzecz powinna mieć określoną swoją wagę.\nitems_weight = {\"a\":3, \"b\":11, \"c\":14, \"d\":19, \"e\":5}\nweight_list = [3,11,14,19.5]\nProblem ten jest problemem optymalizacyjnym.\nMożemy spróbować wszystkich możliwych kombinacji (jest ich \\(2^n\\) gdzie n-liczba przedmiotów - w naszym przypadku istnieją 32 kombinacje)\n\nimport numpy as np\n\nitems_values = {\"a\": 8, \"b\": 47, \"c\": 10, \"d\": 5, \"e\": 16}\nvalues_list = [8, 47, 10, 5, 16]\nitems_weight = {\"a\":3, \"b\":11, \"c\":14, \"d\":19, \"e\":5}\nweights_list = [3,11,14,19.5]\n\nmax_weight = 26\n\ndef sum_weight(bitstring, items_weight):\n    weight = 0\n    for n, i in enumerate(items_weight):\n        if bitstring[n] == \"1\":\n            weight += i\n    return weight\n\n\ndef sum_values(bitstring, items_value):\n    value = 0\n    for n, i in enumerate(items_value):\n        if bitstring[n] == \"1\":\n            value += i\n    return value\n\nitems = list(items_values.keys())\nn_items = len(items)\ncombinations = {}\nmax_value = 0\nfor case_i in range(2**n_items):  # all possible options\n    combinations[case_i] = {}\n    bitstring = np.binary_repr(\n        case_i, n_items\n    )  # bitstring representation of a possible combination, e.g, \"01100\" in our problem means bringing (-💻📸--)\n    combinations[case_i][\"items\"] = [items[n] for n, i in enumerate(bitstring) if i == \"1\"]\n    combinations[case_i][\"value\"] = sum_values(bitstring, values_list)\n    combinations[case_i][\"weight\"] = sum_values(bitstring, weights_list)\n    # save the information of the optimal solution (the one that maximizes the value while respecting the maximum weight)\n    if (\n        combinations[case_i][\"value\"] &gt; max_value\n        and combinations[case_i][\"weight\"] &lt;= max_weight\n    ):\n        max_value = combinations[case_i][\"value\"]\n        optimal_solution = {\n            \"items\": combinations[case_i][\"items\"],\n            \"value\": combinations[case_i][\"value\"],\n            \"weight\": combinations[case_i][\"weight\"],\n        }\n\n\nprint(\n    f\"Najlepszym rozwiązaniem jest kombinacja {optimal_solution['items']} dla której całkowita wartość wynosi: {optimal_solution['value']} a całkowita waga {optimal_solution['weight']} \"\n)\n\nNajlepszym rozwiązaniem jest kombinacja ['b', 'c', 'e'] dla której całkowita wartość wynosi: 73 a całkowita waga 25 \n\n\nZałóżmy, że dla obliczenie jednej kombinacji trwa \\(1 ns\\).\n\ndef time_to_solution(n, time_single_case):\n    \"\"\"\n        n (int): number of variables\n        time_single_case (float): time to solve a single case\n    \"\"\"\n    return time_single_case * 2 ** n\n\ntime_per_case = 1e-9 # time to execute a single case in seconds\nsec_day = 3600 * 24 # seconds in a day\nsec_year = sec_day * 365 # seconds in a year\n\nprint(\n    f\"- For 10 items, 2^10 cases, we need {time_to_solution(2, time_per_case)} seconds.\"\n)\nprint(\n    f\"- For 50 items, 2^50 cases, we need {round(time_to_solution(50, time_per_case) / sec_day)} days.\"\n)\nprint(\n    f\"- For 100 items, 2^100 cases, we need {round(time_to_solution(100, time_per_case) / sec_year)} years.\"\n)\n\n- For 10 items, 2^10 cases, we need 4e-09 seconds.\n- For 50 items, 2^50 cases, we need 13 days.\n- For 100 items, 2^100 cases, we need 40196936841331 years."
  },
  {
    "objectID": "labs/zaoczne/zad1.html",
    "href": "labs/zaoczne/zad1.html",
    "title": "klasyczne i kwantowe sieci neuronowe",
    "section": "",
    "text": "# import potrzebnych bibliotek \n\nimport torch\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\n\ntorch.manual_seed(1234)\n\nWygenruj dane:\n\nkorzystając z metody torch.linespace() wygenruj 500 punktów danych dla zakresu (0,10) w tablicy x\nZe względu, iz potrzebujemy 500 wierszy przypadków (a nie 500 zmiennych) jednowymiarowej tablicy zastosuj metodę view(-1,1)\njako wynik si wygeneruj wartości funckji sin(x). Do zmiennej y zastosuj drobną zmianę dodając wartości losowe.\nAnalogicznie jak dla danych x pamiętaj o zmianie widoku : view(-1,1)\n\nPonizszy wykres wygeneruje Ci graficzną reprezentację danych\n\n###### \n#\n#  twoj kod \nx = ...\nsi = ...\ny = ...\n\nx_train = x.requires_grad_(True)\n#####\n\n\nplt.figure(figsize=(8,4))\nplt.plot(x, torch.sin(x).view(-1,1), color=\"tab:grey\", alpha=0.6, label=\"sin(x)\")\nplt.scatter(x,y, label=\"dane treningowe\")\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend()\nplt.show()\n\nKorzystając z wartwy gęstej torch.nn.Linear(), oraz funkcji aktywacji (np. torch.nn.ReLU(), torch.nn.Tanh() i inne) utwórz sieć z kilkoma (przynajmniej jedną warstwą ukrytą) pozwalającą wygenerować model regresji. Do definicji uzyj obiektu Sequential() - sprawdź w dokumentacji po co taki obiekt.\n\nclass SinusEstimator(torch.nn.Module):\n\n    def __init__(self, N_INPUT: int, N_OUTPUT: int):\n        super(SinusEstimator,self).__init__()\n        self.layers = torch.nn.Sequential(\n            # struktura Twojej sieci\n            torch.nn.Linear(N_INPUT,...),\n            ...\n            torch.nn.Linear(...,N_OUTPUT)\n        )\n\n\n    def forward(self, x):\n        x = self.layers(x)\n        return x\n\nPoniszy kod wytrenuje Twoją sieć:\n\n############## \n# zdefiniuj obiekt modelu. \nmodel = ...\n###########\n\n\nlearning_rate=0.001\noptimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\ncriterion = torch.nn.MSELoss()\n\n# dodatkowa funkcja - warto zrealizować\nlosses = []\n\ndef callback(model, loss):\n    losses.append(loss.item())\n\n    clear_output(wait=True)\n    prediction = model(x).detach()\n    plt.figure(figsize=(6,2.5))\n    plt.plot(x[:,0].detach(), torch.sin(x)[:,0].detach(), label=\"Exact solution\", color=\"tab:grey\", alpha=0.6)\n    plt.plot(x[:,0].detach(), prediction[:,0], label=\"Classical solution\", color=\"tab:green\")\n    plt.title(f\"Training step {len(losses)}\")\n    plt.legend()\n    plt.show()\n\n    plt.figure(figsize=(6,2.5))\n    plt.title('Lossfn Visualised')\n    plt.plot(losses)\n    plt.show()\n\n\ndef train(X, Y, model, optimiser, epochs, lossfn, callback = None):\n    for _ in range(epochs):\n        model.train()\n        prediction = model(X)\n        loss = lossfn(prediction, Y)\n\n        optimiser.zero_grad()\n        loss.backward()\n        optimiser.step()\n        model.eval()\n        if callback != None:\n            callback(model, loss)\n\n\nUruchom funkcję train() z odpowiednimi parametrami.\n\ndane: x_train, y\nmodel sieci: model\noptymalizator: optimiser\nilość epok: 500 (mozesz tez przetestowac najpierw 10 a potem np. 1000)\nfunkcja straty: criterion\ncallback: nasza zdefiniowana funkcja callback\n\n\ntrain()\n\nspradz czy inna definicja funkcji kosztu special_loss_fn usprawni wyniki sieci\n\ndef mse(y, y_pred) -&gt; torch.Tensor:\n    return torch.mean((y-y_pred)**2)\n\ndef special_loss_fn(y, y_pred) -&gt; torch.Tensor:\n    return mse(y, y_pred) + torch.mean((y_pred - torch.sin(x))**2)\n\ntrain(..........)"
  },
  {
    "objectID": "labs/zaoczne/zad1.html#wygeneruj-klasyczną-sieć-neuronową-dla-funckji-sinx",
    "href": "labs/zaoczne/zad1.html#wygeneruj-klasyczną-sieć-neuronową-dla-funckji-sinx",
    "title": "klasyczne i kwantowe sieci neuronowe",
    "section": "",
    "text": "# import potrzebnych bibliotek \n\nimport torch\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\n\ntorch.manual_seed(1234)\n\nWygenruj dane:\n\nkorzystając z metody torch.linespace() wygenruj 500 punktów danych dla zakresu (0,10) w tablicy x\nZe względu, iz potrzebujemy 500 wierszy przypadków (a nie 500 zmiennych) jednowymiarowej tablicy zastosuj metodę view(-1,1)\njako wynik si wygeneruj wartości funckji sin(x). Do zmiennej y zastosuj drobną zmianę dodając wartości losowe.\nAnalogicznie jak dla danych x pamiętaj o zmianie widoku : view(-1,1)\n\nPonizszy wykres wygeneruje Ci graficzną reprezentację danych\n\n###### \n#\n#  twoj kod \nx = ...\nsi = ...\ny = ...\n\nx_train = x.requires_grad_(True)\n#####\n\n\nplt.figure(figsize=(8,4))\nplt.plot(x, torch.sin(x).view(-1,1), color=\"tab:grey\", alpha=0.6, label=\"sin(x)\")\nplt.scatter(x,y, label=\"dane treningowe\")\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend()\nplt.show()\n\nKorzystając z wartwy gęstej torch.nn.Linear(), oraz funkcji aktywacji (np. torch.nn.ReLU(), torch.nn.Tanh() i inne) utwórz sieć z kilkoma (przynajmniej jedną warstwą ukrytą) pozwalającą wygenerować model regresji. Do definicji uzyj obiektu Sequential() - sprawdź w dokumentacji po co taki obiekt.\n\nclass SinusEstimator(torch.nn.Module):\n\n    def __init__(self, N_INPUT: int, N_OUTPUT: int):\n        super(SinusEstimator,self).__init__()\n        self.layers = torch.nn.Sequential(\n            # struktura Twojej sieci\n            torch.nn.Linear(N_INPUT,...),\n            ...\n            torch.nn.Linear(...,N_OUTPUT)\n        )\n\n\n    def forward(self, x):\n        x = self.layers(x)\n        return x\n\nPoniszy kod wytrenuje Twoją sieć:\n\n############## \n# zdefiniuj obiekt modelu. \nmodel = ...\n###########\n\n\nlearning_rate=0.001\noptimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\ncriterion = torch.nn.MSELoss()\n\n# dodatkowa funkcja - warto zrealizować\nlosses = []\n\ndef callback(model, loss):\n    losses.append(loss.item())\n\n    clear_output(wait=True)\n    prediction = model(x).detach()\n    plt.figure(figsize=(6,2.5))\n    plt.plot(x[:,0].detach(), torch.sin(x)[:,0].detach(), label=\"Exact solution\", color=\"tab:grey\", alpha=0.6)\n    plt.plot(x[:,0].detach(), prediction[:,0], label=\"Classical solution\", color=\"tab:green\")\n    plt.title(f\"Training step {len(losses)}\")\n    plt.legend()\n    plt.show()\n\n    plt.figure(figsize=(6,2.5))\n    plt.title('Lossfn Visualised')\n    plt.plot(losses)\n    plt.show()\n\n\ndef train(X, Y, model, optimiser, epochs, lossfn, callback = None):\n    for _ in range(epochs):\n        model.train()\n        prediction = model(X)\n        loss = lossfn(prediction, Y)\n\n        optimiser.zero_grad()\n        loss.backward()\n        optimiser.step()\n        model.eval()\n        if callback != None:\n            callback(model, loss)\n\n\nUruchom funkcję train() z odpowiednimi parametrami.\n\ndane: x_train, y\nmodel sieci: model\noptymalizator: optimiser\nilość epok: 500 (mozesz tez przetestowac najpierw 10 a potem np. 1000)\nfunkcja straty: criterion\ncallback: nasza zdefiniowana funkcja callback\n\n\ntrain()\n\nspradz czy inna definicja funkcji kosztu special_loss_fn usprawni wyniki sieci\n\ndef mse(y, y_pred) -&gt; torch.Tensor:\n    return torch.mean((y-y_pred)**2)\n\ndef special_loss_fn(y, y_pred) -&gt; torch.Tensor:\n    return mse(y, y_pred) + torch.mean((y_pred - torch.sin(x))**2)\n\ntrain(..........)"
  },
  {
    "objectID": "labs/zaoczne/zad1.html#kwantowa-sieć-neuronowa",
    "href": "labs/zaoczne/zad1.html#kwantowa-sieć-neuronowa",
    "title": "klasyczne i kwantowe sieci neuronowe",
    "section": "Kwantowa sieć neuronowa",
    "text": "Kwantowa sieć neuronowa\nZdefiniujmy nową strukturę siec - wymieniając warstę ukrytą na obwód kwantowy.\nclass QN(nn.Module):\n    '''Classical -&gt; Quantum -&gt; Classical'''\n\n    def __init__(self, N_INPUT: int, N_OUTPUT: int, Q_NODE, N_QUBITS):\n        super().__init__()\n\n        self.layers = nn.Sequential(\n            # input layer\n            nn.Linear(N_INPUT, N_QUBITS),\n            # 1st hidden layer as a quantum circuit\n            Q_NODE,\n            # output layer\n            nn.Linear(N_QUBITS, N_OUTPUT)\n        )\n        \n\n    def forward(self, x):\n        return  self.layers(x)\nJak mozesz zauwazyc po warstwie wejsciowej umiescilismy obietk Q_NODE, którego funkcję podstawimy jako trzeci parametr naszej sieci.\nBez większego wchodzenia w definicję tego obiektu nasz obwód kwantowy musi pobrać dane z warstwy poprzedniej i wypuścić jakieś wyniki do warstwy wynikowej. Oczywiście taką operację musi realizować jakaś funkcja (obiekt) w pythonie.\n\n # NASZ kwantowy PQC - parametryzowany obwód kwantowy dla jednej warstwy ukrytej\nimport pennylane as qml\n\nn_qubits = 2\ndev = qml.device(\"default.qubit\", wires=n_qubits)\n\n@qml.qnode(dev)\ndef qnode(inputs, weights):\n    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n\n\n\nn_layers = 5\n\nweight_shapes = {\"weights\": (n_layers, n_qubits)}\nqlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\n\nUruchomienie sieci mozesz zrealizowac ponizszym kodem\n\ndef mse(y, y_pred) -&gt; torch.Tensor:\n    # oblicz średnią z roznnicy y i y_pred podniesionej do kwadratu\n    return ...\n\n\n#########################\n#   utworz zmienna qmodel z parametrami (1,1, qlayer, n_qubits)\n#   Twoj kod\n#  \nqmodel = ...\n#####\n\nprint(qmodel)\n\nx = x.requires_grad_(True)\nx_train = x.requires_grad_(True)\n\nlearning_rate=1e-3\noptimiser = torch.optim.Adam(qmodel.parameters(), lr=learning_rate)\n\nlosses = []\n\ndef special_loss_fn(y, y_pred) -&gt; torch.Tensor:\n    return mse(y, y_pred) + torch.mean((y_pred - torch.sin(x))**2)\n    \n\ntrain(x_train, y, qmodel, optimiser, 500, special_loss_fn, callback)\n\nSprawdz wyniki kodem:\n\ndef plot_result(x,y,x_data,y_data,yh, title=None):\n\n    plt.figure(figsize=(8,4))\n    plt.title(title)\n    plt.plot(x,y, color=\"tab:grey\", alpha=0.6, label=\"Exact solution\")\n    plt.plot(x,yh, color=\"tab:green\", label=\"Neural network prediction\")\n    plt.scatter(x_data, y_data, alpha=0.3, label='Training data')\n    l = plt.legend(loc='best')\n\nplot_result(\n    x.detach(),\n    torch.sin(x).detach(),\n    x.detach(),\n    y.detach(),\n    qmodel(x).detach(),\n    title='Training of PINN'\n    )\n\nprint(mse(qmodel(x), torch.sin(x)))"
  },
  {
    "objectID": "labs/Qiskit/cw1.html",
    "href": "labs/Qiskit/cw1.html",
    "title": "Biblioteka Qiskit wprowadzenie",
    "section": "",
    "text": "python3 -m venv venv\nsource venv/bin/activate\n# Scripts\\Activate\n\npip install qiskit==1.2.1\npip install qiskit[visualization]\n# pip install 'qiskit[visualization]'\npip install qiskit_aer==0.15.1\npip install qiskit-algorithms==0.3.0\npip install qiskit_machine_learning==0.7.2\npip install qiskit-finance==0.4.1\npip install qiskit-ibm-runtime==0.29.0\npip install qiskit-optimization==0.6.1\nThe other important libs.\nimport numpy as np\nnp.set_printoptions(precision=3, suppress=True)"
  },
  {
    "objectID": "labs/Qiskit/cw1.html#qiskit-podstawy",
    "href": "labs/Qiskit/cw1.html#qiskit-podstawy",
    "title": "Biblioteka Qiskit wprowadzenie",
    "section": "Qiskit podstawy",
    "text": "Qiskit podstawy\nTworzenie rejestrów:\n\nkwantowego QuantumRegister - do inicjalizowania kubitów. Kubity domyślnie inicjalizowane są w stanie \\(|0\\rangle\\)\nklasycznego ClassicalRegister do przechowywania wyników pomiarów kubitów. Po pomiarze otrzymywany wynik zawsze jest binarny \\(\\{0,1\\}\\).\n\n\nfrom qiskit import QuantumRegister, ClassicalRegister, QuantumCircuit\n\nOba rejestry wykorzystywane będą do generowania obwodów kwantowych QuantumCircuit.\nWszystkie podstawowe obiekty dostępne są bezpośrednio w bibliotece qiskit.\n\nqreq = QuantumRegister(4) # rejest kwantowy z 4 qubitami\n\n\ncreg = ClassicalRegister(4) # rejestr klasyczny z 4 bitami\n\n\ncircuit = QuantumCircuit(qreq, creg) # obwód kwantowy z 4 qubitami i 4 bitami\n\n\ncircuit.draw('mpl') # funkcja rysująca obwód\n\n\n\n\n\n\n\n\n\noutput = QuantumRegister(1) # inny rejestr kwantowy z 1 qubitem\n\n\ncircuit2 = QuantumCircuit(qreq, output, creg)\n\n\ncircuit2.draw(\"mpl\")\n\n\n\n\n\n\n\n\n\ncircuit3 = QuantumCircuit(qreq)\n\n\ncircuit3.draw('mpl')\n\n\n\n\n\n\n\n\n\ncircuit4 = QuantumCircuit(3,3)\ncircuit4.draw(\"mpl\")\n\n\n\n\n\n\n\n\n\nfrom qiskit_aer.primitives import Sampler\n\nfrom qiskit import QuantumCircuit\nfrom qiskit.visualization import plot_histogram\n\nbell = QuantumCircuit(2)\nbell.h(0)\nbell.measure_all()\n \n# execute the quantum circuit\nquasi_dists = Sampler().run(bell, shots=1000).result().quasi_dists[0]\nprint(quasi_dists)\n\n{1: 0.503, 0: 0.497}\n\n\n\nplot_histogram(quasi_dists)\n\n\n\n\n\n\n\n\n\nPomiar w obwodzie i wielokrotne uruchamianie układu"
  },
  {
    "objectID": "labs/Qiskit/cw1.html#tworzenie-stanu-jednokubitowego",
    "href": "labs/Qiskit/cw1.html#tworzenie-stanu-jednokubitowego",
    "title": "Biblioteka Qiskit wprowadzenie",
    "section": "Tworzenie stanu jednokubitowego",
    "text": "Tworzenie stanu jednokubitowego\n\\[\n\\ket{\\psi}=\\ket{0}\n\\]\nDo inspekcji stanu układu (bez jego pomiaru) mozemy uzyć backend statevector_simulator.\n\nfrom math import pi\nfrom qiskit import QuantumCircuit\nfrom qiskit.quantum_info import Statevector\n \n# Create a Bell state for demonstration\nqc = QuantumCircuit(1)\npsi = Statevector(qc)\n\n\npsi.draw('latex') # metoda wypisująca wektor stanu w latexu\n\n\\[ |0\\rangle\\]\n\n\n\nfrom qiskit.visualization import plot_bloch_multivector\nplot_bloch_multivector(psi)\n\n\n\n\n\n\n\n\n\nqc = QuantumCircuit(1)\nqc.h(0)\nstate = Statevector(qc)\nstate.draw('latex')\n\n\\[\\frac{\\sqrt{2}}{2} |0\\rangle+\\frac{\\sqrt{2}}{2} |1\\rangle\\]\n\n\n\nplot_bloch_multivector(state)\n\n\n\n\n\n\n\n\n\ninicjalizacja stanu\n\nfrom qiskit import QuantumCircuit\nqc = QuantumCircuit(1)\ninitial_state = [0,1]\nqc.initialize(initial_state, 0)\nqc.draw('mpl')\n\n\n\n\n\n\n\n\n\nstate = Statevector(qc)\nstate.draw('latex')\n\n\\[ |1\\rangle\\]\n\n\n\ninitial_state = [1,1]\nqc = QuantumCircuit(1)\nqc.initialize(initial_state, 0)\nresult.draw('latex')\n\n\n---------------------------------------------------------------------------\nQiskitError                               Traceback (most recent call last)\nCell In[43], line 3\n      1 initial_state = [1,1]\n      2 qc = QuantumCircuit(1)\n----&gt; 3 qc.initialize(initial_state, 0)\n      4 result.draw('latex')\n\nFile ~/Documents/Dokumenty – MacBook Air (Sebastian)/qml2024/venv/lib/python3.12/site-packages/qiskit/circuit/quantumcircuit.py:5866, in QuantumCircuit.initialize(self, params, qubits, normalize)\n   5862     qubits = [qubits]\n   5864 num_qubits = len(qubits) if isinstance(params, int) else None\n-&gt; 5866 return self.append(Initialize(params, num_qubits, normalize), qubits, copy=False)\n\nFile ~/Documents/Dokumenty – MacBook Air (Sebastian)/qml2024/venv/lib/python3.12/site-packages/qiskit/circuit/library/data_preparation/initializer.py:75, in Initialize.__init__(self, params, num_qubits, normalize)\n     50 def __init__(\n     51     self,\n     52     params: Statevector | Sequence[complex] | str | int,\n     53     num_qubits: int | None = None,\n     54     normalize: bool = False,\n     55 ) -&gt; None:\n     56     r\"\"\"\n     57     Args:\n     58         params: The state to initialize to, can be either of the following.\n   (...)\n     73         normalize: Whether to normalize an input array to a unit vector.\n     74     \"\"\"\n---&gt; 75     self._stateprep = StatePreparation(params, num_qubits, normalize=normalize)\n     77     super().__init__(\"initialize\", self._stateprep.num_qubits, 0, self._stateprep.params)\n\nFile ~/Documents/Dokumenty – MacBook Air (Sebastian)/qml2024/venv/lib/python3.12/site-packages/qiskit/circuit/library/data_preparation/state_preparation.py:109, in StatePreparation.__init__(self, params, num_qubits, inverse, label, normalize)\n    107         params = np.array(params, dtype=np.complex128) / norm\n    108     elif not math.isclose(norm, 1.0, abs_tol=_EPS):\n--&gt; 109         raise QiskitError(f\"Sum of amplitudes-squared is not 1, but {norm}.\")\n    111 num_qubits = self._get_num_qubits(num_qubits, params)\n    112 params = [params] if isinstance(params, int) else params\n\nQiskitError: 'Sum of amplitudes-squared is not 1, but 1.4142135623730951.'\n\n\n\n\nfrom math import sqrt\ninitial_state = [1/sqrt(2),1/sqrt(2)]\nqc = QuantumCircuit(1)\nqc.initialize(initial_state, 0)\nresult = Statevector(qc)\nresult.draw('latex')\n\n\\[\\frac{\\sqrt{2}}{2} |0\\rangle+\\frac{\\sqrt{2}}{2} |1\\rangle\\]\n\n\n\nfrom math import sqrt\ninitial_state = [1/2,sqrt(3)/2]\nqc = QuantumCircuit(1)\nqc.initialize(initial_state, 0)\nresult = Statevector(qc)\nresult.draw('latex')\n\n\\[\\frac{1}{2} |0\\rangle+\\frac{\\sqrt{3}}{2} |1\\rangle\\]\n\n\n\nfrom math import pi, cos, sin \ndef get_state(theta):\n    return [cos(theta/2), sin(theta/2)]\n\ntheta = -pi/2\n\nqc = QuantumCircuit(1)\nqc.initialize(get_state(theta), 0)\nresult = Statevector(qc)\nresult.draw('latex')\n\n\\[\\frac{\\sqrt{2}}{2} |0\\rangle- \\frac{\\sqrt{2}}{2} |1\\rangle\\]\n\n\n\n# execute the quantum circuit\nqc.measure_all()\nquasi_dists = Sampler().run(qc, shots=1000).result().quasi_dists[0]\nprint(quasi_dists)\n\n{0: 0.523, 1: 0.477}\n\n\n\nplot_histogram(quasi_dists)"
  },
  {
    "objectID": "labs/Qiskit/cw1.html#tworzenie-stanu-dwukubitowego",
    "href": "labs/Qiskit/cw1.html#tworzenie-stanu-dwukubitowego",
    "title": "Biblioteka Qiskit wprowadzenie",
    "section": "Tworzenie stanu dwukubitowego",
    "text": "Tworzenie stanu dwukubitowego\n\\[\n\\ket{00}, \\ket{01}, \\ket{10}, \\ket{11}\n\\]\n\nqc = QuantumCircuit(2)\nresult = Statevector(qc)\nresult.draw('latex')\n\n\\[ |00\\rangle\\]\n\n\n\nqc = QuantumCircuit(2)\nqc.h(0)\nqc.h(1)\nresult = Statevector(qc)\nresult.draw('latex')\n\n\\[\\frac{1}{2} |00\\rangle+\\frac{1}{2} |01\\rangle+\\frac{1}{2} |10\\rangle+\\frac{1}{2} |11\\rangle\\]\n\n\n\nplot_bloch_multivector(result)\n\n\n\n\n\n\n\n\n\nqc = QuantumCircuit(2)\nqc.h(0)\nqc.cx(0,1)\nresult = Statevector(qc)\nresult.draw('latex')\n\n\\[\\frac{\\sqrt{2}}{2} |00\\rangle+\\frac{\\sqrt{2}}{2} |11\\rangle\\]\n\n\n\nplot_bloch_multivector(result)"
  },
  {
    "objectID": "labs/Qiskit/cw1.html#tworzenie-stanu-trzy-kubitowego",
    "href": "labs/Qiskit/cw1.html#tworzenie-stanu-trzy-kubitowego",
    "title": "Biblioteka Qiskit wprowadzenie",
    "section": "Tworzenie stanu trzy-kubitowego",
    "text": "Tworzenie stanu trzy-kubitowego\n\\[\n\\ket{000}, \\ket{001}, \\ket{010}, \\ket{011}, \\ket{100}, \\ket{101}, \\ket{110}, \\ket{111}\\]\n\nqc = QuantumCircuit(3)\nqc.x(0) # uwaga 0 wy kubit jest oznaczony od w stanie od prawej - nie od lewej (jak index)\n#qc.x(1)\nStatevector(qc).draw('latex')\n\n\\[ |001\\rangle\\]\n\n\nUruchom powyższy kod usuwajac poszczegolne komentarze i sprawdz wynik.\n\nfrom qiskit.visualization import circuit_drawer\n\nq = QuantumRegister(1)\nc = ClassicalRegister(1)\ncircuit = QuantumCircuit(q, c)\ncircuit.h(0)\ncircuit.measure(q, c)\ncircuit_drawer(circuit)\n\n      ┌───┐┌─┐\n  q7: ┤ H ├┤M├\n      └───┘└╥┘\nc4: 1/══════╩═\n            0"
  },
  {
    "objectID": "labs/Qiskit/cw2.html",
    "href": "labs/Qiskit/cw2.html",
    "title": "Bramki jednokubitowe",
    "section": "",
    "text": "Bramka X\nBramka X-gate reprezentowana jest przez macierz Pauli-X :\n\\[\nX = \\begin{pmatrix}\n0 & 1 \\\\\n1 & 0 \\\\\n\\end{pmatrix}\n\\]\nBramka X obraca kubit w kierunku osi na sferze Bloch’a o \\(\\pi\\) radianów. Zmienia \\(|0\\rangle\\) na \\(|1\\rangle\\) oraz \\(|1\\rangle\\) na \\(|0\\rangle\\). Jest często nazywana kwantowym odpowiednikiem bramki NOT lub określana jako bit-flip.\n\nfrom qiskit import QuantumCircuit, Aer, execute\n\nx_gate = QuantumCircuit(1)\nx_gate.x(0)\nx_gate.draw(output='mpl')\n\n\n\n\n\n\n\n\n\nfrom qiskit.visualization import plot_bloch_multivector\nbackend = Aer.get_backend('statevector_simulator')\nstate = execute(x_gate, backend).result().get_statevector()\nstate.draw('latex')\nplot_bloch_multivector(state)\n\n\n\n\n\n\n\n\n\nx_gate2 = QuantumCircuit(1)\nx_gate2.x(0)\nx_gate2.x(0)\nx_gate2.draw('mpl')\n\n\n\n\n\n\n\n\n\nbackend = Aer.get_backend('statevector_simulator')\nstate = execute(x_gate2, backend).result().get_statevector()\nstate.draw('latex')\nplot_bloch_multivector(state)\n\n\n\n\n\n\n\n\n\n\nbramka SX\nBramka SX jest pierwiastkiem kwadratowym bramki X. Dwukrotne zastosowanie powinno reazlizowac bramkę X.\n\\[\nSX = \\frac{1}{2}\\begin{pmatrix}\n1+i & 1-i \\\\\n1-i & 1+i \\\\\n\\end{pmatrix}\n\\]\n\nsx_gate = QuantumCircuit(1)\nsx_gate.sx(0)  \nsx_gate.draw(output='mpl')\n\n\n\n\n\n\n\n\n\nbackend = Aer.get_backend('statevector_simulator')\nresult = execute(sx_gate, backend).result().get_statevector()\nplot_bloch_multivector(result)\n\n\n\n\n\n\n\n\n\nsx_gate2 = QuantumCircuit(1)\nsx_gate2.sx(0)\nsx_gate2.sx(0)\nsx_gate2.draw(output='mpl')\n\n\n\n\n\n\n\n\n\nbackend = Aer.get_backend('statevector_simulator')\nresult = execute(sx_gate2, backend).result().get_statevector()\nplot_bloch_multivector(result)\n\n\n\n\n\n\n\n\n\n\nZ gate\n\\[\nZ = \\begin{pmatrix}\n1 & 0 \\\\\n0 & -1 \\\\\n\\end{pmatrix}\n\\]\n\nz_gate = QuantumCircuit(1)\nz_gate.z(0)  \nz_gate.draw(output='mpl')\n\n\n\n\n\n\n\n\n\nbackend = Aer.get_backend('statevector_simulator')\nresult = execute(z_gate, backend).result().get_statevector()\nplot_bloch_multivector(result)\n\n\n\n\n\n\n\n\n\n\nRZ gate\n\\[\nRZ = \\begin{pmatrix}\n1 & 0 \\\\\n0 & e ^{i \\phi } \\\\\n\\end{pmatrix}\n\\]\n\nimport numpy as np\npi = np.pi\nrz_gate = QuantumCircuit(1)\nrz_gate.rz(pi/2, 0)\nrz_gate.draw(output='mpl')\n\n\n\n\n\n\n\n\n\nbackend = Aer.get_backend('statevector_simulator')\nresult = execute(rz_gate, backend).result().get_statevector()\nplot_bloch_multivector(result)\n\n\n\n\n\n\n\n\n\nrz_gate2 = QuantumCircuit(1)\nrz_gate2.sx(0)\nrz_gate2.rz(pi/2, 0)\nrz_gate2.draw(output='mpl')\n\n\n\n\n\n\n\n\n\nbackend = Aer.get_backend('statevector_simulator')\nresult = execute(rz_gate2, backend).result().get_statevector()\nplot_bloch_multivector(result)\n\n\n\n\n\n\n\n\n\n\nHadamard gate\nBramka Hadamarda przetwarza stan \\(|0\\rangle\\) na kombinacje liniowa (superpozycje) \\(\\frac{|0\\rangle + |1\\rangle}{\\sqrt{2}}\\), co oznacza, że pomiar zwróci z takim samym prawdopodobieństwem stanu 1 lub 0. Stan ten często oznaczany jest jako: \\(|+\\rangle\\).\n\\[\nH = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}\n1 & 1 \\\\\n1 & -1 \\\\\n\\end{pmatrix}\n\\]\n\nh_gate = QuantumCircuit(1)\nh_gate.h(0)\nh_gate.draw(output='mpl')\n\n\n\n\n\n\n\n\n\nbackend = Aer.get_backend('statevector_simulator')\nresult = execute(h_gate, backend).result().get_statevector()\nplot_bloch_multivector(result)\n\n\n\n\n\n\n\n\n\nh_gate2 = QuantumCircuit(1)\nh_gate2.h(0)\nh_gate2.h(0)\nh_gate2.draw('mpl')\n\n\n\n\n\n\n\n\n\nbackend = Aer.get_backend('statevector_simulator')\nstate = execute(h_gate2, backend).result().get_statevector()\ndisplay(state.draw('latex'))\nplot_bloch_multivector(state)\n\n\\[ |0\\rangle\\]\n\n\n\n\n\n\n\n\n\n\n\nBramka parametryzowana Ry\n\\[\nR(\\alpha) = \\begin{pmatrix}\n\\cos{\\alpha} & -\\sin{\\alpha}\\\\\n\\sin{\\alpha} & \\cos{\\alpha} \\\\\n\\end{pmatrix}\n\\]\n\nry_gate = QuantumCircuit(1)\npi = np.pi\nry_gate.ry(pi/2,0)\nry_gate.draw(output='mpl')\n\n\n\n\n\n\n\n\n\nbackend = Aer.get_backend('statevector_simulator')\nresult = execute(ry_gate, backend).result().get_statevector()\nplot_bloch_multivector(result)\n\n\n\n\n\n\n\n\n\n\nCX gate (CNOT gate)\nThe controlled NOT (or CNOT or CX) gate acts on two qubits. It performs the NOT operation (equivalent to applying an X gate) on the second qubit only when the first qubit is \\(\\ket{1}\\) and otherwise leaves it unchanged.\nNote: Qiskit numbers the bits in a string from right to left.\n\\[\nCX = \\begin{pmatrix}\n1 & 0 & 0 & 0  \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 0 & 1 \\\\\n0 & 0 & 1 & 0 \\\\\n\\end{pmatrix}\n\\]\n\ncx_gate = QuantumCircuit(2)\ncx_gate.cx(0,1)\ncx_gate.draw(output='mpl')\n\n\n\n\n\n\n\n\n\nZadanie 1 - Sprawdź działanie bramki - CZ na dwukubitowym układzie. Następnie zbuduj drugi obwód złożony z bramek: H(1) (na drugim kubicie) CX(0,1) i H(1) - co możesz zaobserwować?\nZadanie 2 - zbuduj obwod kwantowy złożony z 10 kubitów, zastosuj bramkę H(0) do kubitu 0 i 9 bramek CNOT gdzie kubitem kontrolnym jest kubit 0 a targety to kubity od 1 do 9. Mozesz uzyć do pętli albo listy.\nZadanie 3 - zbuduj obwod kwantowy złożony z 10 kubitów. Zastosuj bramkę H do całego rejestru kwantowego.Następnie dodaj bramkę CNOT gdzie kubitami kontrolnymi sa kubity 1-9 a target to kubit 0. Następnie dodaj bramkę H do każdego kubitu.\n\nPrzydatne definicje dla obwodów\n\nfrom qiskit import QuantumRegister, ClassicalRegister, QuantumCircuit\n\nq = QuantumRegister(10)\nc = ClassicalRegister(10)\nci = QuantumCircuit(q,c)\nci.h(q)\nci.draw('mpl')\n\n\n\n\n\n\n\n\n\n# CCCH gate\nfrom qiskit.circuit.library.standard_gates import HGate\n\nCCCH = HGate().control(3)\n\nci.append(CCCH, [0,1,3,2])\nci.draw('mpl')"
  },
  {
    "objectID": "labs/do_testow.html",
    "href": "labs/do_testow.html",
    "title": "Wstęp do kwantowego uczenia maszynowego",
    "section": "",
    "text": "from sklearn.datasets import make_regression\nimport pennylane.numpy as np\nimport pennylane as qml\n\nX, y = make_regression(n_samples=100, n_features=2, noise=1, random_state=42)\n\nX = np.array(X)\ny = np.array(y)\n\n\n\ny_std = [(el-y.mean())/y.std() for el in y]\n\n\n\ndev = qml.device('default.qubit', wires=2)\n\n@qml.qnode(dev)\ndef qc2(datapoint, params):\n    # zakodujemy dane w bramke RX \n    qml.RX(datapoint[0], wires=0)\n    qml.RX(datapoint[1], wires=1)\n    # qml.AngleEmbedding(features=datapoint, wires=dev.wires)\n    # model to ogólna bramka unitarna zalezna od 3 parametrów\n    # qml.Rot(params[0], params[1], 0, wires=0)\n    qml.RX(params[0], wires=0)\n    qml.RX(params[1], wires=1)\n    qml.CNOT(wires=[0,1])\n\n    # mozna tez\n    # for i in rane(dev.wires)):\n    #    qml.RX(params[i], wires=i)\n\n    # bedziemy zwracali wartosc oczekiwana operatora Z \n    return qml.expval(qml.PauliZ(wires=0))\n\n\ndef loss_func(predictions):\n    total_losses = 0 \n    for i in range(len(y_std)):\n        output = y_std[i]\n        prediction = predictions[i]\n        loss = (prediction - output)**2\n        total_losses += loss\n    return total_losses\n\ndef cost_fn(params):\n    predictions = [qc2(x, params) for x in X]\n    cost = loss_func(predictions)\n    return cost\n\n\nopt1 = qml.GradientDescentOptimizer(stepsize=0.001)\n\nparams1 = np.array([0.05, 0.05], requires_grad=True)\n\nepochs = 10\n\nfor epoch in range(epochs):\n    \n    params1, prev_cost1 = opt1.step_and_cost(cost_fn, params1)\n    if (epoch+1)%10 == 0:\n        print(f\"Step = {epoch+1} Cost = {cost_fn(params1)} for params: {params1}\")\n\nStep = 10 Cost = 150.11150403462875 for params: [-0.00738039  0.09591009]\n\n\n\nimport random\ninit_param = [random.uniform(0, 2*3.1415) for _ in range(2)]\n\n\ninit_param\n\n[5.94068465726165, 5.438415845995134]\n\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n##################\n# YOUR CODE HERE #\n##################\n\n# ADJUST THE VALUES OF PHI, THETA, AND OMEGA\nphi, theta, omega = np.pi, np.pi/2, np.pi\n\n\n@qml.qnode(dev)\ndef hadamard_with_rz_rx():\n    qml.RZ(phi, wires=0)\n    qml.RX(theta, wires=0)\n    qml.RZ(omega, wires=0)\n    # qml.Hadamard(wires=0)\n    return qml.state(),qml.probs()\n\n\nhadamard_with_rz_rx()\n\n(tensor([-0.70710678-8.65956056e-17j,  0.        -7.07106781e-01j], requires_grad=True),\n tensor([0.5, 0.5], requires_grad=True))\n\n\n\nnp.exp(np.pi* 1.j)\n\n(-1+1.2246467991473532e-16j)"
  },
  {
    "objectID": "labs/Qiskit/cw3.html",
    "href": "labs/Qiskit/cw3.html",
    "title": "Bramki wielokubitowe",
    "section": "",
    "text": "from qiskit import (QuantumCircuit, QuantumRegister, ClassicalRegister, \n                    execute, Aer, __qiskit_version__)\nfrom qiskit.visualization import plot_bloch_multivector\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\ndef obwod(strategia):\n    qc = QuantumCircuit(QuantumRegister(1, name='qGra'))\n    for bramka in strategia:\n        if bramka == 'I':\n            qc.id(0)\n        elif bramka == 'H':\n            qc.h(0)\n        elif bramka == 'X':\n            qc.x(0)\n    return qc\n\n%matplotlib inline\ndef animacja(strategia):\n    qc = QuantumCircuit(QuantumRegister(1, name=\"q0\"))\n    symulator = Aer.get_backend('statevector_simulator')\n    wynik = execute(qc, backend=symulator).result()\n    stan = wynik.get_statevector()\n    display(stan)\n    print(\"stan poczatkowy:\")\n    display(plot_bloch_multivector(stan))\n    plt.show()\n    for it, bramka in enumerate(strategia):\n        if bramka == 'I':\n            qc.id(0)\n        elif bramka == 'H':\n            qc.h(0)\n        elif bramka == 'X':\n            qc.x(0)\n        wynik = execute(qc, backend=symulator).result()\n        stan = wynik.get_statevector()\n        print(\"stan po bramce\", bramka)\n        display(plot_bloch_multivector(stan))\n        plt.show()\nstrategia = 'XXX'\ndisplay(obwod(strategia).draw('mpl'))\nanimacja(strategia)\n\n\n\n\n\n\n\n\nStatevector([1.+0.j, 0.+0.j],\n            dims=(2,))\nstan poczatkowy:\n\n\n\n\n\n\n\n\n\nstan po bramce X\n\n\n\n\n\n\n\n\n\nstan po bramce X\n\n\n\n\n\n\n\n\n\nstan po bramce X\ndef sedzia(obwod):\n    qr = QuantumRegister(1)\n    cr = ClassicalRegister(1)\n    ob = QuantumCircuit(qr, cr)\n    ob.append(obwod, qr)\n    ob.measure(0, 0)\n    return  execute(ob, backend=Aer.get_backend('qasm_simulator'), shots=1000).result()\nstrategia = 'XXX'\nstats = sedzia(obwod(strategia)).get_counts()\nprint(stats)\n\n{'1': 1000}\nstrategia = 'HXH'\nstats = sedzia(obwod(strategia)).get_counts()\nprint(stats)\n\n{'0': 1000}\ndef klasycze_strategie():\n    wyniki = []\n    for ruch_1 in ['I','X']:\n        for ruch_2 in ['I','X']:\n            for ruch_3 in ['I','X']:\n                strategia = ruch_1 + ruch_2 + ruch_3\n                print(\"strategia\",strategia)\n                ob = obwod(strategia)\n                display(ob.draw('mpl'))\n                plt.show()\n                stats = sedzia(ob).get_counts()\n                print(\"statystyka\", stats)\n                wyniki.append((strategia, stats))\nklasycze_strategie()\n\nstrategia III\n\n\n\n\n\n\n\n\n\nstatystyka {'0': 1000}\nstrategia IIX\n\n\n\n\n\n\n\n\n\nstatystyka {'1': 1000}\nstrategia IXI\n\n\n\n\n\n\n\n\n\nstatystyka {'1': 1000}\nstrategia IXX\n\n\n\n\n\n\n\n\n\nstatystyka {'0': 1000}\nstrategia XII\n\n\n\n\n\n\n\n\n\nstatystyka {'1': 1000}\nstrategia XIX\n\n\n\n\n\n\n\n\n\nstatystyka {'0': 1000}\nstrategia XXI\n\n\n\n\n\n\n\n\n\nstatystyka {'0': 1000}\nstrategia XXX\n\n\n\n\n\n\n\n\n\nstatystyka {'1': 1000}\ndef kwantowe_strategie():\n    wyniki = []\n    for ruch_1 in ['H']:\n        for ruch_2 in ['I','X']:\n            for ruch_3 in ['H']:\n                strategia = ruch_1 + ruch_2 + ruch_3\n                print(\"strategia\",strategia)\n                ob = obwod(strategia)\n                display(ob.draw('mpl'))\n                plt.show()\n                stats = sedzia(ob).get_counts()\n                print(\"statystyka\", stats)\n                wyniki.append((strategia, stats))\nkwantowe_strategie()\n\nstrategia HIH\n\n\n\n\n\n\n\n\n\nstatystyka {'0': 1000}\nstrategia HXH\n\n\n\n\n\n\n\n\n\nstatystyka {'0': 1000}"
  },
  {
    "objectID": "labs/Qiskit/cw3.html#losowy-bajt",
    "href": "labs/Qiskit/cw3.html#losowy-bajt",
    "title": "Bramki wielokubitowe",
    "section": "Losowy bajt",
    "text": "Losowy bajt\n\n# generator liczb losowych\nfrom random import randrange\n''.join([str(randrange(2)) for i in range(8)])\n\n'00011001'\n\n\n\n# mozna takze zrealizowac jako rzut monetą \n\nimport random\nfor n in range(5):\n    if random.random()&lt;0.5:       #if the random number is less than 0.5 print heads\n        print('HEADS')\n    else:\n        print('TAILS')\n\nHEADS\nTAILS\nTAILS\nHEADS\nTAILS\n\n\n\n# LOSOWY BAJT \nfrom qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, execute, Aer\nq = QuantumRegister(8)\nc = ClassicalRegister(8)\n\nqc = QuantumCircuit(q,c)\n# tutaj kod losowania \nfor i in range(8):\n    if randrange(2) == 0:\n        qc.x(q[i])\n        \nqc.barrier()\nqc.measure(q,c)\nqc.draw('mpl')\n\n\n\n\n\n\n\n\n\njob = execute(qc, Aer.get_backend('qasm_simulator'), shots=10)\ncounts = job.result().get_counts()\n\n\ncounts\n\n{'00100100': 10}\n\n\n\nprint(list(counts)[0], \"wynosi: \", int(list(counts)[0],2))\n\n00100100 wynosi:  36\n\n\n\n# losowy kwantowo bajt \n# LOSOWY BAJT \nfrom qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, execute, Aer\nq = QuantumRegister(8)\nc = ClassicalRegister(8)\n\nqc = QuantumCircuit(q,c)\n# tutaj kod losowania \nqc.h(q)        \nqc.barrier()\nqc.measure(q,c)\ndisplay(qc.draw('mpl'))\njob = execute(qc, Aer.get_backend('qasm_simulator'), shots=10)\ncounts = job.result().get_counts()\ncounts\n\n\n\n\n\n\n\n\n{'01000110': 1,\n '00001001': 1,\n '00100100': 1,\n '11000000': 1,\n '01000011': 1,\n '11010001': 1,\n '11100110': 1,\n '11100100': 1,\n '10101011': 1,\n '11001100': 1}\n\n\n\nfor el in counts:\n    print(int(el,2))\n\n70\n9\n36\n192\n67\n209\n230\n228\n171\n204\n\n\n\n# losowanie z zakresu liczb 0-15 \nn = 4\nq = QuantumRegister(n)\nc = ClassicalRegister(n)\ncircuit = QuantumCircuit(q, c)\n\nfor j in range(n):\n    circuit.h(q[j])\n    \ncircuit.measure(q,c)\n\njob = execute(circuit,  Aer.get_backend('qasm_simulator'), shots=1000)\n\n# get the histogram of bit string results, convert it to one of integers and plot it\nbit_counts = job.result().get_counts()\nint_counts = {}\nfor bitstring in bit_counts:\n    int_counts[ int(bitstring,2) ] = bit_counts[bitstring]\n\nfrom qiskit.tools.visualization import plot_histogram    \nplot_histogram(int_counts)"
  },
  {
    "objectID": "labs/Qiskit/cw3.html#swap-gate",
    "href": "labs/Qiskit/cw3.html#swap-gate",
    "title": "Bramki wielokubitowe",
    "section": "SWAP GATE",
    "text": "SWAP GATE\n\\[\n\\text{SWAP}\\ket{01} = \\ket{10}\n\\]\n\nqc = QuantumCircuit(2)\nqc.x(0)\nqc.swap(0,1)\nqc.measure_all()\nqc.draw('mpl')\n\n\n\n\n\n\n\n\n\ncounts = execute(qc, Aer.get_backend('qasm_simulator'), shots=1).result()\ncounts.get_counts()"
  },
  {
    "objectID": "labs/Qiskit/cw3.html#stany-splątane",
    "href": "labs/Qiskit/cw3.html#stany-splątane",
    "title": "Bramki wielokubitowe",
    "section": "Stany splątane",
    "text": "Stany splątane\n\nqr = QuantumRegister(2)\nqc = QuantumCircuit(qr)\nqc.h(qr[0])\nqc.cx(0,1)\nbackend = Aer.get_backend('statevector_simulator')\njob = execute(qc, backend)\nresult = job.result()\nstate = result.get_statevector()\n\n\ndisplay(qc.draw('mpl'))\nstate.draw('latex')\n\n\n\n\n\n\n\n\n\\[\\frac{\\sqrt{2}}{2} |00\\rangle+\\frac{\\sqrt{2}}{2} |11\\rangle\\]\n\n\n\nqr = QuantumRegister(2)\nqc = QuantumCircuit(qr)\nqc.h(qr[0])\nqc.cx(0,1)\nqc.x(1)\nbackend = Aer.get_backend('statevector_simulator')\njob = execute(qc, backend)\nresult = job.result()\nstate = result.get_statevector()\ndisplay(qc.draw('mpl'))\nstate.draw('latex')\n\n\n\n\n\n\n\n\n\\[\\frac{\\sqrt{2}}{2} |01\\rangle+\\frac{\\sqrt{2}}{2} |10\\rangle\\]\n\n\n\nqr = QuantumRegister(2)\nqc = QuantumCircuit(qr)\nqc.h(qr[0])\nqc.cx(0,1)\nqc.z(1)\nbackend = Aer.get_backend('statevector_simulator')\njob = execute(qc, backend)\nresult = job.result()\nstate = result.get_statevector()\ndisplay(qc.draw('mpl'))\nstate.draw('latex')\n\n\n\n\n\n\n\n\n\\[\\frac{\\sqrt{2}}{2} |00\\rangle- \\frac{\\sqrt{2}}{2} |11\\rangle\\]\n\n\n\nqr = QuantumRegister(2)\nqc = QuantumCircuit(qr)\nqc.h(qr[0])\nqc.cx(0,1)\nqc.x(1)\nqc.z(1)\nbackend = Aer.get_backend('statevector_simulator')\njob = execute(qc, backend)\nresult = job.result()\nstate = result.get_statevector()\ndisplay(qc.draw('mpl'))\nstate.draw('latex')\n\n\n\n\n\n\n\n\n\\[\\frac{\\sqrt{2}}{2} |01\\rangle- \\frac{\\sqrt{2}}{2} |10\\rangle\\]"
  },
  {
    "objectID": "labs/Qiskit/cw3.html#half-adder-cirquit",
    "href": "labs/Qiskit/cw3.html#half-adder-cirquit",
    "title": "Bramki wielokubitowe",
    "section": "Half adder cirquit",
    "text": "Half adder cirquit\n\nNapisz operator 1+1 na układzie 4 kubitów\n\\[\n0+0 = 00\n\\] \\[\n0+1 = 01\n\\] \\[\n1+0 = 01\n\\] \\[\n1+1 = 10\n\\]\nzauwaz, ze mamy dwa typy rozwiązań:\n\ndwa bity wejsciowe są takie same (00, 11) i dają na prawym bicie odpowiedzi 0.\ndwa bity wejsciowe są rózne (10,01) i dają na prawym bicie odpowiedzi 1.\n\nAby napisać prawidłowe rozwiązanie musimy stworzyć bramki, które będą rozpoznawać czy dwa kubity są takie same czy tez rózne. Dla przypomnienia - klasycznie rolę taką pełni bramka XOR.\n\n\n\nInput 1\nInput 2\nXOR\n\n\n\n\n0\n0\n0\n\n\n0\n1\n1\n\n\n1\n1\n1\n\n\n1\n0\n0\n\n\n\nPodobnie działa bramka CNOT\n\nqc  = QuantumCircuit(2)\nqc.cx(0,1)\nqc.draw(output='mpl')\n\n\n\n\n\n\n\n\n\nqc = QuantumCircuit(4,2)\n# zakodowanie danych wejściowych do kubitu 1 i 2 \nqc.x(0) \nqc.x(1) # bo chcemy policzyc 1+1 \n# uzyjemy CNOT - bramka XOR dla porownania kubitow 1 i 2\nqc.cx(0,2)\nqc.cx(1,2)\nqc.measure(2,0) # wydobycie wyniku XOR\nqc.measure(3,1) # wydobycie wyniku AND\nqc.draw(output='mpl')\n\n\n\n\n\n\n\n\nZastosowanie dwóch CNOT do inputów rozwiązuje nam problem prawego bitu odpowiedzi.\nCo z pierszym bitem odpowiedzi otrzymywanym po pomiarzze q3 ?\n\njego wartość dla pierwszych trzech równań zawsze wynosi 0.\n\nJednak dla równania 1+1 powinniśmy otrzymać 1.\nDo rozwiązania tego problemu mozna wykorzystać bramkę operującą na 3 kubitach. Bramka ta to bramka Toffoli.\n\nqc = QuantumCircuit(4,2)\n# zakodowanie danych wejściowych do kubitu 1 i 2 \nqc.x(0) \nqc.x(1) # bo chcemy policzyc 1+1 \n# uzyjemy CNOT\nqc.cx(0,2)\nqc.cx(1,2)\nqc.ccx(0,1,3) # AND\nqc.measure(2,0) # wydobycie wyniku XOR\nqc.measure(3,1) # wydobycie wyniku AND\nqc.draw(output='mpl')\n\n\n\n\n\n\n\n\n\nfrom qiskit.visualization import plot_histogram\ncounts = execute(qc,Aer.get_backend('qasm_simulator'),shots=1).result().get_counts()\nplot_histogram(counts)\n\n\n\n\n\n\n\n\nDla przypomnienia:\n\nprint(\"wynik 1+1 =\",int('10',2))\n\nwynik 1+1 = 2\n\n\nsprawdźmy wszystkie mozliwe wyniki\n\nfor input in ['00','01','10','11']:\n    \n    mycircuit1 = QuantumCircuit(4,2)\n    \n    #Initialization - Note qiskit order\n    if input[0] == '1':\n        mycircuit1.x(1)\n    if input[1] == '1':\n        mycircuit1.x(0)\n\n    mycircuit1.cx(0,2)\n    mycircuit1.cx(1,2)\n    mycircuit1.ccx(0,1,3)\n\n    mycircuit1.measure(2,0)\n    mycircuit1.measure(3,1)\n\n    job = execute(mycircuit1,Aer.get_backend('qasm_simulator'),shots=1)\n    counts = job.result().get_counts(mycircuit1)\n    print(\"Input:\", input, \"Output:\", counts)\n\nInput: 00 Output: {'00': 1}\nInput: 01 Output: {'01': 1}\nInput: 10 Output: {'01': 1}\nInput: 11 Output: {'10': 1}\n\n\n\nZadanie - czy potrafisz utworzyć 3 kubitową wersję bramki OR"
  },
  {
    "objectID": "labs/zaoczne/zad3.html",
    "href": "labs/zaoczne/zad3.html",
    "title": "Zadanie",
    "section": "",
    "text": "Utwórz obwód kwantowy i dodaj parametryzowaną bramkę \\(R_x\\) z kątem ustawionym jako pi/4\nOblicz wartość oczekiwaną operatora \\(&lt;\\sigma_z&gt;\\) wykorzystując qml.expval(qml.PauliZ(0))\nBramka (i operator) Z, w bazie obliczeniowej dany jest macierzą: \\[\n\\textbf{Z} = \\begin{bmatrix} 1 \\,\\,\\,\\,\\,\\,\\,\\, 0 \\\\ 0 \\,\\, -1 \\end{bmatrix}\n\\]\nOperator ten mierzy różnicę pomiędzy prawdopodobieństwem, że kubit jest w stanie \\(\\ket{0}\\) a prawdopodobieństwem, że jest w stanie \\(\\ket{1}\\)\nW ogólności wartość oczekiwana (wartość średnia wyniku pomiaru w bazie operatora Z) dana jest wzorem: \\[\n\\textbf{&lt;Z&gt;} = \\bra{\\psi} \\textbf{Z} \\ket{\\psi}\n\\]\nNiech \\[\n\\ket{\\psi} = \\alpha\\ket{0} + \\beta\\ket{1}\n\\] wtedy \\[\n\\bra{\\psi} = \\alpha^*\\bra{0} + \\beta^*\\bra{1}\n\\]\nMożemy obliczyć: \\[\n\\bra{\\psi} \\textbf{Z} \\ket{\\psi}  = (\\alpha^*\\bra{0} + \\beta^*\\bra{1} ) \\,\\,\\, Z \\,\\,\\,(\\alpha\\ket{0} + \\beta\\ket{1}) = |\\alpha|^2 - |\\beta|^2\n\\] Czyli dla kubitu w stanie \\(\\ket{0}\\) \\[\n\\textbf{&lt;Z&gt;} = 1  \n\\] Dla kubitu w stanie \\(\\ket{1}\\) \\[\n\\textbf{&lt;Z&gt;} = -1  \n\\] Dla kubitu w superpozycji \\(\\ket{0} +\\ket{1}\\) \\[\n\\textbf{&lt;Z&gt;} = 0  \n\\]"
  },
  {
    "objectID": "labs/zaoczne/zad3.html#zadanie---obwód-kwantowy-z-optymalizacją",
    "href": "labs/zaoczne/zad3.html#zadanie---obwód-kwantowy-z-optymalizacją",
    "title": "Zadanie",
    "section": "Zadanie - Obwód kwantowy z optymalizacją",
    "text": "Zadanie - Obwód kwantowy z optymalizacją\n\nNapisz nowy obwód kwantowy, który zawierać będzie tylko bramkę \\(R_X\\) dla dowolnego parametru \\(\\theta\\)\noblicz i uzasadnij, że wartość oczekiwana dla stanu \\(\\ket{\\psi} = R_X \\, \\ket{0}\\) \\[&lt;Z&gt; = cos^2(\\theta /2)- sin^2(\\theta /2) = cos(\\theta)\\]\n\nZałóżmy, że nasz problem obliczeniowy sprowadza się do wygenerowania wartości oczekiwanej o wartości 0.5.\n\\[\n\\textbf{&lt;Z&gt;} = \\bra{\\psi} \\textbf{Z} \\ket{\\psi} = 0.5\n\\]\nNapisz program znajdujący rozwiązanie - szukający wagę \\(\\theta\\) dla naszego obwodu\n\nZdefiniuj funkcję kosztu, którą bedziemy minimalizować \\((Y - y)^2\\)\nzainicjuj rozwiązanie \\(theta=0.01\\) i przypisz do tablicy array np.array(0.01, requires_grad=True)\nJako opt wybierz spadek po gradiencie : opt = qml.GradientDescentOptimizer(stepsize=0.1)\nuzyj poniższego kodu do wygenerowania pętli obiczeń\n\n\nepochs = 100\n\nfor epoch in range(epochs):\n    theta = opt.step(cost_fn, theta)\n\n    if epoch % 10 == 0:\n        print(f\"epoka: {epoch}, theta: {theta}, koszt: {cost_fn(theta)}\")"
  },
  {
    "objectID": "labs/zaoczne/zad3.html#bramki-dwukubitowe",
    "href": "labs/zaoczne/zad3.html#bramki-dwukubitowe",
    "title": "Zadanie",
    "section": "Bramki dwukubitowe",
    "text": "Bramki dwukubitowe\n\\[\n\\renewcommand{\\bra}[1]{\\left \\langle #1 \\right \\rvert}\n\\renewcommand{\\ket}[1]{\\left \\rvert #1 \\right \\rangle}\n\\renewcommand{\\braket}[2]{\\left \\langle #1 \\middle \\rvert #2 \\right \\rangle}\n\\]\nO bramkach dwukubitowych wspominaliśmy juz tutaj\nJedną z bramek realizującą zadania na dwóch kubitach jest bramka CNOT, która na bazie bitu kontrolnego decyduje czy zastosować operację X do drugiego kubitu.\n\\[\n\\text{CNOT} = \\begin{bmatrix} 1 \\,\\, \\,\\,\\, 0 \\,\\,\\,\\,\\, 0 \\,\\,\\,\\,\\, 0 \\\\\n0\\,\\, \\,\\,\\, 1 \\,\\,\\,\\,\\, 0 \\,\\,\\,\\,\\, 0 \\\\\n0\\,\\,\\,\\,\\, 0\\,\\,\\,\\,\\,  0 \\,\\,\\,\\,\\, 1 \\\\ 0\\,\\,\\,\\,\\, 0\\,\\,\\,\\,\\, 1\\,\\,\\,\\,\\, 0 \\end{bmatrix}\n\\]\n\\[ \\text{CNOT} \\ket{00} = \\ket{00} \\]\n\\[ \\text{CNOT} \\ket{10} = \\ket{11} \\]\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=2, shots=100)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.CNOT(wires=[0,1])\n    #return qml.state()\n    return qml.counts()\n\nqc()\n\n\nimport matplotlib.pyplot as plt\nqml.drawer.use_style(\"sketch\")\nfig, ax = qml.draw_mpl(qc)()\nplt.show()\n\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=2, shots=100)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.CNOT(wires=[0,1])\n    qml.X(wires=1)\n    #return qml.state()\n    return qml.counts()\n\nqc()\n\n\nfig, ax = qml.draw_mpl(qc)()\nplt.show()\n\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=2, shots=100)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.CNOT(wires=[0,1])\n    qml.Z(wires=1)\n    #return qml.state()\n    return qml.counts()\n\nqc()\n\n\nfig, ax = qml.draw_mpl(qc)()\nplt.show()\n\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=2, shots=100)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.CNOT(wires=[0,1])\n    qml.X(wires=1)\n    qml.Z(wires=1)\n    #return qml.state()\n    return qml.counts()\n\nqc()\n\n\nfig, ax = qml.draw_mpl(qc)()\nplt.show()"
  },
  {
    "objectID": "labs/zaoczne/zad3.html#zadanie",
    "href": "labs/zaoczne/zad3.html#zadanie",
    "title": "Zadanie",
    "section": "Zadanie",
    "text": "Zadanie\nutwórz obwód dwu kubitowy: - bramka CNOT 0,1 - bramka CNOT (odwrocona) 1,0 - bramka CNOT 0,1\nOpisz jak działa ta kombinacja na stany: \\(\\ket{00}, \\ket{11}, \\ket{01},\\ket{10}\\)\nZnajdź odpowiednik tej kombinacji w bibliotece Pennylane."
  },
  {
    "objectID": "labs/zaoczne/zad3.html#zadanie-1",
    "href": "labs/zaoczne/zad3.html#zadanie-1",
    "title": "Zadanie",
    "section": "Zadanie",
    "text": "Zadanie\nutwórz obwód dwu kubitowy: - bramka CNOT - bramki H na kazdym kubicie - bramka CNOT - bramki H na kazdym kubicie - bramka CNOT"
  },
  {
    "objectID": "labs/zaoczne/zad3.html#stany-ghz",
    "href": "labs/zaoczne/zad3.html#stany-ghz",
    "title": "Zadanie",
    "section": "Stany GHZ",
    "text": "Stany GHZ\nJak realizują się stany splątane dla więcej niz dwóch kubitów\nStany Greenbergerha-Hornea-Zeilingera\npublikacja\n\ndev = qml.device('default.qubit', wires=3, shots=100)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.CNOT(wires=[0,1])\n    qml.CNOT(wires=[1,2])\n    #return qml.state()\n    return qml.counts()\n\nqc()"
  },
  {
    "objectID": "labs/zaoczne/zad3.html#kopiowanie-kubitu",
    "href": "labs/zaoczne/zad3.html#kopiowanie-kubitu",
    "title": "Zadanie",
    "section": "Kopiowanie Kubitu",
    "text": "Kopiowanie Kubitu\nKlasyczne komputery bardzo często wykorzystując operację kopiowania.\nZobaczmy jak taka operacja wygląda dla kubitów.\nRozwazmy obwod z operatorem C, który w działaniu na dwa kubity kopiuje wartość pierwszego kubitu na wynik drugiego. Drugi kubit mozna na początku ustawić w dowolnym stanie.\nChcemy skopiować stan \\(\\ket{\\psi_0} = a\\ket{0} + b\\ket{1}\\)\nStan początkowy układu: \\(\\ket{\\psi_0} \\otimes \\ket{0}\\)\nChcemy przekształcić na \\(\\ket{\\psi_0} \\otimes \\ket{\\psi_0}\\) czyli\n\\[\nC \\left(\\ket{\\psi_0} \\otimes \\ket{0}\\right) = \\ket{\\psi_0} \\otimes \\ket{\\psi_0}\n\\]\nLewa strona\n\\[\nC \\left(\\ket{\\psi_0} \\otimes \\ket{0}\\right) = C\\left(   (a\\ket{0} + b\\ket{1} )  \\otimes \\ket{0} \\right)\n\\] \\[\nC\\left( a\\ket{0} \\otimes \\ket{0} + b\\ket{1}\\otimes \\ket{0} \\right) = a C \\left(\\ket{0} \\otimes \\ket{0}\\right) + b C \\left( \\ket{1}\\otimes \\ket{0}\\right)\n\\] \\[\na \\ket{00} + b \\ket{11}\n\\]\nPrawa strona \\[\n\\ket{\\psi_0} \\otimes \\ket{\\psi_0}  = a^2 \\ket{00} + ab\\ket{01} + ab\\ket{10} + b^2\\ket{11}\n\\]"
  },
  {
    "objectID": "labs/zaoczne/zad3.html#zadanie-2",
    "href": "labs/zaoczne/zad3.html#zadanie-2",
    "title": "Zadanie",
    "section": "Zadanie",
    "text": "Zadanie\n\nNapisz operator 1+1 na układzie 4 kubitów\n\\[\n0+0 = 00\n\\] \\[\n0+1 = 01\n\\] \\[\n1+0 = 01\n\\] \\[\n1+1 = 10\n\\]\nzauwaz, ze mamy dwa typy rozwiązań:\n\ndwa bity wejsciowe są takie same (00, 11) i dają na prawym bicie odpowiedzi 0.\ndwa bity wejsciowe są rózne (10,01) i dają na prawym bicie odpowiedzi 1.\n\nAby napisać prawidłowe rozwiązanie musimy stworzyć bramki, które będą rozpoznawać czy dwa kubity są takie same czy tez rózne. Dla przypomnienia - klasycznie rolę taką pełni bramka XOR.\n\n\n\nInput 1\nInput 2\nXOR\n\n\n\n\n0\n0\n0\n\n\n0\n1\n1\n\n\n1\n1\n1\n\n\n1\n0\n0\n\n\n\nPodobnie działa bramka CNOT\n\ndev = qml.device('default.qubit', wires=4, shots=1)\n\n@qml.qnode(dev)\ndef qc(input='00'):\n    if input[0]=='1':\n        qml.X(wires=0)\n    if input[1]=='1':\n        qml.X(wires=1)\n    qml.CNOT(wires=[0,3])\n    qml.CNOT(wires=[1,3])\n    #return qml.state()\n    return qml.counts(wires=[2,3])\n\nqc()\n\n\nfig, ax = qml.draw_mpl(qc)()\nplt.show()\n\n\nfor input in ['00','01','10','11']:\n    print(f\"wartosci poczatkowe: {input} : wynik {qc(input)}\")\n\nZastosowanie dwóch CNOT do inputów rozwiązuje nam problem prawego bitu odpowiedzi.\nCo z pierszym bitem odpowiedzi otrzymywanym po pomiarzze q3 ?\n\njego wartość dla pierwszych trzech równań zawsze wynosi 0.\n\nJednak dla równania 1+1 powinniśmy otrzymać 1.\nDo rozwiązania tego problemu mozna wykorzystać bramkę operującą na 3 kubitach. Bramka ta to bramka Toffoli.\n\ndev = qml.device('default.qubit', wires=4, shots=1)\n\n@qml.qnode(dev)\ndef qc(input='00'):\n    if input[0]=='1':\n        qml.X(wires=0)\n    if input[1]=='1':\n        qml.X(wires=1)\n    qml.CNOT(wires=[0,3])\n    qml.CNOT(wires=[1,3])\n    qml.Toffoli(wires=[0,1,2])\n    #return qml.state()\n    return qml.counts(wires=[2,3])\n\n\nfor input in ['00','01','10','11']:\n    print(f\"wartosci poczatkowe: {input} : wynik {qc(input)}\")\n\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=4, shots=1)\n\n@qml.qnode(dev)\ndef qc():\n    qml.X(wires=0)\n    qml.X(wires=1)\n    qml.CNOT([0,1])\n    qml.CNOT([0,2])\n    qml.Toffoli([0,1,3])\n    return qml.counts(wires=[2,3])\n\nqc()\n\nprint(\"wynik 1+1 =\",int('10', 2))"
  },
  {
    "objectID": "labs/zaoczne/zad2.html",
    "href": "labs/zaoczne/zad2.html",
    "title": "Proste kwantowe obwody",
    "section": "",
    "text": "Na ostatnich zajęciach wyprodukowaliśmy klasyczną i kwantową sieć neuronową realizowaną w bibliotece PyTorch i Pennylane.\nKod naszej wartwy ukrytej w której użyliśmy obwodu kwantowego realizował następujące obiekty i funkcje:\nNa tych zajęciach nauczymy się tworzyć proste obwody kwantowe.\nZaczynamy!\nObwody kwantowe składają się z rejestrów, które reprezentują poszczególne kubity.\nDomyślnie kubity inicjalizujemy w stanie 0.\nLiczbę rejestrów możesz ustalić parametrem wires przy definicji środowiska wykonawczego device.\nOperacje wykonywane na kubitach nazywamy bramkami. Operacje te można wykonywać na jednym albo i wielu kubitach na raz. Domyślnie będziemy optymalizować algortymy aby składały się z jak najmniejszej ilości bramek działających na dużą liczbę kubitów.\nGraficznie można rozumieć realizację algorytmu jako stosowanie bramek na poszczególnych kubitach.\nW bibliotece PennyLane, obwody kwantowe reprezentowane są przez kwantowe funkcje, realizowane przez klasyczne funkcje w pythonie.\nSchemat kodu penny lane możemy zapisać jako:\nPrzykładowo\nMatematycznie całość możemy zapisać jako:\nTyle teoria … a jak zakodować i wykorzystać ?"
  },
  {
    "objectID": "labs/zaoczne/zad2.html#jeden-kubit",
    "href": "labs/zaoczne/zad2.html#jeden-kubit",
    "title": "Proste kwantowe obwody",
    "section": "Jeden kubit",
    "text": "Jeden kubit\nPrzygotujmy kod dla obwodu kwantowego realizującego jeden kubit z którym nic nie robimy.\n\nimport pennylane as qml\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(dev)\ndef qc():\n    ## tu pojawi się kod przetwarzający nasz kubit\n    ## ale teraz nic z nim nie robimy \n    return qml.state()\n\n\nqc()\n\nwektor \\([1,0]\\) można interpretować jako stan \\(\\ket{0}\\) czyli jako wartość bitu \\(0\\).\nNatomiast wykorzystując metodę qml.probs() możesz zwrócić kwadraty amplitud czyli prawdopodobieństow otrzymania 0 i 1.\n\nimport pennylane as qml\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(dev)\ndef qc2():\n    return qml.probs(wires=0)\n\n\nqc2()\n\nzobaczmy jak zainicjalozować stan \\(\\ket{1}= [0,1]^T\\) \\[\n\\ket{\\psi}=\\ket{1}\n\\]\n\nfrom pennylane import numpy as np\nfrom pennylane.ops import StatePrep\n\nstan = np.array([0,1]) # stan do inicjalizacji\n\n@qml.qnode(dev)\ndef qc():\n    StatePrep(stan, wires=0)\n    return qml.state()\n\nqc()\n\n\n@qml.qnode(dev)\ndef qc():\n    StatePrep(stan, wires=0)\n    return qml.probs()\n\nqc()\n\nutwórzmy pełną superpozycję stanu 0 i 1. \\[\n\\ket{\\psi}=\\frac{1}{\\sqrt{2}} (\\ket{0} + \\ket{1} )\n\\]\n\nstan = np.array([1/np.sqrt(2), 1/np.sqrt(2)])\n\n@qml.qnode(dev)\ndef qc_s():\n    qml.StatePrep(stan,wires=0)\n    return qml.state()\n\nprint(f\"amplitudy: {qc_s()}\")\n\n\n@qml.qnode(dev)\ndef qc_p():\n    qml.StatePrep(stan,wires=0)\n    return qml.probs()\n\nprint(f\"prwadopodobieństwa: {qc_p()}\")\n\nprint(f\"test czy amp^2 = prawdopodobienstwo: {qc_s()**2 == qc_p()}\")\n\nZADANIE Napisz funkcję generującą stan jednego kubitu jako funkcję kąta \\(\\theta\\)\ndef stan_kubitu(theta):\n    pass # Twoj kod \n\n\\(\\ket{\\psi}= [\\cos(\\frac{\\theta}{2}), \\sin(\\frac{\\theta}{2})]\\)\n\nWygeneruj obwód z pojedynczym kubitem inicjalizujący stan \\(\\ket{0}\\) , \\(\\ket{1}\\) oraz \\(\\frac{1}{\\sqrt{2}} (\\ket{0} + \\ket{1} )\\)\n\nStany dwukubitowe\n\\[\n\\ket{\\psi_0}=\\ket{00}\n\\] \\[\n\\ket{\\psi_1}=\\ket{01}\n\\] \\[\n\\ket{\\psi_2}=\\ket{10}\n\\] \\[\n\\ket{\\psi_3}=\\ket{11}\n\\]\nKtóry stan wygeneruje poniższy kod?\n\ndev = qml.device(\"default.qubit\", wires=2)\n@qml.qnode(dev)\ndef qc():\n    return qml.state()\n\nqc()\n\nA co jesli chcemy otrzymać superpozycję wszystkich stanów bazowych \\[\n\\ket{\\psi}=\\frac{1}{2}\\left( \\ket{00} + \\ket{01} + \\ket{10} + \\ket{11} \\right)\n\\]\n\ndev = qml.device(\"default.qubit\", wires=2)\n\nstan = np.array([1/2, 1/2, 1/2, 1/2])\n\nprawd = [i**2 for i in stan]\nprint(f\"test: suma prawdopodobienst {np.sum(prawd)}\")\n\n@qml.qnode(dev)\ndef qc():\n    StatePrep(stan, wires=[0,1])\n    return qml.state()\n\nqc()"
  },
  {
    "objectID": "labs/zaoczne/zad2.html#bramki-jednokubitowe",
    "href": "labs/zaoczne/zad2.html#bramki-jednokubitowe",
    "title": "Proste kwantowe obwody",
    "section": "Bramki jednokubitowe",
    "text": "Bramki jednokubitowe\n\nBramka X\nBramka X-gate reprezentowana jest przez macierz Pauli-X :\n\\[\nX = \\begin{pmatrix}\n0 & 1 \\\\\n1 & 0 \\\\\n\\end{pmatrix}\n\\]\nBramka X obraca kubit w kierunku osi na sferze Bloch’a o \\(\\pi\\) radianów. Zmienia \\(|0\\rangle\\) na \\(|1\\rangle\\) oraz \\(|1\\rangle\\) na \\(|0\\rangle\\). Jest często nazywana kwantowym odpowiednikiem bramki NOT lub określana jako bit-flip.\n\\[ \\sigma_x \\ket{0} = \\ket{1} \\,\\,\\, \\sigma_x\\ket{1} = \\ket{0} \\]\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\ndef qc():\n    qml.X(wires=0)\n    return qml.state()\n\nqc()\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\ndef qc():\n    qml.PauliX(wires=0)\n    return qml.state()\n\nqc()\n\n\nqml.draw_mpl(qc)()\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\ndef qc():\n    qml.PauliX(wires=0)\n    qml.X(wires=0)\n    return qml.state()\n\nqml.draw_mpl(qc)()\nqc()\n\n\n\nBramka Hadamarda\nBramka Hadamarda przetwarza stan \\(|0\\rangle\\) na kombinacje liniowa (superpozycje) \\(\\frac{|0\\rangle + |1\\rangle}{\\sqrt{2}}\\), co oznacza, że pomiar zwróci z takim samym prawdopodobieństwem stanu 1 lub 0. Stan ten często oznaczany jest jako: \\(|+\\rangle\\).\n\\[\nH = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}\n1 & 1 \\\\\n1 & -1 \\\\\n\\end{pmatrix}\n\\]\n\\[ H\\ket{0} = \\frac{\\sqrt{2}}{2} (\\ket{0}+ \\ket{1})\\] \\[ H\\ket{1} = \\frac{\\sqrt{2}}{2}(\\ket{0}- \\ket{1})\\]\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\n\n\ndef qc():\n    qml.Hadamard(wires=0)\n    return qml.state()\n\nqml.draw_mpl(qc)()\nqc()\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\n\n\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.Hadamard(wires=0)\n    return qml.state()\n\nqml.draw_mpl(qc)()\nqc()\n\n\ndev = qml.device(\"default.qubit\", wires=2)\n@qml.qnode(dev)\n\n\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.Hadamard(wires=1)\n    return qml.state()\n\nqml.draw_mpl(qc)()\nqc()\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\n\n\ndef qc(state):\n    if state==1:\n        qml.X(wires=0)\n    qml.Hadamard(wires=0)\n    qml.PauliX(wires=0)\n    qml.Hadamard(wires=0)\n    return qml.state()\n\nqml.draw_mpl(qc)(0)\nqc(0)\n\n\nqc(1)"
  },
  {
    "objectID": "labs/zaoczne/zad2.html#do-czego-możemy-wykorzystać-te-proste-obwody",
    "href": "labs/zaoczne/zad2.html#do-czego-możemy-wykorzystać-te-proste-obwody",
    "title": "Proste kwantowe obwody",
    "section": "do czego możemy wykorzystać te proste obwody?",
    "text": "do czego możemy wykorzystać te proste obwody?\n\nLosowy bit\nutwórz obwód kwantowy zawierający jeden qubit. Utwórz superpozycję stanu zero i jeden z wykorzystaniem odpowiedniej bramki.\n-[a)] wyświetl stan po pomiarze pojedynczego kubitu\n-[b)] wyświetl prawdopodobieństwa otrzymania stanu 0 i 1\n-[c)] uruchom obwód 3 razy (do dev dodaj parametr , shots=3) i sprawdź wyniki otrzymywane przez metodę qml.counts() link\n-[d)] uruchom powyzszą prcedurę 100 razy\nDo jakiego zdarzenia losowego podobne są wyniki?\n\n\nLosowy bajt\n-[a)] bajt to 8 bitów - jaki zakres wartości jesteś w stanie przechowywać w 8 kubitach ?\n-[b)] wygeneruj 3 proby w pełni losowego bajtu - odkoduj wyniki w systemie int\n-[c)] oblicz różnicę dwóch bajtów dla których pierwsze cztery bity to 0, piąty bit pierwszego bajtu to 0 a drugiego bajtu to 1 . pozostałe bity są równe 1.\n\n\nGra w obracanie monety\nWykorzystując powyżej zdefiniowane bramki możemy zrealizowa następującą grę:\n\nW grze bierze udział dwóch graczy. Gracze dysponują monetą, której nie widzą w trakcie gry (np. jest zamknięta w pudełku). Natomiast wiedzą, że początkowo moneta ułożona jest orłem do góry (w stanie \\(\\ket{0}\\)) Gra polega na wykonaniu trzech ruchów na przemian. Każdy ruch polega na odwróceniu monety bądź pozostawieniu jej w takim stanie w jakim była. Gracze nie wiedzą jaki ruch wykonuje przeciwnik. Po ostatnim ruchu pudełko zostaje otwarte i gracze sprawdzają w jakiej pozycji jest moneta. Pierwszy gracz wygrywa jeśli moneta jest w pozycji orła, a drugi jeśli przeciwnie.\n\nSzansa wygranej wynosi dla każdego \\(50\\%\\) i jak można sprawdzic nie istnieje strategia wygrywająca.\n\nimport pennylane as qml\n\ndev = qml.device(\"default.qubit\", wires=1)\n\ndef obwod(strategia):\n    # print(f\"strategia {strategia}\")\n\n    @qml.qnode(dev)\n    def qc():\n        for el in strategia:\n            if el == 'X':\n                # print(\"działam bramką X\")\n                qml.PauliX(wires=0)\n        return qml.state()\n    return qc\n\ndef sedzia(stan):\n    if stan.real.tolist()[0]:\n        return 1\n    else:\n        return 2\n\n\ndef klasycze_strategie():\n    wyniki = []\n    for ruch_1 in ['I','X']:\n        for ruch_2 in ['I','X']:\n            for ruch_3 in ['I','X']:\n                strategia = ruch_1 + ruch_2 + ruch_3\n                ob = obwod(strategia)\n                stats = sedzia(ob())\n                wyniki.append((strategia, stats))\n    return wyniki\n\n\nklasycze_strategie()\n\n\nqml.draw_mpl(obwod('XIX'))()\n\nPytanie zasadnicze - a co jeśli zamienimy monetę na kubit?\nMożliwe operacje pozostawienia kubitu w takim samym stanie - bramka I, zmiany stanu na przeciwny bramka X. Czyli pierwszy gracz ustala pierwszą bramkę, drugi drugą i ponownie pierwszy trzecią. Otwarcie pudełka to pomiar stanu kubitu.\n\nPrzeanalizuj wynik dla sekwencji I X I\n\nA co jeśli pierwszy gracz wie, że działa na kubicie?\n\nCzy może sprawic on, że wygra zawsze? (skoro wie, że działa na kubicie może użyc innych bramek)\n\n\nimport pennylane as qml\n\ndev = qml.device(\"default.qubit\", wires=1)\n\ndef obwod(strategia):\n    # print(f\"strategia {strategia}\")\n\n    @qml.qnode(dev)\n    def qc():\n        for el in strategia:\n            if el == 'X':\n                qml.PauliX(wires=0)\n            elif el == \"H\":\n                qml.Hadamard(wires=0)\n        return qml.state()\n    return qc\n\ndef sedzia(stan):\n    if stan.real.tolist()[0]:\n        return 1\n    else:\n        return 2\n\n\ndef kwantowa_strategia():\n    wyniki = []\n    for ruch_1 in ['H']:\n        for ruch_2 in ['I','X']:\n            for ruch_3 in ['H']:\n                strategia = ruch_1 + ruch_2 + ruch_3\n                ob = obwod(strategia)\n                stats = sedzia(ob())\n                wyniki.append((strategia, stats))\n    return wyniki\n        \n\n\nkwantowa_strategia()"
  },
  {
    "objectID": "labs/rozwiazania/zad2-rozw.html",
    "href": "labs/rozwiazania/zad2-rozw.html",
    "title": "Proste kwantowe obwody",
    "section": "",
    "text": "Na ostatnich zajęciach wyprodukowaliśmy klasyczną i kwantową sieć neuronową realizowaną w bibliotece PyTorch i Pennylane.\nKod naszej wartwy ukrytej w której użyliśmy obwodu kwantowego realizował następujące obiekty i funkcje:\nNa tych zajęciach nauczymy się tworzyć proste obwody kwantowe.\nZaczynamy!\nObwody kwantowe składają się z rejestrów, które reprezentują poszczególne kubity.\nDomyślnie kubity inicjalizujemy w stanie 0.\nLiczbę rejestrów możesz ustalić parametrem wires przy definicji środowiska wykonawczego device.\nOperacje wykonywane na kubitach nazywamy bramkami. Operacje te można wykonywać na jednym albo i wielu kubitach na raz. Domyślnie będziemy optymalizować algortymy aby składały się z jak najmniejszej ilości bramek działających na dużą liczbę kubitów.\nGraficznie można rozumieć realizację algorytmu jako stosowanie bramek na poszczególnych kubitach.\nW bibliotece PennyLane, obwody kwantowe reprezentowane są przez kwantowe funkcje, realizowane przez klasyczne funkcje w pythonie.\nSchemat kodu penny lane możemy zapisać jako:\nPrzykładowo\nMatematycznie całość możemy zapisać jako:\nTyle teoria … a jak zakodować i wykorzystać ?"
  },
  {
    "objectID": "labs/rozwiazania/zad2-rozw.html#jeden-kubit",
    "href": "labs/rozwiazania/zad2-rozw.html#jeden-kubit",
    "title": "Proste kwantowe obwody",
    "section": "Jeden kubit",
    "text": "Jeden kubit\nPrzygotujmy kod dla obwodu kwantowego realizującego jeden kubit z którym nic nie robimy.\n\nimport pennylane as qml\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(dev)\ndef qc():\n    ## tu pojawi się kod przetwarzający nasz kubit\n    ## ale teraz nic z nim nie robimy \n    return qml.state()\n\n\nqc()\n\nwektor \\([1,0]\\) można interpretować jako stan \\(\\ket{0}\\) czyli jako wartość bitu \\(0\\).\nNatomiast wykorzystując metodę qml.probs() możesz zwrócić kwadraty amplitud czyli prawdopodobieństow otrzymania 0 i 1.\n\nimport pennylane as qml\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(dev)\ndef qc2():\n    return qml.probs(wires=0)\n\n\nqc2()\n\nzobaczmy jak zainicjalozować stan \\(\\ket{1}= [0,1]^T\\) \\[\n\\ket{\\psi}=\\ket{1}\n\\]\n\nfrom pennylane import numpy as np\nfrom pennylane.ops import StatePrep\n\nstan = np.array([0,1]) # stan do inicjalizacji\n\n@qml.qnode(dev)\ndef qc():\n    StatePrep(stan, wires=0)\n    return qml.state()\n\nqc()\n\n\n@qml.qnode(dev)\ndef qc():\n    StatePrep(stan, wires=0)\n    return qml.probs()\n\nqc()\n\nutwórzmy pełną superpozycję stanu 0 i 1. \\[\n\\ket{\\psi}=\\frac{1}{\\sqrt{2}} (\\ket{0} + \\ket{1} )\n\\]\n\nstan = np.array([1/np.sqrt(2), 1/np.sqrt(2)])\n\n@qml.qnode(dev)\ndef qc_s():\n    qml.StatePrep(stan,wires=0)\n    return qml.state()\n\nprint(f\"amplitudy: {qc_s()}\")\n\n\n@qml.qnode(dev)\ndef qc_p():\n    qml.StatePrep(stan,wires=0)\n    return qml.probs()\n\nprint(f\"prwadopodobieństwa: {qc_p()}\")\n\nprint(f\"test czy amp^2 = prawdopodobienstwo: {qc_s()**2 == qc_p()}\")\n\nZADANIE Napisz funkcję generującą stan jednego kubitu jako funkcję kąta \\(\\theta\\)\ndef stan_kubitu(theta):\n    pass # Twoj kod \n\n\\(\\ket{\\psi}= [\\cos(\\frac{\\theta}{2}), \\sin(\\frac{\\theta}{2})]\\)\n\nWygeneruj obwód z pojedynczym kubitem inicjalizujący stan \\(\\ket{0}\\) , \\(\\ket{1}\\) oraz \\(\\frac{1}{\\sqrt{2}} (\\ket{0} + \\ket{1} )\\)\n\nStany dwukubitowe\n\\[\n\\ket{\\psi_0}=\\ket{00}\n\\] \\[\n\\ket{\\psi_1}=\\ket{01}\n\\] \\[\n\\ket{\\psi_2}=\\ket{10}\n\\] \\[\n\\ket{\\psi_3}=\\ket{11}\n\\]\nKtóry stan wygeneruje poniższy kod?\n\ndev = qml.device(\"default.qubit\", wires=2)\n@qml.qnode(dev)\ndef qc():\n    return qml.state()\n\nqc()\n\n\\[\n\\ket{\\psi}=\\frac{1}{2}\\left( \\ket{00} + \\ket{01} + \\ket{10} + \\ket{11} \\right)\n\\]\n\ndev = qml.device(\"default.qubit\", wires=2)\n\nstan = np.array([1/2, 1/2, 1/2, 1/2])\n\nprawd = [i**2 for i in stan]\nprint(f\"test: suma prawdopodobienst {np.sum(prawd)}\")\n\n@qml.qnode(dev)\ndef qc():\n    StatePrep(stan, wires=[0,1])\n    return qml.state()\n\nqc()"
  },
  {
    "objectID": "labs/rozwiazania/zad2-rozw.html#bramki-jednokubitowe",
    "href": "labs/rozwiazania/zad2-rozw.html#bramki-jednokubitowe",
    "title": "Proste kwantowe obwody",
    "section": "Bramki jednokubitowe",
    "text": "Bramki jednokubitowe\n\nBramka X\nBramka X-gate reprezentowana jest przez macierz Pauli-X :\n\\[\nX = \\begin{pmatrix}\n0 & 1 \\\\\n1 & 0 \\\\\n\\end{pmatrix}\n\\]\nBramka X obraca kubit w kierunku osi na sferze Bloch’a o \\(\\pi\\) radianów. Zmienia \\(|0\\rangle\\) na \\(|1\\rangle\\) oraz \\(|1\\rangle\\) na \\(|0\\rangle\\). Jest często nazywana kwantowym odpowiednikiem bramki NOT lub określana jako bit-flip.\n\\[ \\sigma_x \\ket{0} = \\ket{1} \\,\\,\\, \\sigma_x\\ket{1} = \\ket{0} \\]\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\ndef qc():\n    qml.X(wires=0)\n    return qml.state()\n\nqc()\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\ndef qc():\n    qml.PauliX(wires=0)\n    return qml.state()\n\nqc()\n\n\nqml.draw_mpl(qc)()\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\ndef qc():\n    qml.PauliX(wires=0)\n    qml.X(wires=0)\n    return qml.state()\n\nqml.draw_mpl(qc)()\nqc()\n\n\n\nBramka Hadamarda\nBramka Hadamarda przetwarza stan \\(|0\\rangle\\) na kombinacje liniowa (superpozycje) \\(\\frac{|0\\rangle + |1\\rangle}{\\sqrt{2}}\\), co oznacza, że pomiar zwróci z takim samym prawdopodobieństwem stanu 1 lub 0. Stan ten często oznaczany jest jako: \\(|+\\rangle\\).\n\\[\nH = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}\n1 & 1 \\\\\n1 & -1 \\\\\n\\end{pmatrix}\n\\]\n\\[ H\\ket{0} = \\frac{\\sqrt{2}}{2} (\\ket{0}+ \\ket{1})\\] \\[ H\\ket{1} = \\frac{\\sqrt{2}}{2}(\\ket{0}- \\ket{1})\\]\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\n\n\ndef qc():\n    qml.Hadamard(wires=0)\n    return qml.state()\n\nqml.draw_mpl(qc)()\nqc()\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\n\n\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.Hadamard(wires=0)\n    return qml.state()\n\nqml.draw_mpl(qc)()\nqc()\n\n\ndev = qml.device(\"default.qubit\", wires=2)\n@qml.qnode(dev)\n\n\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.Hadamard(wires=1)\n    return qml.state()\n\nqml.draw_mpl(qc)()\nqc()\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\n\n\ndef qc(state):\n    if state==1:\n        qml.X(wires=0)\n    qml.Hadamard(wires=0)\n    qml.PauliX(wires=0)\n    qml.Hadamard(wires=0)\n    return qml.state()\n\nqml.draw_mpl(qc)(0)\nqc(0)\n\n\nqc(1)"
  },
  {
    "objectID": "labs/rozwiazania/zad2-rozw.html#do-czego-możemy-wykorzystać-te-proste-obwody",
    "href": "labs/rozwiazania/zad2-rozw.html#do-czego-możemy-wykorzystać-te-proste-obwody",
    "title": "Proste kwantowe obwody",
    "section": "do czego możemy wykorzystać te proste obwody?",
    "text": "do czego możemy wykorzystać te proste obwody?\n\nLosowy bit\nutwórz obwód kwantowy zawierający jeden qubit. Utwórz superpozycję stanu zero i jeden z wykorzystaniem odpowiedniej bramki.\n-[a)] wyświetl stan po pomiarze pojedynczego kubitu\n-[b)] wyświetl prawdopodobieństwa otrzymania stanu 0 i 1\n-[c)] uruchom obwód 3 razy (do dev dodaj parametr , shots=3) i sprawdź wyniki otrzymywane przez metodę qml.counts() link\n-[d)] uruchom powyzszą prcedurę 100 razy\nDo jakiego zdarzenia losowego podobne są wyniki?\n\n\nLosowy bajt\n-[a)] bajt to 8 bitów - jaki zakres wartości jesteś w stanie przechowywać w 8 kubitach ?\n-[b)] wygeneruj 3 proby w pełni losowego bajtu - odkoduj wyniki w systemie int\n-[c)] oblicz różnicę dwóch bajtów dla których pierwsze cztery bity to 0, piąty bit pierwszego bajtu to 0 a drugiego bajtu to 1 . pozostałe bity są równe 1.\n\n\nGra w obracanie monety\nWykorzystując powyżej zdefiniowane bramki możemy zrealizowa następującą grę:\n\nW grze bierze udział dwóch graczy. Gracze dysponują monetą, której nie widzą w trakcie gry (np. jest zamknięta w pudełku). Natomiast wiedzą, że początkowo moneta ułożona jest orłem do góry (w stanie \\(\\ket{0}\\)) Gra polega na wykonaniu trzech ruchów na przemian. Każdy ruch polega na odwróceniu monety bądź pozostawieniu jej w takim stanie w jakim była. Gracze nie wiedzą jaki ruch wykonuje przeciwnik. Po ostatnim ruchu pudełko zostaje otwarte i gracze sprawdzają w jakiej pozycji jest moneta. Pierwszy gracz wygrywa jeśli moneta jest w pozycji orła, a drugi jeśli przeciwnie.\n\nSzansa wygranej wynosi dla każdego \\(50\\%\\) i jak można sprawdzic nie istnieje strategia wygrywająca.\n\nimport pennylane as qml\n\ndev = qml.device(\"default.qubit\", wires=1)\n\ndef obwod(strategia):\n    # print(f\"strategia {strategia}\")\n\n    @qml.qnode(dev)\n    def qc():\n        for el in strategia:\n            if el == 'X':\n                # print(\"działam bramką X\")\n                qml.PauliX(wires=0)\n        return qml.state()\n    return qc\n\ndef sedzia(stan):\n    if stan.real.tolist()[0]:\n        return 1\n    else:\n        return 2\n\n\ndef klasycze_strategie():\n    wyniki = []\n    for ruch_1 in ['I','X']:\n        for ruch_2 in ['I','X']:\n            for ruch_3 in ['I','X']:\n                strategia = ruch_1 + ruch_2 + ruch_3\n                # print(\"strategia\", strategia)\n                ob = obwod(strategia)\n                #qml.draw_mpl(ob)()\n                stats = sedzia(ob())\n                wyniki.append((strategia, stats))\n    return wyniki\n\n\nklasycze_strategie()\n\n\nqml.draw_mpl(obwod('XIX'))()\n\nPytanie zasadnicze - a co jeśli zamienimy monetę na kubit?\nMożliwe operacje pozostawienia kubitu w takim samym stanie - bramka I, zmiany stanu na przeciwny bramka X. Czyli pierwszy gracz ustala pierwszą bramkę, drugi drugą i ponownie pierwszy trzecią. Otwarcie pudełka to pomiar stanu kubitu.\n\nPrzeanalizuj wynik dla sekwencji I X I\n\nA co jeśli pierwszy gracz wie, że działa na kubicie?\n\nCzy może sprawic on, że wygra zawsze? (skoro wie, że działa na kubicie może użyc innych bramek)\n\n\nimport pennylane as qml\n\ndev = qml.device(\"default.qubit\", wires=1)\n\ndef obwod(strategia):\n    # print(f\"strategia {strategia}\")\n\n    @qml.qnode(dev)\n    def qc():\n        for el in strategia:\n            if el == 'X':\n                qml.PauliX(wires=0)\n            elif el == \"H\":\n                qml.Hadamard(wires=0)\n        return qml.state()\n    return qc\n\ndef sedzia(stan):\n    if stan.real.tolist()[0]:\n        return 1\n    else:\n        return 2\n\n\ndef kwantowa_strategia():\n    wyniki = []\n    for ruch_1 in ['H']:\n        for ruch_2 in ['I','X']:\n            for ruch_3 in ['H']:\n                strategia = ruch_1 + ruch_2 + ruch_3\n                ob = obwod(strategia)\n                stats = sedzia(ob())\n                wyniki.append((strategia, stats))\n    return wyniki\n        \n\n\nkwantowa_strategia()"
  },
  {
    "objectID": "labs/cw2.html",
    "href": "labs/cw2.html",
    "title": "Pennylane wprowadzenie",
    "section": "",
    "text": "Obiekt Qnode będziemy używać do definicji obwodów kwantowych. Obiekt ten wspiera wiele bibliotek do obliczeń numerycznych, tzw. interfejsów: - NumPy, - PyTorch, - TensorFlow, - JAX\nDomyślnie QNodes używa interfejs NumPy. Dzięki niemu mamy dostęp do optymalizatorów domyślnych z biblioteki Pennylane. Pozostałe interferjsy wymagają użycia optymalizatorów z innych pakietów.\nPennyLane oferuje kilka symulatorów: - ‘default.qubit’, - ‘default.mixed’, - ‘lightning.qubit’, - ‘default.gaussian’, - ‘default.clifford’, - ‘default.tensor’",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Pennylane wprowadzenie"
    ]
  },
  {
    "objectID": "labs/cw2.html#kod-pennylane",
    "href": "labs/cw2.html#kod-pennylane",
    "title": "Pennylane wprowadzenie",
    "section": "Kod Pennylane",
    "text": "Kod Pennylane\nPennylane pozwala zrealizować obwód kwantowy (ang. quantum circuit) jako funkcję w Pythonie.\n\nimport pennylane as qml\n\ndef qc(): # from quantum circuit\n    qml.Hadamard(wires=0)\n    return qml.counts()\n\nwires oznacza kwantowy podsystem - czyli nasz pojedynczy kubit. Liczymy od 0 nie od 1.\n\nFunkcja kwantowa może pobierać klasyczne pamaretry\nFunkcja kwantowa może zawierać klasyczny flow (przepływ) twojego programu for czy if else.\n\nZbiór kwantowych operatorów",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Pennylane wprowadzenie"
    ]
  },
  {
    "objectID": "labs/cw2.html#uruchomienie-obwodu-kwantowego",
    "href": "labs/cw2.html#uruchomienie-obwodu-kwantowego",
    "title": "Pennylane wprowadzenie",
    "section": "Uruchomienie obwodu kwantowego",
    "text": "Uruchomienie obwodu kwantowego\nUruchomienie odbywa się po wyborze device z określeniem ilości kubitów (wires)\n\n# domyślnie\ndev = qml.device(\"default.qubit\", wires=1)\n\n\n# można nadać własne nazwy kubitów\ndev_unique_wires =  qml.device(\"default.qubit\", wires=['q1','aux'])\n\nW przypadku gdy będziemy chcieli powtórzyć wielokrotnie wykonanie obwodu w celu zebrania statystyki wyników mozemy zdefiniować parametr shots\n\n# shots \nshots_list = [5,10,1000]\ndev = qml.device(\"default.qubit\", wires=1, shots=shots_list)\n\nqml.QNode - łączy naszą kwantową funkcję ze środowiskiem na którym chcemy ją wykonać\n\ncirc = qml.QNode(qc, dev)\n\n\ncirc()\n\n({'0': tensor(2, requires_grad=True), '1': tensor(3, requires_grad=True)},\n {'0': tensor(6, requires_grad=True), '1': tensor(4, requires_grad=True)},\n {'0': tensor(486, requires_grad=True), '1': tensor(514, requires_grad=True)})\n\n\nŁatwiej skorzystać z dekoratora @qml.qnode bezpośrednio przy definicji funkcji kwantowej\n\ndev = qml.device(\"default.qubit\", wires=1, shots=1000)\n@qml.qnode(dev)\ndef circuit():\n    qml.Hadamard(wires=0)\n    return qml.counts()\n\n\ncircuit()\n\n{'0': tensor(505, requires_grad=True), '1': tensor(495, requires_grad=True)}",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Pennylane wprowadzenie"
    ]
  },
  {
    "objectID": "labs/cw2.html#konstrukcja-obwodów-kwantowych-w-pennylane",
    "href": "labs/cw2.html#konstrukcja-obwodów-kwantowych-w-pennylane",
    "title": "Pennylane wprowadzenie",
    "section": "Konstrukcja obwodów kwantowych w Pennylane",
    "text": "Konstrukcja obwodów kwantowych w Pennylane\nNa ostatnich zajęciach wyprodukowaliśmy klasyczną i kwantową sieć neuronową realizowaną w bibliotece PyTorch i Pennylane.\nKod naszej wartwy ukrytej w której użyliśmy obwodu kwantowego realizował następujące obiekty i funkcje:\n\nimport pennylane as qml\n\nn_qubits = 2\ndev = qml.device(\"default.qubit\", wires=n_qubits)\n\n@qml.qnode(dev)\ndef qnode(inputs, weights):\n    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\nObwody kwantowe składają się z rejestrów, które reprezentują poszczególne kubity.\n\nDomyślnie kubity inicjalizujemy w stanie 0.\n\nLiczbę rejestrów możesz ustalić parametrem wires przy definicji środowiska wykonawczego device.\ndev = qml.device(\"default.qubit\", wires=1)\nOperacje wykonywane na kubitach nazywamy bramkami.\nOperacje te można wykonywać na jednym albo i wielu kubitach na raz.\nDomyślnie będziemy optymalizować algortymy aby składały się z jak najmniejszej ilości bramek działających na dużą liczbę kubitów.\nGraficznie można rozumieć realizację algorytmu jako stosowanie bramek na poszczególnych kubitach.\n\n\n\nkibu2\n\n\nW bibliotece PennyLane, obwody kwantowe reprezentowane są przez kwantowe funkcje, realizowane przez klasyczne funkcje w pythonie.\nSchemat kodu penny lane możemy zapisać jako:\nimport pennylane as qml\n\ndef my_quantum_function(params):\n\n    # Single-qubit operations with no input parameters\n    qml.Gate1(wires=0)\n    qml.Gate2(wires=1)\n\n    # A single-qubit operation with an input parameter\n    qml.Gate3(params[0], wires=0)\n\n    # Two-qubit operation with no input parameter on wires 0 and 1\n    qml.TwoQubitGate1(wires=[0, 1])\n\n    # Two-qubit operation with an input parameter on wires 0 and 1\n    qml.TwoQubitGate2(params[1], wires=[0, 1])\n\n    # Return the result of a measurement\n    return qml.Measurement(wires=[0, 1])\nPrzykładowo\n\n\ndef my_first_circuit(theta):\n\n    qml.Hadamard(wires = 0)\n    qml.CNOT(wires = [0,1])\n    qml.RZ(theta, wires = 0)\n\n    return qml.probs(wires = [0,1])\n\nMatematycznie całość możemy zapisać jako:\n\n\nimport pennylane as qml\nfrom pennylane import numpy as np\n\ndev = qml.device(\"default.qubit\", wires=2)\n#dev = qml.device(\"default.qubit\", wires=2, shots=1000)\n\n@qml.qnode(dev)\ndef circ(theta):\n    qml.Hadamard(wires = 0)\n    qml.CNOT(wires = [0,1])\n    qml.RZ(theta, wires = 0)\n    return qml.state()\n#    return qml.probs(wires = [0,1])\n\ncirc(np.pi)\n\ntensor([4.32978028e-17-0.70710678j, 0.00000000e+00+0.j        ,\n        0.00000000e+00+0.j        , 4.32978028e-17+0.70710678j], requires_grad=True)\n\n\n\nprint(qml.draw(circ)(np.pi))\n\n0: ──H─╭●──RZ(3.14)─┤  State\n1: ────╰X───────────┤  State\n\n\n\nqml.draw_mpl(circ)(np.pi)\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nqml.drawer.use_style(\"sketch\")\nfig, ax = qml.draw_mpl(circ)(np.pi)\nplt.show()\n\n\n\n\n\n\n\n\n\nqml.drawer.use_style(\"pennylane_sketch\")\nfig, ax = qml.draw_mpl(circ)(np.pi)\nplt.show()\n\nMatplotlib is building the font cache; this may take a moment.\n\n\n\n\n\n\n\n\n\n\nObwody z jednym kubitem\n\\[\n\\ket{\\psi}=\\ket{0}\n\\] Przedstawmy obwód kwantowy z jednym kubitem. Funkcja kwantowa zwraca nam stan kubitu po realizacji obwodu.\n\nObwód z jednym kubitem bez bramek.\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\ndef qc():\n    return qml.state()\n\n\nqc()\n\ntensor([1.+0.j, 0.+0.j], requires_grad=True)\n\n\nwektor \\([1,0]\\) można interpretować jako stan \\(\\ket{0}\\) czyli jako wartość bitu \\(0\\).\nNatomiast wykorzystując metodę qml.probs() możesz zwrócić kwadraty amplitud czyli prawdopodobieństow otrzymania 0 i 1.\n\nimport pennylane as qml\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(dev)\ndef qc2():\n    return qml.probs(wires=0)\n\nqc2()\n\ntensor([1., 0.], requires_grad=True)\n\n\n\nZobaczmy jak zainicjalozować stan \\(\\ket{1}= [0,1]^T\\) \\[\n\\ket{\\psi}=\\ket{1}\n\\]\n\n\nfrom pennylane import numpy as np\nfrom pennylane.ops import StatePrep\n\nstan = np.array([0,1]) # stan do inicjalizacji\n\n@qml.qnode(dev)\ndef qc():\n    StatePrep(stan, wires=0)\n    return qml.state()\n\nqc()\n\ntensor([0.+0.j, 1.+0.j], requires_grad=True)\n\n\n\n@qml.qnode(dev)\ndef qc():\n    StatePrep(stan, wires=0)\n    return qml.probs()\n\nqc()\n\ntensor([0., 1.], requires_grad=True)\n\n\n\nutwórzmy pełną superpozycję stanu 0 i 1. \\[\n\\ket{\\psi}=\\frac{1}{\\sqrt{2}} (\\ket{0} + \\ket{1} )\n\\]\n\n\nstan = np.array([1/np.sqrt(2), 1/np.sqrt(2)])\n\n@qml.qnode(dev)\ndef qc_s():\n    qml.StatePrep(stan,wires=0)\n    return qml.state()\n\nprint(f\"amplitudy: {qc_s()}\")\n\n\n@qml.qnode(dev)\ndef qc_p():\n    qml.StatePrep(stan,wires=0)\n    return qml.probs()\n\nprint(f\"prwadopodobieństwa: {qc_p()}\")\n\nprint(f\"test czy amp^2 = prawdopodobienstwo: {qc_s()**2 == qc_p()}\")\n\namplitudy: [0.70710678+0.j 0.70710678+0.j]\nprwadopodobieństwa: [0.5 0.5]\ntest czy amp^2 = prawdopodobienstwo: [ True  True]\n\n\n\n\nStany dwukubitowe\n\\[\n\\ket{\\psi}=\\ket{00}\n\\] \\[\n\\ket{\\psi}=\\ket{01}\n\\] \\[\n\\ket{\\psi}=\\ket{10}\n\\] \\[\n\\ket{\\psi}=\\ket{11}\n\\]\n\ndev = qml.device(\"default.qubit\", wires=2)\n@qml.qnode(dev)\ndef qc():\n    return qml.state()\n\nqc()\n\ntensor([1.+0.j, 0.+0.j, 0.+0.j, 0.+0.j], requires_grad=True)\n\n\n\\[\n\\ket{\\psi}=\\frac{1}{2}\\left( \\ket{00} + \\ket{01} + \\ket{10} + \\ket{11} \\right)\n\\]\n\ndev = qml.device(\"default.qubit\", wires=2)\n\nstan = np.array([1/2, 1/2, 1/2, 1/2])\n\nprawd = [i**2 for i in stan]\nprint(f\"test: suma prawdopodobienst {np.sum(prawd)}\")\n\n@qml.qnode(dev)\ndef qc():\n    StatePrep(stan, wires=[0,1])\n    return qml.state()\n\nqc()\n\ntest: suma prawdopodobienst 1.0\n\n\ntensor([0.5+0.j, 0.5+0.j, 0.5+0.j, 0.5+0.j], requires_grad=True)\n\n\nZADANIE Napisz funkcję generującą stan jednego kubitu jako funkcję kąta \\(\\theta\\)\ndef stan_kubitu(theta):\n    pass # Twoj kod \n\n\\(\\ket{\\psi}= [\\cos(\\frac{\\theta}{2}), \\sin(\\frac{\\theta}{2})]\\)\n\nWygeneruj obwód z pojedynczym kubitem inicjalizujący stan \\(\\ket{0}\\) , \\(\\ket{1}\\) oraz \\(\\frac{1}{\\sqrt{2}} (\\ket{0} + \\ket{1} )\\)",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Pennylane wprowadzenie"
    ]
  },
  {
    "objectID": "labs/cw2.html#bramki-jako-operacje-na-kubitach",
    "href": "labs/cw2.html#bramki-jako-operacje-na-kubitach",
    "title": "Pennylane wprowadzenie",
    "section": "Bramki jako operacje na kubitach",
    "text": "Bramki jako operacje na kubitach\n\nBramka X\nBramka X-gate reprezentowana jest przez macierz Pauli-X :\n\\[\nX = \\begin{pmatrix}\n0 & 1 \\\\\n1 & 0 \\\\\n\\end{pmatrix}\n\\]\nBramka X obraca kubit w kierunku osi na sferze Bloch’a o \\(\\pi\\) radianów. Zmienia \\(|0\\rangle\\) na \\(|1\\rangle\\) oraz \\(|1\\rangle\\) na \\(|0\\rangle\\). Jest często nazywana kwantowym odpowiednikiem bramki NOT lub określana jako bit-flip.\n\\[ \\sigma_x \\ket{0} = \\ket{1} \\,\\,\\, \\sigma_x\\ket{1} = \\ket{0} \\]\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\ndef qc():\n    qml.X(wires=0)\n    return qml.state()\n\nqc()\n\ntensor([0.+0.j, 1.+0.j], requires_grad=True)\n\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\ndef qc():\n    qml.PauliX(wires=0)\n    return qml.state()\n\nqc()\n\ntensor([0.+0.j, 1.+0.j], requires_grad=True)\n\n\n\nqml.draw_mpl(qc)()\n\n\n\n\n\n\n\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\ndef qc():\n    qml.PauliX(wires=0)\n    qml.X(wires=0)\n    return qml.state()\n\nqml.draw_mpl(qc)()\nqc()\n\ntensor([1.+0.j, 0.+0.j], requires_grad=True)\n\n\n\n\n\n\n\n\n\n\nJak bramka X działa na stan \\(\\ket{+}\\), \\(\\ket{-}\\) \\(\\ket{i}\\) i \\(\\ket{-i}\\)\n\n\n\nDowolna bramka unitarna\n\nfrom pennylane import numpy as np\n\nU = np.array([[1, 1], [1, -1]]) / np.sqrt(2)\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(dev)\ndef qc():\n    qml.QubitUnitary(U, wires=0)\n    return qml.state()\n\nqml.draw_mpl(qc)()\nqc()\n\n\n\nBramka Hadamarda\nBramka Hadamarda przetwarza stan \\(|0\\rangle\\) na kombinacje liniowa (superpozycje) \\(\\frac{|0\\rangle + |1\\rangle}{\\sqrt{2}}\\), co oznacza, że pomiar zwróci z takim samym prawdopodobieństwem stanu 1 lub 0. Stan ten często oznaczany jest jako: \\(|+\\rangle\\).\n\\[\nH = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}\n1 & 1 \\\\\n1 & -1 \\\\\n\\end{pmatrix}\n\\]\n\\[ H\\ket{0} = \\frac{\\sqrt{2}}{2} (\\ket{0}+ \\ket{1})\\] \\[ H\\ket{1} = \\frac{\\sqrt{2}}{2}(\\ket{0}- \\ket{1})\\]\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    return qml.state()\n\nqc()\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.Hadamard(wires=0)\n    return qml.state()\n\nqc()\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n\n@qml.qnode(dev)\ndef qc(state):\n    if state==1:\n        qml.X(wires=0)\n    qml.Hadamard(wires=0)\n    qml.PauliX(wires=0)\n    qml.Hadamard(wires=0)\n    return qml.state()\n\nqc(0)\n\n\nqc(1)\n\n\n\nbramka SX\nBramka SX jest pierwiastkiem kwadratowym bramki X. Dwukrotne zastosowanie powinno reazlizowac bramkę X.\n\\[\nSX = \\frac{1}{2}\\begin{pmatrix}\n1+i & 1-i \\\\\n1-i & 1+i \\\\\n\\end{pmatrix}\n\\]\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\ndef qc():\n    qml.SX(wires=0)\n    return qml.state()\n\nqml.draw_mpl(qc)()\nqc()\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\ndef qc():\n    qml.SX(wires=0)\n    qml.SX(wires=0)\n    return qml.state()\n\nqml.draw_mpl(qc)()\nqc()\n\n\n\nZ gate\n\\[\nZ = \\begin{pmatrix}\n1 & 0 \\\\\n0 & -1 \\\\\n\\end{pmatrix} = \\begin{pmatrix}\n1 & 0 \\\\\n0 & e^{i \\pi} \\\\\n\\end{pmatrix}\n\\]\nInne nazwy bramki: phase flip lub sign flip\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\ndef qc():\n    qml.Z(wires=0)\n    return qml.state()\n\nqml.draw_mpl(qc)()\nqc()\n\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\ndef qc():\n    qml.PauliZ(wires=0)\n    return qml.state()\n\nqml.draw_mpl(qc)()\nqc()\n\n\nJak bramka Z działa na stan \\(\\ket{+}\\), \\(\\ket{-}\\) \\(\\ket{i}\\) i \\(\\ket{-i}\\) ?\n\n\nJak zmieniają się prawdopodobieństwa wyników w bazie obliczeniowej?\n\n\n\nRZ gate\nBramkę PauliZ można uogólnić i sparametryzować kątem. Dla \\(\\phi=\\pi\\) otrzymujemy bramkę \\(\\sigma_z\\).\n\\[\n\\begin{pmatrix}\n1 & 0 \\\\\n0 & -1 \\\\\n\\end{pmatrix} = \\begin{pmatrix}\n1 & 0 \\\\\n0 & e^{i \\pi} \\\\\n\\end{pmatrix} = \\begin{pmatrix}\n1 & 0 \\\\\n0 & e^{i \\phi} \\\\\n\\end{pmatrix}\n\\]\n\\[ R_Z(\\phi) = e^{-i \\phi \\frac{\\sigma_z}{2} }  \\]\n\\[\nRZ = \\begin{pmatrix}\ne ^{-i \\frac{\\phi}{2} } & 0 \\\\\n0 & e ^{i \\frac{\\phi}{2} } \\\\\n\\end{pmatrix} = \\cos(\\frac{\\phi}{2})I_2 - \\sin(\\frac{\\phi}{2}) i\\sigma_z\n\\]\n\nfrom pennylane import numpy as np\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\n\n\ndef qc(phi):\n    qml.RZ(phi=phi, wires=0)\n    return qml.state()\n\nqc(np.pi/2)\n\n\nqml.draw_mpl(qc)(np.pi/2)\n\n\nfrom pennylane import numpy as np\n\ndev = qml.device(\"default.qubit\", wires=1)\n@qml.qnode(dev)\n\n\ndef qc(phi):\n    qml.SX(wires=0)\n    qml.RZ(phi=phi, wires=0)\n    return qml.state()\n\nqc(np.pi)\n\n\nZnajdz informacje o bramce \\(S\\), \\(S^{\\dag}\\), \\(T\\), \\(T^{\\dag}\\).",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Pennylane wprowadzenie"
    ]
  },
  {
    "objectID": "labs/cw4.html",
    "href": "labs/cw4.html",
    "title": "Bramki wielokubitowe",
    "section": "",
    "text": "\\[\n\\renewcommand{\\bra}[1]{\\left \\langle #1 \\right \\rvert}\n\\renewcommand{\\ket}[1]{\\left \\rvert #1 \\right \\rangle}\n\\renewcommand{\\braket}[2]{\\left \\langle #1 \\middle \\rvert #2 \\right \\rangle}\n\\]\nO bramkach dwukubitowych wspominaliśmy juz tutaj\nJedną z bramek realizującą zadania na dwóch kubitach jest bramka CNOT, która na bazie bitu kontrolnego decyduje czy zastosować operację X do drugiego kubitu.\n\\[\n\\text{CNOT} = \\begin{bmatrix} 1 \\,\\, \\,\\,\\, 0 \\,\\,\\,\\,\\, 0 \\,\\,\\,\\,\\, 0 \\\\\n0\\,\\, \\,\\,\\, 1 \\,\\,\\,\\,\\, 0 \\,\\,\\,\\,\\, 0 \\\\\n0\\,\\,\\,\\,\\, 0\\,\\,\\,\\,\\,  0 \\,\\,\\,\\,\\, 1 \\\\ 0\\,\\,\\,\\,\\, 0\\,\\,\\,\\,\\, 1\\,\\,\\,\\,\\, 0 \\end{bmatrix}\n\\]\n\\[ \\text{CNOT} \\ket{00} = \\ket{00} \\]\n\\[ \\text{CNOT} \\ket{10} = \\ket{11} \\]\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=2, shots=100)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.CNOT(wires=[0,1])\n    #return qml.state()\n    return qml.counts()\n\nqc()\n\n{'00': tensor(38, requires_grad=True), '11': tensor(62, requires_grad=True)}\n\n\n\nimport matplotlib.pyplot as plt\nqml.drawer.use_style(\"sketch\")\nfig, ax = qml.draw_mpl(qc)()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=2, shots=100)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.CNOT(wires=[0,1])\n    qml.X(wires=1)\n    #return qml.state()\n    return qml.counts()\n\nqc()\n\n{'01': tensor(46, requires_grad=True), '10': tensor(54, requires_grad=True)}\n\n\n\nfig, ax = qml.draw_mpl(qc)()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=2, shots=100)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.CNOT(wires=[0,1])\n    qml.Z(wires=1)\n    #return qml.state()\n    return qml.counts()\n\nqc()\n\n{'00': tensor(63, requires_grad=True), '11': tensor(37, requires_grad=True)}\n\n\n\nfig, ax = qml.draw_mpl(qc)()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=2, shots=100)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.CNOT(wires=[0,1])\n    qml.X(wires=1)\n    qml.Z(wires=1)\n    #return qml.state()\n    return qml.counts()\n\nqc()\n\n{'01': tensor(55, requires_grad=True), '10': tensor(45, requires_grad=True)}\n\n\n\nfig, ax = qml.draw_mpl(qc)()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nutwórz obwód dwu kubitowy: - bramka CNOT 0,1 - bramka CNOT (odwrocona) 1,0 - bramka CNOT 0,1\nOpisz jak działa ta kombinacja na stany: \\(\\ket{00}, \\ket{11}, \\ket{01},\\ket{10}\\)\nZnajdź odpowiednik tej kombinacji w bibliotece Pennylane.\n\n\n\nutwórz obwód dwu kubitowy: - bramka CNOT - bramki H na kazdym kubicie - bramka CNOT - bramki H na kazdym kubicie - bramka CNOT\n\n\n\nJak realizują się stany splątane dla więcej niz dwóch kubitów\nStany Greenbergerha-Hornea-Zeilingera\npublikacja\n\ndev = qml.device('default.qubit', wires=3, shots=100)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.CNOT(wires=[0,1])\n    qml.CNOT(wires=[1,2])\n    #return qml.state()\n    return qml.counts()\n\nqc()\n\n{'000': tensor(45, requires_grad=True), '111': tensor(55, requires_grad=True)}\n\n\n\n\n\nKlasyczne komputery bardzo często wykorzystując operację kopiowania.\nZobaczmy jak taka operacja wygląda dla kubitów.\nRozwazmy obwod z operatorem C, który w działaniu na dwa kubity kopiuje wartość pierwszego kubitu na wynik drugiego. Drugi kubit mozna na początku ustawić w dowolnym stanie.\nChcemy skopiować stan \\(\\ket{\\psi_0} = a\\ket{0} + b\\ket{1}\\)\nStan początkowy układu: \\(\\ket{\\psi_0} \\otimes \\ket{0}\\)\nChcemy przekształcić na \\(\\ket{\\psi_0} \\otimes \\ket{\\psi_0}\\) czyli\n\\[\nC \\left(\\ket{\\psi_0} \\otimes \\ket{0}\\right) = \\ket{\\psi_0} \\otimes \\ket{\\psi_0}\n\\]\nLewa strona\n\\[\nC \\left(\\ket{\\psi_0} \\otimes \\ket{0}\\right) = C\\left(   (a\\ket{0} + b\\ket{1} )  \\otimes \\ket{0} \\right)\n\\] \\[\nC\\left( a\\ket{0} \\otimes \\ket{0} + b\\ket{1}\\otimes \\ket{0} \\right) = a C \\left(\\ket{0} \\otimes \\ket{0}\\right) + b C \\left( \\ket{1}\\otimes \\ket{0}\\right)\n\\] \\[\na \\ket{00} + b \\ket{11}\n\\]\nPrawa strona \\[\n\\ket{\\psi_0} \\otimes \\ket{\\psi_0}  = a^2 \\ket{00} + ab\\ket{01} + ab\\ket{10} + b^2\\ket{11}\n\\]\n\n\n\n\n\n\\[\n0+0 = 00\n\\] \\[\n0+1 = 01\n\\] \\[\n1+0 = 01\n\\] \\[\n1+1 = 10\n\\]\nzauwaz, ze mamy dwa typy rozwiązań:\n\ndwa bity wejsciowe są takie same (00, 11) i dają na prawym bicie odpowiedzi 0.\ndwa bity wejsciowe są rózne (10,01) i dają na prawym bicie odpowiedzi 1.\n\nAby napisać prawidłowe rozwiązanie musimy stworzyć bramki, które będą rozpoznawać czy dwa kubity są takie same czy tez rózne. Dla przypomnienia - klasycznie rolę taką pełni bramka XOR.\n\n\n\nInput 1\nInput 2\nXOR\n\n\n\n\n0\n0\n0\n\n\n0\n1\n1\n\n\n1\n1\n1\n\n\n1\n0\n0\n\n\n\nPodobnie działa bramka CNOT\n\ndev = qml.device('default.qubit', wires=4, shots=1)\n\n@qml.qnode(dev)\ndef qc(input='00'):\n    if input[0]=='1':\n        qml.X(wires=0)\n    if input[1]=='1':\n        qml.X(wires=1)\n    qml.CNOT(wires=[0,3])\n    qml.CNOT(wires=[1,3])\n    #return qml.state()\n    return qml.counts(wires=[2,3])\n\nqc()\n\n{'00': tensor(1, requires_grad=True)}\n\n\n\nfig, ax = qml.draw_mpl(qc)()\nplt.show()\n\n\n\n\n\n\n\n\n\nfor input in ['00','01','10','11']:\n    print(f\"wartosci poczatkowe: {input} : wynik {qc(input)}\")\n\nwartosci poczatkowe: 00 : wynik {'00': tensor(1, requires_grad=True)}\nwartosci poczatkowe: 01 : wynik {'01': tensor(1, requires_grad=True)}\nwartosci poczatkowe: 10 : wynik {'01': tensor(1, requires_grad=True)}\nwartosci poczatkowe: 11 : wynik {'00': tensor(1, requires_grad=True)}\n\n\nZastosowanie dwóch CNOT do inputów rozwiązuje nam problem prawego bitu odpowiedzi.\nCo z pierszym bitem odpowiedzi otrzymywanym po pomiarzze q3 ?\n\njego wartość dla pierwszych trzech równań zawsze wynosi 0.\n\nJednak dla równania 1+1 powinniśmy otrzymać 1.\nDo rozwiązania tego problemu mozna wykorzystać bramkę operującą na 3 kubitach. Bramka ta to bramka Toffoli.\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=4, shots=1)\n\n@qml.qnode(dev)\ndef qc():\n    qml.X(wires=0)\n    qml.X(wires=1)\n    qml.CNOT([0,1])\n    qml.CNOT([0,2])\n    qml.Toffoli([0,1,3])\n    return qml.counts(wires=[2,3])\n\nqc()\n\nprint(\"wynik 1+1 =\",int('10', 2))\n\nwynik 1+1 = 2\n\n\n\ndev = qml.device('default.qubit', wires=4, shots=1)\n\n@qml.qnode(dev)\ndef qc(input='00'):\n    if input[0]=='1':\n        qml.X(wires=0)\n    if input[1]=='1':\n        qml.X(wires=1)\n    qml.CNOT(wires=[0,3])\n    qml.CNOT(wires=[1,3])\n    qml.Toffoli(wires=[0,1,2])\n    #return qml.state()\n    return qml.counts(wires=[2,3])\n\n\nfor input in ['00','01','10','11']:\n    print(f\"wartosci poczatkowe: {input} : wynik {qc(input)}\")\n\nwartosci poczatkowe: 00 : wynik {'00': tensor(1, requires_grad=True)}\nwartosci poczatkowe: 01 : wynik {'01': tensor(1, requires_grad=True)}\nwartosci poczatkowe: 10 : wynik {'01': tensor(1, requires_grad=True)}\nwartosci poczatkowe: 11 : wynik {'10': tensor(1, requires_grad=True)}",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Bramki wielokubitowe"
    ]
  },
  {
    "objectID": "labs/cw4.html#bramki-dwukubitowe",
    "href": "labs/cw4.html#bramki-dwukubitowe",
    "title": "Bramki wielokubitowe",
    "section": "",
    "text": "\\[\n\\renewcommand{\\bra}[1]{\\left \\langle #1 \\right \\rvert}\n\\renewcommand{\\ket}[1]{\\left \\rvert #1 \\right \\rangle}\n\\renewcommand{\\braket}[2]{\\left \\langle #1 \\middle \\rvert #2 \\right \\rangle}\n\\]\nO bramkach dwukubitowych wspominaliśmy juz tutaj\nJedną z bramek realizującą zadania na dwóch kubitach jest bramka CNOT, która na bazie bitu kontrolnego decyduje czy zastosować operację X do drugiego kubitu.\n\\[\n\\text{CNOT} = \\begin{bmatrix} 1 \\,\\, \\,\\,\\, 0 \\,\\,\\,\\,\\, 0 \\,\\,\\,\\,\\, 0 \\\\\n0\\,\\, \\,\\,\\, 1 \\,\\,\\,\\,\\, 0 \\,\\,\\,\\,\\, 0 \\\\\n0\\,\\,\\,\\,\\, 0\\,\\,\\,\\,\\,  0 \\,\\,\\,\\,\\, 1 \\\\ 0\\,\\,\\,\\,\\, 0\\,\\,\\,\\,\\, 1\\,\\,\\,\\,\\, 0 \\end{bmatrix}\n\\]\n\\[ \\text{CNOT} \\ket{00} = \\ket{00} \\]\n\\[ \\text{CNOT} \\ket{10} = \\ket{11} \\]\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=2, shots=100)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.CNOT(wires=[0,1])\n    #return qml.state()\n    return qml.counts()\n\nqc()\n\n{'00': tensor(38, requires_grad=True), '11': tensor(62, requires_grad=True)}\n\n\n\nimport matplotlib.pyplot as plt\nqml.drawer.use_style(\"sketch\")\nfig, ax = qml.draw_mpl(qc)()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=2, shots=100)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.CNOT(wires=[0,1])\n    qml.X(wires=1)\n    #return qml.state()\n    return qml.counts()\n\nqc()\n\n{'01': tensor(46, requires_grad=True), '10': tensor(54, requires_grad=True)}\n\n\n\nfig, ax = qml.draw_mpl(qc)()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=2, shots=100)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.CNOT(wires=[0,1])\n    qml.Z(wires=1)\n    #return qml.state()\n    return qml.counts()\n\nqc()\n\n{'00': tensor(63, requires_grad=True), '11': tensor(37, requires_grad=True)}\n\n\n\nfig, ax = qml.draw_mpl(qc)()\nplt.show()\n\n\n\n\n\n\n\n\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=2, shots=100)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.CNOT(wires=[0,1])\n    qml.X(wires=1)\n    qml.Z(wires=1)\n    #return qml.state()\n    return qml.counts()\n\nqc()\n\n{'01': tensor(55, requires_grad=True), '10': tensor(45, requires_grad=True)}\n\n\n\nfig, ax = qml.draw_mpl(qc)()\nplt.show()",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Bramki wielokubitowe"
    ]
  },
  {
    "objectID": "labs/cw4.html#zadanie",
    "href": "labs/cw4.html#zadanie",
    "title": "Bramki wielokubitowe",
    "section": "",
    "text": "utwórz obwód dwu kubitowy: - bramka CNOT 0,1 - bramka CNOT (odwrocona) 1,0 - bramka CNOT 0,1\nOpisz jak działa ta kombinacja na stany: \\(\\ket{00}, \\ket{11}, \\ket{01},\\ket{10}\\)\nZnajdź odpowiednik tej kombinacji w bibliotece Pennylane.",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Bramki wielokubitowe"
    ]
  },
  {
    "objectID": "labs/cw4.html#zadanie-1",
    "href": "labs/cw4.html#zadanie-1",
    "title": "Bramki wielokubitowe",
    "section": "",
    "text": "utwórz obwód dwu kubitowy: - bramka CNOT - bramki H na kazdym kubicie - bramka CNOT - bramki H na kazdym kubicie - bramka CNOT",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Bramki wielokubitowe"
    ]
  },
  {
    "objectID": "labs/cw4.html#stany-ghz",
    "href": "labs/cw4.html#stany-ghz",
    "title": "Bramki wielokubitowe",
    "section": "",
    "text": "Jak realizują się stany splątane dla więcej niz dwóch kubitów\nStany Greenbergerha-Hornea-Zeilingera\npublikacja\n\ndev = qml.device('default.qubit', wires=3, shots=100)\n\n@qml.qnode(dev)\ndef qc():\n    qml.Hadamard(wires=0)\n    qml.CNOT(wires=[0,1])\n    qml.CNOT(wires=[1,2])\n    #return qml.state()\n    return qml.counts()\n\nqc()\n\n{'000': tensor(45, requires_grad=True), '111': tensor(55, requires_grad=True)}",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Bramki wielokubitowe"
    ]
  },
  {
    "objectID": "labs/cw4.html#kopiowanie-kubitu",
    "href": "labs/cw4.html#kopiowanie-kubitu",
    "title": "Bramki wielokubitowe",
    "section": "",
    "text": "Klasyczne komputery bardzo często wykorzystując operację kopiowania.\nZobaczmy jak taka operacja wygląda dla kubitów.\nRozwazmy obwod z operatorem C, który w działaniu na dwa kubity kopiuje wartość pierwszego kubitu na wynik drugiego. Drugi kubit mozna na początku ustawić w dowolnym stanie.\nChcemy skopiować stan \\(\\ket{\\psi_0} = a\\ket{0} + b\\ket{1}\\)\nStan początkowy układu: \\(\\ket{\\psi_0} \\otimes \\ket{0}\\)\nChcemy przekształcić na \\(\\ket{\\psi_0} \\otimes \\ket{\\psi_0}\\) czyli\n\\[\nC \\left(\\ket{\\psi_0} \\otimes \\ket{0}\\right) = \\ket{\\psi_0} \\otimes \\ket{\\psi_0}\n\\]\nLewa strona\n\\[\nC \\left(\\ket{\\psi_0} \\otimes \\ket{0}\\right) = C\\left(   (a\\ket{0} + b\\ket{1} )  \\otimes \\ket{0} \\right)\n\\] \\[\nC\\left( a\\ket{0} \\otimes \\ket{0} + b\\ket{1}\\otimes \\ket{0} \\right) = a C \\left(\\ket{0} \\otimes \\ket{0}\\right) + b C \\left( \\ket{1}\\otimes \\ket{0}\\right)\n\\] \\[\na \\ket{00} + b \\ket{11}\n\\]\nPrawa strona \\[\n\\ket{\\psi_0} \\otimes \\ket{\\psi_0}  = a^2 \\ket{00} + ab\\ket{01} + ab\\ket{10} + b^2\\ket{11}\n\\]",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Bramki wielokubitowe"
    ]
  },
  {
    "objectID": "labs/cw4.html#zadanie-2",
    "href": "labs/cw4.html#zadanie-2",
    "title": "Bramki wielokubitowe",
    "section": "",
    "text": "\\[\n0+0 = 00\n\\] \\[\n0+1 = 01\n\\] \\[\n1+0 = 01\n\\] \\[\n1+1 = 10\n\\]\nzauwaz, ze mamy dwa typy rozwiązań:\n\ndwa bity wejsciowe są takie same (00, 11) i dają na prawym bicie odpowiedzi 0.\ndwa bity wejsciowe są rózne (10,01) i dają na prawym bicie odpowiedzi 1.\n\nAby napisać prawidłowe rozwiązanie musimy stworzyć bramki, które będą rozpoznawać czy dwa kubity są takie same czy tez rózne. Dla przypomnienia - klasycznie rolę taką pełni bramka XOR.\n\n\n\nInput 1\nInput 2\nXOR\n\n\n\n\n0\n0\n0\n\n\n0\n1\n1\n\n\n1\n1\n1\n\n\n1\n0\n0\n\n\n\nPodobnie działa bramka CNOT\n\ndev = qml.device('default.qubit', wires=4, shots=1)\n\n@qml.qnode(dev)\ndef qc(input='00'):\n    if input[0]=='1':\n        qml.X(wires=0)\n    if input[1]=='1':\n        qml.X(wires=1)\n    qml.CNOT(wires=[0,3])\n    qml.CNOT(wires=[1,3])\n    #return qml.state()\n    return qml.counts(wires=[2,3])\n\nqc()\n\n{'00': tensor(1, requires_grad=True)}\n\n\n\nfig, ax = qml.draw_mpl(qc)()\nplt.show()\n\n\n\n\n\n\n\n\n\nfor input in ['00','01','10','11']:\n    print(f\"wartosci poczatkowe: {input} : wynik {qc(input)}\")\n\nwartosci poczatkowe: 00 : wynik {'00': tensor(1, requires_grad=True)}\nwartosci poczatkowe: 01 : wynik {'01': tensor(1, requires_grad=True)}\nwartosci poczatkowe: 10 : wynik {'01': tensor(1, requires_grad=True)}\nwartosci poczatkowe: 11 : wynik {'00': tensor(1, requires_grad=True)}\n\n\nZastosowanie dwóch CNOT do inputów rozwiązuje nam problem prawego bitu odpowiedzi.\nCo z pierszym bitem odpowiedzi otrzymywanym po pomiarzze q3 ?\n\njego wartość dla pierwszych trzech równań zawsze wynosi 0.\n\nJednak dla równania 1+1 powinniśmy otrzymać 1.\nDo rozwiązania tego problemu mozna wykorzystać bramkę operującą na 3 kubitach. Bramka ta to bramka Toffoli.\n\nimport pennylane as qml\nfrom pennylane import numpy as np \n\ndev = qml.device('default.qubit', wires=4, shots=1)\n\n@qml.qnode(dev)\ndef qc():\n    qml.X(wires=0)\n    qml.X(wires=1)\n    qml.CNOT([0,1])\n    qml.CNOT([0,2])\n    qml.Toffoli([0,1,3])\n    return qml.counts(wires=[2,3])\n\nqc()\n\nprint(\"wynik 1+1 =\",int('10', 2))\n\nwynik 1+1 = 2\n\n\n\ndev = qml.device('default.qubit', wires=4, shots=1)\n\n@qml.qnode(dev)\ndef qc(input='00'):\n    if input[0]=='1':\n        qml.X(wires=0)\n    if input[1]=='1':\n        qml.X(wires=1)\n    qml.CNOT(wires=[0,3])\n    qml.CNOT(wires=[1,3])\n    qml.Toffoli(wires=[0,1,2])\n    #return qml.state()\n    return qml.counts(wires=[2,3])\n\n\nfor input in ['00','01','10','11']:\n    print(f\"wartosci poczatkowe: {input} : wynik {qc(input)}\")\n\nwartosci poczatkowe: 00 : wynik {'00': tensor(1, requires_grad=True)}\nwartosci poczatkowe: 01 : wynik {'01': tensor(1, requires_grad=True)}\nwartosci poczatkowe: 10 : wynik {'01': tensor(1, requires_grad=True)}\nwartosci poczatkowe: 11 : wynik {'10': tensor(1, requires_grad=True)}",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Bramki wielokubitowe"
    ]
  },
  {
    "objectID": "labs/cw1.html",
    "href": "labs/cw1.html",
    "title": "Obliczenia hybrydowe",
    "section": "",
    "text": "W przypadku obliczeń (kwantowych) hybrydowe oznacza strategię mieszania klasycznych i kwantowych obliczeń. Idea ta jest podstawowym elementem optymalizacji obwodów wariacyjnych, gdzie kwantowy obwód optymalizowany jest z wykorzystaniem klasycznego ko-procesora.\nNajczęściej, obwody (i komputery) kwantowe będziemy wykorzystywać do oszacowania (obliczania) średnich z wyników pomiarów (wartość oczekiwana obserwabli), które złozyć mozna do pojedynczej klasycznej funkcji kosztu. Pozwola nam to oszacować jak dobrze wybrane obwody kwantowe dopasowują się do danych. Przykładem moze być model realizowany jako variational quantum eigensolver Peruzzo 2013\nW ogólności łatwo wyobrazić sobie bardziej interesujący sposób w którym mozna łączyć składniki klasyczne i kwantowe w większy i bardziej złozony układ Kazdy element (czy to kwantowy czy klasyczny) mozna w takim obrazku przedstawić jako klasyczny bądź kwantowy node.\nKlasyczne i kwantowe nody mozemy składać w dowolny acykliczny graf (DAG). Informacja w takim grafie przebiega w ustalonym kierunku oraz nie występują w nim cykle (pętle).\nJednym z przykładów takiego DAG’a są sieci neuronowe.\nPoniewaz mozemy obliczać gradienty variacyjnych obwodów kwantowych, obliczenia hybrydowe są kompatybilne z algorytmem propagacji wstecznej. Potwierdza to możliwość trenowania obwodów kwantowych w taki sam sposób w jaki trenuje sie klasyczne sieci neuronowe.\nKorzystając z biblioteki PyTorch możemy generować sieci neuronowe korzystając z modułu nn. Każdy taki model składa się z elementarnych warstw (ang. layers). Bilioteka PennyLane pozwala przetworzyć obiekt QNode do obiektu torch.nn.\nW pierwszym kroku stwórzmy dwa zestawy danych. Pierwszy dotyczyć będzie wartości ciągłej, natomiast drugi będzie realizował proces klasyfikacji.\nDane muszą być przekształcone do obiektu tensora realizowanego w bibliotece torch.\n# DANE  dla przewidywania zmiennej ciągłej - funkcja sinus z drobnym szumem\nimport torch\n\ntorch.manual_seed(123)\n\nX_cont = torch.linspace(0,10,500).view(-1,1)\ny_cont = torch.sin(X_cont)\ny_cont_noise = y_cont + 0.1*(torch.rand(500).view(-1,1)-0.5)\n\n# wyktres danych\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8,4))\nplt.plot(X_cont, y_cont.view(-1,1), color=\"tab:grey\", alpha=0.6, label=\"dokładne rozwiązanie\")\nplt.scatter(X_cont, y_cont_noise, label=\"dane treningowe\")\nplt.axis(\"off\")\nplt.legend()\nplt.show()\nZanim przejdziemy do daleszego etapy zdefiniujmy dodatkowe funkcje przydatne do eksploracji sieci neuronowych.\ndef mse(y_true, y_pred) -&gt; torch.Tensor:\n    return torch.mean((y_true - y_pred)**2)\n\ndef train(X, Y, model, optimiser, iteration, lossfn, callback = None):\n    \"\"\" Dodatkowa funkcja pozwalająca wykonać trenowanie naszej sieci neuronowej\"\"\"\n    for i in range(iteration):\n        optimiser.zero_grad()\n        prediction = model(X)\n        loss = lossfn(Y, prediction)\n        loss.backward()\n        optimiser.step()\n        if callback is not None: \n            callback(model, loss)\n\nlosses = []\n\ndef callback(model, loss):\n    losses.append(loss.item())\n    x = torch.linspace(0,10,500).view(-1,1)\n    clear_output(wait=True)\n    prediction = model(x).detach()\n    plt.figure(figsize=(6,2.5))\n    plt.plot(x[:,0].detach(), torch.sin(x)[:,0].detach(), label=\"Exact solution\", color=\"tab:grey\", alpha=0.6)\n    plt.plot(x[:,0].detach(), prediction[:,0], label=\"QML solution\", color=\"tab:green\")\n    plt.title(f\"Training step {len(losses)}\")\n    plt.legend()\n    plt.show()\n\n    plt.figure(figsize=(6,2.5))\n    plt.title('Lossfn Visualised')\n    plt.plot(losses)\n    plt.show()\nW następnym kroku zdefiniujmy obiekt realizujący obwód kwantowy: QNode, który chcemy podpiąć pod torch.nn. Dla uproszczenia sytuacji przyjmiemy obwód wykorzystujący 2 kubity.\nimport pennylane as qml\n\nn_qubits = 2\ndev = qml.device(\"default.qubit\", wires=n_qubits)\n# NASZ kwantowy PQC - parametryzowany obwód kwantowy dla jednej warstwy ukrytej\n@qml.qnode(dev)\ndef qnode(inputs, weights):\n    qml.AngleEmbedding(inputs, wires=range(n_qubits))\n    qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n    return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\nObwód ten pobiera dane wejściowe i przetwarza je za pomocą zdefiniowanego obwodu kodującego dane Angle Embedding. Następnie wynik tej operacji,czyli dane zanurzone do przestrzeni Hilberta stanów, są przetwarzane (obracane przez parametryczne bramki z wagami) jest przez ansatz (model kwantowy) z wykorzystaniem gotowego obwodu realizowanego jako BasicENtanglerLayers.\nCałość można zrozumieć jako jedna wartwa nn.Linear.\nBiblioteka PennyLane udostępnia obiekt TorchLayer, który pozwala na taką transformację. Zanim jednak go użyjemy musimy utworzyć słownik z wagami.\nn_layers = 5\n\nweight_shapes = {\"weights\": (n_layers, n_qubits)}\n\nqlayer = qml.qnn.TorchLayer(qnode, weight_shapes)\nclass QN(torch.nn.Module):\n    '''Classical -&gt; Quantum -&gt; Classical'''\n\n    def __init__(self, n_input: int, n_output: int, quanutm_layer):\n        super().__init__()\n\n        self.layers = torch.nn.Sequential(\n            torch.nn.Linear(n_input, n_qubits),\n            quanutm_layer,\n            torch.nn.Linear(n_qubits, n_output)\n        )\n        \n\n    def forward(self, x):\n        return  self.layers(x)\nDla przypadku estymacji funkcji sinus mamy jedną zmienną (x_cont) wejściową która zostanie połączona z dwoma kubitami następnie na wyjściu mamy również jedną zmienną (y_cont).\nreg_qmodel = QN(1, 1, qlayer)\nprint(reg_qmodel)\n\nQN(\n  (layers): Sequential(\n    (0): Linear(in_features=1, out_features=2, bias=True)\n    (1): &lt;Quantum Torch Layer: func=qnode&gt;\n    (2): Linear(in_features=2, out_features=1, bias=True)\n  )\n)\nfrom IPython.display import clear_output \n\nlearning_rate=1e-3\noptimiser = torch.optim.Adam(reg_qmodel.parameters(), lr=learning_rate)\n\ntrain(X_cont, y_cont_noise, reg_qmodel, optimiser, 200, mse, callback)\nbatches = torch.utils.data.DataLoader(\n    list(zip(X_cont, y_cont_noise)), batch_size=10, shuffle=True, drop_last=True\n)\ndef train_batch(data_loader, model, optimiser, iteration, lossfn, callback = None):\n    \"\"\" Dodatkowa funkcja pozwalająca wykonać trenowanie naszej sieci neuronowej\"\"\"\n    for i in range(iteration):\n        for X, Y in data_loader:\n            optimiser.zero_grad()\n            prediction = model(X)\n            loss = lossfn(Y, prediction)\n            loss.backward()\n            optimiser.step()\n            if callback is not None: \n                callback(model, loss)\ntrain_batch(batches, reg_qmodel, optimiser, 10, mse, callback)",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Obliczenia hybrydowe"
    ]
  },
  {
    "objectID": "labs/cw1.html#klasyfikacja-z-wykorzystaniem-kwantowej-sieci-neuronowej",
    "href": "labs/cw1.html#klasyfikacja-z-wykorzystaniem-kwantowej-sieci-neuronowej",
    "title": "Obliczenia hybrydowe",
    "section": "Klasyfikacja z wykorzystaniem kwantowej sieci neuronowej",
    "text": "Klasyfikacja z wykorzystaniem kwantowej sieci neuronowej\n\nimport torch\nimport pennylane.numpy as np\nfrom sklearn.datasets import make_moons\n\ntorch.manual_seed(123)\n\n\nX, y = make_moons(n_samples=200, noise=0.1)\n\n# create torch\n\nX = torch.from_numpy(X).to(torch.float32)\n\ny_ = torch.from_numpy(y).view(-1,1)\n\n\nc = [\"#1f77b4\" if y_ == 0 else \"#ff7f0e\" for y_ in y]  # kolorowanie\nplt.axis(\"off\")\nplt.scatter(X[:, 0], X[:, 1], c=c)\nplt.show()\n\n\ny_hot = torch.scatter(torch.zeros((200, 2)), 1, y_, 1).to(torch.float32)\n\n# X = X.clone().detach().requires_grad_(True)\n\n\n\n\n\n\n\n\n\n\nclass QN2(torch.nn.Module):\n    '''Classical -&gt; Quantum -&gt; Classical'''\n\n    def __init__(self, quanutm_layer):\n        super().__init__()\n\n        self.layers = torch.nn.Sequential(\n            torch.nn.Linear(2, 2),\n            quanutm_layer,\n            torch.nn.Linear(2, 2),\n            torch.nn.Softmax(dim=1)\n        )\n        \n\n    def forward(self, x):\n        return  self.layers(x)\n\n\nqclassifier = QN2(qlayer)\nprint(qclassifier)\n\nQN2(\n  (layers): Sequential(\n    (0): Linear(in_features=2, out_features=2, bias=True)\n    (1): &lt;Quantum Torch Layer: func=qnode&gt;\n    (2): Linear(in_features=2, out_features=2, bias=True)\n    (3): Softmax(dim=1)\n  )\n)\n\n\n\nopt = torch.optim.SGD(qclassifier.parameters(), lr=0.2)\nloss = torch.nn.L1Loss()\n\n\nbatch_size = 5\nbatches = 200 // batch_size\n\ndata_loader = torch.utils.data.DataLoader(\n    list(zip(X, y_hot)), batch_size=5, shuffle=True, drop_last=True\n)\n\nepochs = 6\n\nfor epoch in range(epochs):\n\n    running_loss = 0\n\n    for xs, ys in data_loader:\n        opt.zero_grad()\n\n        loss_evaluated = loss(qclassifier(xs), ys)\n        loss_evaluated.backward()\n\n        opt.step()\n\n        running_loss += loss_evaluated\n\n    avg_loss = running_loss / batches\n    print(\"Average loss over epoch {}: {:.4f}\".format(epoch + 1, avg_loss))\n\ny_pred = qclassifier(X)\npredictions = torch.argmax(y_pred, axis=1).detach().numpy()\n\ncorrect = [1 if p == p_true else 0 for p, p_true in zip(predictions, y)]\naccuracy = sum(correct) / len(correct)\nprint(f\"Accuracy: {accuracy * 100}%\")\n\nAverage loss over epoch 1: 0.4803\nAverage loss over epoch 2: 0.3293\nAverage loss over epoch 3: 0.2266\nAverage loss over epoch 4: 0.1889\nAverage loss over epoch 5: 0.1809\nAverage loss over epoch 6: 0.1726\nAccuracy: 86.5%\n\n\n\n\nclass HybridModel(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.clayer_1 = torch.nn.Linear(2, 4)\n        self.qlayer_1 = qml.qnn.TorchLayer(qnode, weight_shapes)\n        self.qlayer_2 = qml.qnn.TorchLayer(qnode, weight_shapes)\n        self.clayer_2 = torch.nn.Linear(4, 2)\n        self.softmax = torch.nn.Softmax(dim=1)\n\n    def forward(self, x):\n        x = self.clayer_1(x)\n        x_1, x_2 = torch.split(x, 2, dim=1)\n        x_1 = self.qlayer_1(x_1)\n        x_2 = self.qlayer_2(x_2)\n        x = torch.cat([x_1, x_2], axis=1)\n        x = self.clayer_2(x)\n        return self.softmax(x)\n\nmodel = HybridModel()\n\n\nopt = torch.optim.SGD(model.parameters(), lr=0.2)\nepochs = 6\n\nfor epoch in range(epochs):\n\n    running_loss = 0\n\n    for xs, ys in data_loader:\n        opt.zero_grad()\n\n        loss_evaluated = loss(model(xs), ys)\n        loss_evaluated.backward()\n\n        opt.step()\n\n        running_loss += loss_evaluated\n\n    avg_loss = running_loss / batches\n    print(\"Average loss over epoch {}: {:.4f}\".format(epoch + 1, avg_loss))\n\ny_pred = model(X)\npredictions = torch.argmax(y_pred, axis=1).detach().numpy()\n\ncorrect = [1 if p == p_true else 0 for p, p_true in zip(predictions, y)]\naccuracy = sum(correct) / len(correct)\nprint(f\"Accuracy: {accuracy * 100}%\")\n\nAverage loss over epoch 1: 0.4345\nAverage loss over epoch 2: 0.2538\nAverage loss over epoch 3: 0.1893\nAverage loss over epoch 4: 0.1633\nAverage loss over epoch 5: 0.1664\nAverage loss over epoch 6: 0.1548\nAccuracy: 87.0%",
    "crumbs": [
      "Sylabus",
      "Ćwiczenia",
      "Obliczenia hybrydowe"
    ]
  },
  {
    "objectID": "labs/svm.html",
    "href": "labs/svm.html",
    "title": "Wstęp do kwantowego uczenia maszynowego",
    "section": "",
    "text": "import pennylane as qml\nimport pennylane.numpy as np \n\nfrom sklearn.datasets import load_iris\n\nfrom sklearn.preprocessing import MaxAbsScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\n\n\nX, y = load_iris(return_X_y=True)\n\n\ny\n\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n\n\n\nX = X[:100, :]\ny = y[:100]\n\n\ny\n\narray([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=123)\n\n\n\n\n((30, 4), (70, 4))\n\n\n\nscaler = MaxAbsScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n\nX_test.shape, X_train.shape\n\n((30, 4), (70, 4))\n\n\nkernel \\[k(x_j, x_k)  = |\\bra{0} \\Phi^{\\dag} (x_j) \\Phi (x_k) \\ket{0}|^2\\]\n\nnum_qubits = 4 # bo 4 zmienne\n\ndev = qml.device('default.qubit', wires=num_qubits)\n\n\n@qml.qnode(dev)\ndef qc(a,b):\n    qml.AngleEmbedding(features=a, wires=range(num_qubits), rotation='X')\n    qml.adjoint(qml.AngleEmbedding(features=b, wires=range(num_qubits), rotation='X'))\n    return qml.probs(wires=range(num_qubits))\n\n\nX_train[0]\n\narray([0.73913043, 0.84090909, 0.29411765, 0.25      ])\n\n\n\nqc(X_train[0], X_train[0])\n\ntensor([1.00000000e+00, 4.40652173e-38, 5.70726749e-35, 2.00826258e-36,\n        1.74203515e-33, 5.00317179e-38, 2.19269390e-34, 2.28018454e-36,\n        0.00000000e+00, 1.85855637e-39, 1.23130106e-38, 8.47032978e-38,\n        2.10982474e-33, 9.61730693e-40, 1.56979860e-34, 4.38306648e-38], requires_grad=True)\n\n\n\ndef qkernel(A,B):\n    return np.array([[qc(a,b)[0] for a in A] for b in B ])\n\n\nqkernel[X_train,y_train]\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[60], line 1\n----&gt; 1 qkernel[X_train,y_train]\n\nTypeError: 'function' object is not subscriptable\n\n\n\n\nqsvm = SVC(kernel=qkernel)\nqsvm.fit(X_train, y_train)\n\nSVC(kernel=&lt;function qkernel at 0x17b112480&gt;)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.SVCSVC(kernel=&lt;function qkernel at 0x17b112480&gt;)\n\n\n\ny_pred = qsvm.score(X_test, y_test)\n\n\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\nCell In[69], line 1\n----&gt; 1 y_pred = qsvm.score(X_test, y_test)\n\nFile ~/Documents/GitHub/qml2024/venv/lib/python3.11/site-packages/sklearn/base.py:706, in ClassifierMixin.score(self, X, y, sample_weight)\n    681 \"\"\"\n    682 Return the mean accuracy on the given test data and labels.\n    683 \n   (...)\n    702     Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n    703 \"\"\"\n    704 from .metrics import accuracy_score\n--&gt; 706 return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n\nFile ~/Documents/GitHub/qml2024/venv/lib/python3.11/site-packages/sklearn/svm/_base.py:818, in BaseSVC.predict(self, X)\n    816     y = np.argmax(self.decision_function(X), axis=1)\n    817 else:\n--&gt; 818     y = super().predict(X)\n    819 return self.classes_.take(np.asarray(y, dtype=np.intp))\n\nFile ~/Documents/GitHub/qml2024/venv/lib/python3.11/site-packages/sklearn/svm/_base.py:433, in BaseLibSVM.predict(self, X)\n    431 X = self._validate_for_predict(X)\n    432 predict = self._sparse_predict if self._sparse else self._dense_predict\n--&gt; 433 return predict(X)\n\nFile ~/Documents/GitHub/qml2024/venv/lib/python3.11/site-packages/sklearn/svm/_base.py:444, in BaseLibSVM._dense_predict(self, X)\n    442     kernel = \"precomputed\"\n    443     if X.shape[1] != self.shape_fit_[0]:\n--&gt; 444         raise ValueError(\n    445             \"X.shape[1] = %d should be equal to %d, \"\n    446             \"the number of samples at training time\"\n    447             % (X.shape[1], self.shape_fit_[0])\n    448         )\n    450 svm_type = LIBSVM_IMPL.index(self._impl)\n    452 return libsvm.predict(\n    453     X,\n    454     self.support_,\n   (...)\n    466     cache_size=self.cache_size,\n    467 )\n\nValueError: X.shape[1] = 30 should be equal to 70, the number of samples at training time\n\n\n\n\naccuracy_score(y_pred=y_pred, y_true=y_train)\n\n1.0\n\n\n\ny_pred\n\narray([0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n       1, 0, 1, 1])\n\n\n\ny_train\n\narray([0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n       0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n       1, 0, 1, 1])"
  },
  {
    "objectID": "sylabus.html",
    "href": "sylabus.html",
    "title": "Sylabus",
    "section": "",
    "text": "Nazwa przedmiotu: Wstęp do kwantowego uczenia maszynowego\nJednostka: SGH Szkoła Główna Handlowa w Warszawie\nKod przedmiotu: 232530-D, 232530-S\nPunkty ECTS: 3\nJęzyk prowadzenia: polski\nPoziom przedmiotu: średnio-zaawansowany\nProwadzący: Sebastian Zając, sebastian.zajac@sgh.waw.pl\nWebsite: https://sebkaz-teaching.github.io/qml2024/\nSupport Program realizowany jest ze wsparciem firmy Xanadu.\nXanadu is a Canadian quantum computing company with the mission to build quantum computers that are useful and available to people everywhere. Xanadu is one of the world’s leading quantum hardware and software companies and also leads the development of PennyLane.\nPennyLane is an open-source software framework for quantum machine learning, quantum chemistry, and quantum computing, with the ability to run on all hardware.\nSupport and additional resources:"
  },
  {
    "objectID": "sylabus.html#cel-przedmiotu",
    "href": "sylabus.html#cel-przedmiotu",
    "title": "Sylabus",
    "section": "Cel Przedmiotu",
    "text": "Cel Przedmiotu\nJeszcze do niedawna rozwój technologiczny oparty był na zmniejszaniu rozmiaru tranzystorów i zwiększaniu mocy obliczeniowej procesorów. Ze względu na fizyczne aspekty natury proces ten, od pewnego momentu, musi uwzględniać ograniczenia fizyki kwantowej. Przyszłość może jednak wykorzystać inne narzędzia, których możliwości wykraczają poza klasyczne moce obliczeniowe. Mimo, iż konstrukcja komputerów kwantowych to wciąż etap inżynierski, to okazuje się, że można już wskazać i wykorzystać je do tworzenia algorytmów, które można wykorzystać w dziedzinie uczenia maszynowego. Wykorzystanie algorytmów kwantowych pozwala zmniejszyć czas przetwarzania dużej ilości danych, a tym samym rozszerza możliwości przetwarzania i modelowania danych. Przedstawione na zajęciach biblioteki - IBM qiskit czy Pennylane (python) pozwalają na prostą i szybką konstrukcje dowolnego algorytmu kwantowego. Algorytmy te, jak np. algorytm Grovera wykorzystać można do wielu problemów obliczeniowych uczenia maszynowego bądź do konstrukcji kwantowych sieci neuronowych."
  },
  {
    "objectID": "sylabus.html#program-przedmiotu",
    "href": "sylabus.html#program-przedmiotu",
    "title": "Sylabus",
    "section": "Program przedmiotu",
    "text": "Program przedmiotu\n\nKomputery klasyczne i kwantowe\nKlasyczne bramki logiczne - Algebra Boola\nPrzestrzenie wektorowe, stany kwantowe, reprezentacja klasycznych i kwantowych bitów\nKwantowe bramki logiczne w prostych algorytmach i obwodach kwantowych\nAlgorytmy kwantowego uczenia maszynowego\nBiblioteka Qiskit, Pennylane wprowadzenie\nBramki jednokubitowe\nBramki wielokubitowe\nAlgorytm Deutscha, szyfrowanie kwantowe\nParametryzowane obwody kwantowe\nWariacyjne algorytmy kwantowe\nKlasyfikacja binarna na przykładzie danych Titanic\nQAOA - jako przykład wariacyjnego algorytmu\nKwantowe sieci neuronowe cz.1\nkwantowe sieci neuronowe cz.2"
  },
  {
    "objectID": "sylabus.html#efekty-kształcenia",
    "href": "sylabus.html#efekty-kształcenia",
    "title": "Sylabus",
    "section": "Efekty kształcenia",
    "text": "Efekty kształcenia\n\nWiedza:\n\n\nZna i rozumie koncepcje działania komputera klasycznego i kwantowego\nZna metody kwantowego uczenia maszynowego możliwe do wykorzystania w biznesie\nRozumie potrzebę i możliwości zastosowania komputerów kwantowych\n\n\nUmiejętności:\n\n\nPotrafi stworzyć proste algorytmy z wykorzystaniem kwantowych bramek logicznych\nUmie wykorzystać biblioteki pythonowe do generowania kodów obliczeń kwantowych\nPotrafi wykorzystać metody nadzorowane wykorzystywane w kwantowym uczeniu maszynowym\nPotrafi wykorzystać metody nienadzorowane wykorzystywane w kwantowym uczeniu maszynowym\nUmie stworzyć prostą kwantową sieć neuronową\n\n\nKompetencje społeczne:\n\n\nformułuje problem biznesowy wraz z jego informatycznym rozwiązaniem\nuzupełniania wiedzę teoretyczną jak i praktyczną, w zakresie teorii, programowania, modelowania, nowych technologii informatycznych z wykorzystaniem kwantowego uczenia maszynowego"
  },
  {
    "objectID": "sylabus.html#realizacja-przedmiotu",
    "href": "sylabus.html#realizacja-przedmiotu",
    "title": "Sylabus",
    "section": "Realizacja przedmiotu",
    "text": "Realizacja przedmiotu\n\negzamin testowy: 40%\nkolokwium: 20%\nreferaty/eseje: 40%"
  },
  {
    "objectID": "sylabus.html#literatura",
    "href": "sylabus.html#literatura",
    "title": "Sylabus",
    "section": "Literatura",
    "text": "Literatura\n\nS. Zajac - Modelowanie dla Biznesu. Analiza danych w czasie rzeczywistym. Oficyna Wydawnicza SGH. 2021\nCybulski, J.L., Zając, S. (2024). Design Considerations for Denoising Quantum Time Series Autoencoder. Computational Science – ICCS 2024. ICCS 2024. Lecture Notes in Computer Science, vol 14837. Springer, Cham. https://doi.org/10.1007/978-3-031-63778-0_18\nM. Schuld, F. Petruccione - Supervised Learning with Quantum Computers, Quantum Science and Technology. Springer 2018 https://doi.org/10.1007/978-3-319-96424-9\nC. Bernhardt - Obliczenia kwantowe dla każdego, Wydawnictwo Naukowe PWN 2020\nP. Gawron, M. Cholewa, … Rewolucja stanu. Fantastyczne wprowadzenie do informatyki kwantowej. Quantumz.io 2021\nA. Saxena, J. Mancilla, I. Montalban, C. Pere, Financial Modeling Using Quantum Computing. Packt 2023\nA. Jacquier, O. Kondratyev, Quantum Machine Learning and Optimisation in Finance. On the Road to Quantum Advantage."
  },
  {
    "objectID": "sylabus.html#literatura-uzupełniająca",
    "href": "sylabus.html#literatura-uzupełniająca",
    "title": "Sylabus",
    "section": "Literatura uzupełniająca",
    "text": "Literatura uzupełniająca\n\nMichael A. Nielsen & Isaac L. Chuang - Quantum Computation and Quantum Information, Cambridge University Press, 2010\nK. Przanowski, S. Zając - Modelowanie dla Biznesu. Metody Machine learning, Modele portfela consumer finance, modelek rekurencyjne analizy przeżycia, modele scoringowe. Oficyna Wydawnicza SGH. 2020\nE. Frątczak - Modelowanie dla Biznesu. Regresja Logistyczna, Regresja Poissona, Survival Data Mining, CRM, Credit Scoring. Oficyna Wydawnicza SGH. 2019"
  },
  {
    "objectID": "checks/Untitled.html",
    "href": "checks/Untitled.html",
    "title": "Wstęp do kwantowego uczenia maszynowego",
    "section": "",
    "text": "from sklearn.datasets import make_classification\nimport torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nX, y = make_classification(n_samples=10**3, n_features=10 ,random_state=42)\n\n\nX_train = torch.from_numpy(X.astype(np.float32))\ny_train = torch.from_numpy(y.astype(np.float32))\n\ny_train = y_train.view(y_train.shape[0], 1)\n\n\nclass LogisticRegression(torch.nn.Module):\n\n    def __init__(self, inputSize, outputSize):\n        super(LogisticRegression, self).__init__()\n        self.linear = torch.nn.Linear(inputSize, outputSize)\n\n    def forward(self, x):\n        x = self.linear(x)\n        y_pred = torch.sigmoid(x)\n        return y_pred\n\n\ninputDim = X_train.shape[1]\noutputDim = y_train.shape[1]\nlearningRate = 0.01\nepochs = 100\n\nmodel = LogisticRegression(inputDim, outputDim)\n\n\n#criterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\ncriterion = torch.nn.BCELoss()\n\n\na = model(X_train[:2])\n\n\na\n\n\nloss = criterion(a, y_train[0:2])\n\n\nloss\n\n\n\n# training loop\nnum_epochs = 200\n\nfor epoch in range(num_epochs):\n    # forward pass and loss\n    y_predicted = model(X_train)\n    loss = criterion(y_predicted, y_train)\n    \n    # backward pass\n    loss.backward()\n    \n    # updates\n    optimizer.step()\n    \n    # zero gradients\n    optimizer.zero_grad()\n    \n    if (epoch+1) % 25 == 0:\n        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n\n\nwith torch.no_grad():\n    y_predicted = model(X_train)  # no need to call model.forward()\n    y_predicted_cls = y_predicted.round()   # round off to nearest class\n    acc = y_predicted_cls.eq(y_train).sum() / float(y_train.shape[0])  # accuracy\n    print(f'accuracy = {acc:.4f}')\n\n\nimport torch\nx = torch.linspace(0,10,500)\ny = torch.sin(x)\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(8,4))\nplt.plot(x, y, color=\"tab:grey\", alpha=0.6, label=\"sin(x)\")\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\ny\n\ntensor([ 0.0000,  0.0200,  0.0401,  0.0601,  0.0801,  0.1000,  0.1200,  0.1398,\n         0.1596,  0.1794,  0.1991,  0.2187,  0.2382,  0.2576,  0.2769,  0.2961,\n         0.3152,  0.3341,  0.3529,  0.3716,  0.3902,  0.4085,  0.4267,  0.4448,\n         0.4626,  0.4803,  0.4978,  0.5151,  0.5321,  0.5490,  0.5656,  0.5820,\n         0.5982,  0.6142,  0.6299,  0.6453,  0.6605,  0.6754,  0.6900,  0.7044,\n         0.7185,  0.7323,  0.7458,  0.7590,  0.7719,  0.7844,  0.7967,  0.8087,\n         0.8203,  0.8316,  0.8426,  0.8532,  0.8635,  0.8734,  0.8830,  0.8922,\n         0.9011,  0.9096,  0.9177,  0.9255,  0.9329,  0.9399,  0.9466,  0.9529,\n         0.9587,  0.9643,  0.9694,  0.9741,  0.9784,  0.9824,  0.9859,  0.9891,\n         0.9918,  0.9942,  0.9961,  0.9977,  0.9989,  0.9996,  1.0000,  0.9999,\n         0.9995,  0.9986,  0.9974,  0.9957,  0.9937,  0.9912,  0.9884,  0.9851,\n         0.9815,  0.9774,  0.9730,  0.9682,  0.9630,  0.9574,  0.9514,  0.9451,\n         0.9383,  0.9312,  0.9237,  0.9159,  0.9076,  0.8990,  0.8901,  0.8808,\n         0.8711,  0.8611,  0.8507,  0.8400,  0.8290,  0.8176,  0.8059,  0.7939,\n         0.7815,  0.7689,  0.7559,  0.7426,  0.7291,  0.7152,  0.7010,  0.6866,\n         0.6719,  0.6569,  0.6417,  0.6262,  0.6104,  0.5945,  0.5782,  0.5618,\n         0.5451,  0.5282,  0.5110,  0.4937,  0.4762,  0.4585,  0.4406,  0.4225,\n         0.4042,  0.3858,  0.3673,  0.3485,  0.3297,  0.3107,  0.2916,  0.2724,\n         0.2530,  0.2336,  0.2141,  0.1945,  0.1748,  0.1550,  0.1352,  0.1153,\n         0.0954,  0.0754,  0.0554,  0.0354,  0.0153, -0.0047, -0.0247, -0.0448,\n        -0.0648, -0.0848, -0.1047, -0.1246, -0.1445, -0.1643, -0.1840, -0.2037,\n        -0.2232, -0.2427, -0.2621, -0.2814, -0.3006, -0.3196, -0.3386, -0.3573,\n        -0.3760, -0.3945, -0.4128, -0.4310, -0.4490, -0.4668, -0.4844, -0.5019,\n        -0.5191, -0.5361, -0.5529, -0.5695, -0.5859, -0.6020, -0.6179, -0.6335,\n        -0.6489, -0.6640, -0.6788, -0.6934, -0.7077, -0.7217, -0.7355, -0.7489,\n        -0.7620, -0.7748, -0.7874, -0.7995, -0.8114, -0.8230, -0.8342, -0.8451,\n        -0.8556, -0.8658, -0.8757, -0.8852, -0.8943, -0.9031, -0.9115, -0.9196,\n        -0.9273, -0.9346, -0.9415, -0.9481, -0.9543, -0.9601, -0.9655, -0.9705,\n        -0.9751, -0.9794, -0.9832, -0.9867, -0.9898, -0.9924, -0.9947, -0.9965,\n        -0.9980, -0.9991, -0.9997, -1.0000, -0.9999, -0.9993, -0.9984, -0.9970,\n        -0.9953, -0.9931, -0.9906, -0.9876, -0.9843, -0.9806, -0.9764, -0.9719,\n        -0.9670, -0.9617, -0.9560, -0.9500, -0.9435, -0.9367, -0.9295, -0.9219,\n        -0.9140, -0.9056, -0.8970, -0.8879, -0.8785, -0.8688, -0.8587, -0.8482,\n        -0.8375, -0.8263, -0.8149, -0.8031, -0.7910, -0.7786, -0.7659, -0.7528,\n        -0.7395, -0.7258, -0.7119, -0.6977, -0.6832, -0.6684, -0.6534, -0.6381,\n        -0.6225, -0.6067, -0.5907, -0.5744, -0.5579, -0.5411, -0.5242, -0.5070,\n        -0.4896, -0.4720, -0.4543, -0.4363, -0.4182, -0.3999, -0.3815, -0.3629,\n        -0.3441, -0.3253, -0.3062, -0.2871, -0.2679, -0.2485, -0.2290, -0.2095,\n        -0.1898, -0.1701, -0.1503, -0.1305, -0.1106, -0.0907, -0.0707, -0.0507,\n        -0.0307, -0.0106,  0.0094,  0.0294,  0.0495,  0.0695,  0.0894,  0.1094,\n         0.1293,  0.1491,  0.1689,  0.1886,  0.2083,  0.2278,  0.2473,  0.2667,\n         0.2859,  0.3051,  0.3241,  0.3430,  0.3617,  0.3803,  0.3988,  0.4171,\n         0.4352,  0.4532,  0.4709,  0.4885,  0.5059,  0.5231,  0.5401,  0.5568,\n         0.5734,  0.5897,  0.6057,  0.6216,  0.6371,  0.6524,  0.6675,  0.6823,\n         0.6968,  0.7110,  0.7250,  0.7386,  0.7520,  0.7651,  0.7778,  0.7902,\n         0.8024,  0.8142,  0.8256,  0.8368,  0.8476,  0.8580,  0.8682,  0.8779,\n         0.8873,  0.8964,  0.9051,  0.9135,  0.9214,  0.9290,  0.9363,  0.9431,\n         0.9496,  0.9557,  0.9614,  0.9667,  0.9716,  0.9762,  0.9803,  0.9841,\n         0.9875,  0.9904,  0.9930,  0.9952,  0.9969,  0.9983,  0.9993,  0.9998,\n         1.0000,  0.9998,  0.9991,  0.9981,  0.9966,  0.9948,  0.9926,  0.9899,\n         0.9869,  0.9835,  0.9796,  0.9754,  0.9708,  0.9658,  0.9604,  0.9546,\n         0.9485,  0.9419,  0.9350,  0.9277,  0.9201,  0.9120,  0.9036,  0.8949,\n         0.8857,  0.8763,  0.8664,  0.8563,  0.8457,  0.8349,  0.8237,  0.8121,\n         0.8003,  0.7881,  0.7756,  0.7628,  0.7497,  0.7363,  0.7226,  0.7086,\n         0.6943,  0.6798,  0.6649,  0.6498,  0.6345,  0.6188,  0.6030,  0.5869,\n         0.5705,  0.5540,  0.5372,  0.5201,  0.5029,  0.4855,  0.4679,  0.4501,\n         0.4321,  0.4139,  0.3956,  0.3771,  0.3585,  0.3397,  0.3208,  0.3018,\n         0.2826,  0.2633,  0.2439,  0.2245,  0.2049,  0.1852,  0.1655,  0.1457,\n         0.1258,  0.1059,  0.0860,  0.0660,  0.0460,  0.0260,  0.0059, -0.0141,\n        -0.0341, -0.0542, -0.0742, -0.0941, -0.1141, -0.1339, -0.1538, -0.1735,\n        -0.1932, -0.2129, -0.2324, -0.2518, -0.2712, -0.2904, -0.3095, -0.3285,\n        -0.3474, -0.3661, -0.3847, -0.4031, -0.4214, -0.4394, -0.4574, -0.4751,\n        -0.4926, -0.5100, -0.5271, -0.5440])\n\n\n\n(y + 0.1*(torch.rand(500) -0.5)).view(-1,1)\n\ntensor([[-0.0056],\n        [-0.0162],\n        [ 0.0745],\n        [ 0.0534],\n        [ 0.0909],\n        [ 0.0974],\n        [ 0.0877],\n        [ 0.1128],\n        [ 0.1871],\n        [ 0.1667],\n        [ 0.2139],\n        [ 0.1877],\n        [ 0.2292],\n        [ 0.2291],\n        [ 0.3061],\n        [ 0.2577],\n        [ 0.3596],\n        [ 0.3161],\n        [ 0.3474],\n        [ 0.3732],\n        [ 0.4109],\n        [ 0.3788],\n        [ 0.3812],\n        [ 0.4138],\n        [ 0.5085],\n        [ 0.4971],\n        [ 0.5123],\n        [ 0.4901],\n        [ 0.5118],\n        [ 0.5905],\n        [ 0.5192],\n        [ 0.6178],\n        [ 0.5896],\n        [ 0.5871],\n        [ 0.6222],\n        [ 0.6526],\n        [ 0.6134],\n        [ 0.6717],\n        [ 0.7379],\n        [ 0.6970],\n        [ 0.6965],\n        [ 0.7027],\n        [ 0.7437],\n        [ 0.8057],\n        [ 0.7320],\n        [ 0.8269],\n        [ 0.8025],\n        [ 0.8110],\n        [ 0.8457],\n        [ 0.8508],\n        [ 0.8807],\n        [ 0.8828],\n        [ 0.8965],\n        [ 0.8711],\n        [ 0.9050],\n        [ 0.8783],\n        [ 0.9418],\n        [ 0.8951],\n        [ 0.9217],\n        [ 0.9699],\n        [ 0.9474],\n        [ 0.9318],\n        [ 0.9742],\n        [ 0.9303],\n        [ 0.9141],\n        [ 0.9761],\n        [ 0.9252],\n        [ 1.0177],\n        [ 1.0261],\n        [ 1.0102],\n        [ 0.9488],\n        [ 0.9574],\n        [ 0.9866],\n        [ 0.9870],\n        [ 0.9621],\n        [ 1.0406],\n        [ 0.9684],\n        [ 0.9730],\n        [ 1.0213],\n        [ 1.0044],\n        [ 1.0080],\n        [ 1.0033],\n        [ 0.9714],\n        [ 1.0254],\n        [ 1.0227],\n        [ 1.0245],\n        [ 1.0160],\n        [ 1.0139],\n        [ 0.9457],\n        [ 0.9396],\n        [ 0.9642],\n        [ 0.9788],\n        [ 0.9919],\n        [ 0.9687],\n        [ 0.9899],\n        [ 0.9740],\n        [ 0.8966],\n        [ 0.8905],\n        [ 0.8893],\n        [ 0.8975],\n        [ 0.8589],\n        [ 0.8601],\n        [ 0.9318],\n        [ 0.8833],\n        [ 0.8760],\n        [ 0.8169],\n        [ 0.8903],\n        [ 0.8054],\n        [ 0.8469],\n        [ 0.7703],\n        [ 0.8279],\n        [ 0.7703],\n        [ 0.7529],\n        [ 0.7383],\n        [ 0.8002],\n        [ 0.6961],\n        [ 0.7388],\n        [ 0.6807],\n        [ 0.6718],\n        [ 0.6848],\n        [ 0.7146],\n        [ 0.6898],\n        [ 0.6374],\n        [ 0.5805],\n        [ 0.5679],\n        [ 0.5741],\n        [ 0.5697],\n        [ 0.5141],\n        [ 0.5718],\n        [ 0.4997],\n        [ 0.5465],\n        [ 0.5002],\n        [ 0.5107],\n        [ 0.4158],\n        [ 0.4247],\n        [ 0.4010],\n        [ 0.4007],\n        [ 0.4327],\n        [ 0.3273],\n        [ 0.3601],\n        [ 0.3105],\n        [ 0.2736],\n        [ 0.2459],\n        [ 0.2542],\n        [ 0.2180],\n        [ 0.2489],\n        [ 0.2245],\n        [ 0.1490],\n        [ 0.1499],\n        [ 0.1284],\n        [ 0.1426],\n        [ 0.1641],\n        [ 0.0817],\n        [ 0.0596],\n        [ 0.0868],\n        [ 0.0279],\n        [ 0.0015],\n        [ 0.0192],\n        [-0.0083],\n        [-0.0378],\n        [-0.0300],\n        [-0.0797],\n        [-0.0678],\n        [-0.1721],\n        [-0.1551],\n        [-0.1979],\n        [-0.2288],\n        [-0.1981],\n        [-0.2337],\n        [-0.2376],\n        [-0.3118],\n        [-0.2983],\n        [-0.3231],\n        [-0.2837],\n        [-0.3341],\n        [-0.3957],\n        [-0.3272],\n        [-0.4182],\n        [-0.4360],\n        [-0.3990],\n        [-0.4462],\n        [-0.4347],\n        [-0.5307],\n        [-0.5107],\n        [-0.5089],\n        [-0.5593],\n        [-0.5366],\n        [-0.5227],\n        [-0.6336],\n        [-0.6245],\n        [-0.5743],\n        [-0.5952],\n        [-0.6041],\n        [-0.6307],\n        [-0.6749],\n        [-0.6930],\n        [-0.7550],\n        [-0.7349],\n        [-0.7789],\n        [-0.7489],\n        [-0.7431],\n        [-0.7456],\n        [-0.7611],\n        [-0.7697],\n        [-0.8215],\n        [-0.7895],\n        [-0.8768],\n        [-0.8284],\n        [-0.8738],\n        [-0.8229],\n        [-0.9059],\n        [-0.8798],\n        [-0.8812],\n        [-0.8934],\n        [-0.8925],\n        [-0.9009],\n        [-0.9559],\n        [-0.9181],\n        [-0.9300],\n        [-0.9771],\n        [-0.9512],\n        [-0.9252],\n        [-0.9484],\n        [-0.9810],\n        [-0.9393],\n        [-0.9998],\n        [-1.0128],\n        [-0.9640],\n        [-0.9543],\n        [-1.0076],\n        [-1.0007],\n        [-1.0423],\n        [-1.0340],\n        [-0.9720],\n        [-0.9536],\n        [-1.0041],\n        [-1.0223],\n        [-1.0261],\n        [-0.9867],\n        [-1.0379],\n        [-1.0154],\n        [-0.9875],\n        [-0.9674],\n        [-0.9969],\n        [-0.9604],\n        [-1.0057],\n        [-0.9811],\n        [-0.9293],\n        [-0.9764],\n        [-0.9593],\n        [-0.9088],\n        [-0.9775],\n        [-0.9810],\n        [-0.9798],\n        [-0.9103],\n        [-0.9697],\n        [-0.8714],\n        [-0.9366],\n        [-0.9241],\n        [-0.9289],\n        [-0.9276],\n        [-0.8304],\n        [-0.8622],\n        [-0.8205],\n        [-0.8099],\n        [-0.8753],\n        [-0.7867],\n        [-0.8153],\n        [-0.8311],\n        [-0.7557],\n        [-0.7916],\n        [-0.7267],\n        [-0.7853],\n        [-0.7385],\n        [-0.7543],\n        [-0.6566],\n        [-0.7268],\n        [-0.6655],\n        [-0.6616],\n        [-0.6667],\n        [-0.5902],\n        [-0.5801],\n        [-0.6181],\n        [-0.5941],\n        [-0.5217],\n        [-0.5863],\n        [-0.5120],\n        [-0.4866],\n        [-0.4627],\n        [-0.4934],\n        [-0.5030],\n        [-0.3938],\n        [-0.4449],\n        [-0.3759],\n        [-0.4208],\n        [-0.3209],\n        [-0.3426],\n        [-0.3361],\n        [-0.3230],\n        [-0.3159],\n        [-0.2857],\n        [-0.2163],\n        [-0.2331],\n        [-0.2535],\n        [-0.2188],\n        [-0.1775],\n        [-0.1992],\n        [-0.1537],\n        [-0.0802],\n        [-0.0998],\n        [-0.0818],\n        [-0.0270],\n        [-0.0630],\n        [-0.0429],\n        [ 0.0556],\n        [ 0.0437],\n        [ 0.0133],\n        [ 0.1109],\n        [ 0.1386],\n        [ 0.1535],\n        [ 0.1278],\n        [ 0.1062],\n        [ 0.2061],\n        [ 0.2112],\n        [ 0.2279],\n        [ 0.2697],\n        [ 0.2395],\n        [ 0.2483],\n        [ 0.3105],\n        [ 0.2988],\n        [ 0.3141],\n        [ 0.3646],\n        [ 0.3321],\n        [ 0.3751],\n        [ 0.3691],\n        [ 0.4456],\n        [ 0.3996],\n        [ 0.4076],\n        [ 0.5158],\n        [ 0.4910],\n        [ 0.5493],\n        [ 0.5706],\n        [ 0.5862],\n        [ 0.5177],\n        [ 0.5795],\n        [ 0.6370],\n        [ 0.6151],\n        [ 0.6641],\n        [ 0.6140],\n        [ 0.6513],\n        [ 0.7115],\n        [ 0.6721],\n        [ 0.6609],\n        [ 0.6803],\n        [ 0.7517],\n        [ 0.7032],\n        [ 0.7768],\n        [ 0.7395],\n        [ 0.7755],\n        [ 0.8327],\n        [ 0.7671],\n        [ 0.8598],\n        [ 0.8258],\n        [ 0.7982],\n        [ 0.8145],\n        [ 0.9049],\n        [ 0.8535],\n        [ 0.8814],\n        [ 0.9217],\n        [ 0.9118],\n        [ 0.9283],\n        [ 0.8672],\n        [ 0.9243],\n        [ 0.8922],\n        [ 0.9131],\n        [ 0.8961],\n        [ 0.9915],\n        [ 0.9737],\n        [ 1.0034],\n        [ 0.9178],\n        [ 0.9545],\n        [ 0.9546],\n        [ 0.9870],\n        [ 1.0298],\n        [ 0.9881],\n        [ 0.9960],\n        [ 1.0108],\n        [ 1.0330],\n        [ 1.0252],\n        [ 0.9654],\n        [ 1.0063],\n        [ 0.9748],\n        [ 1.0171],\n        [ 0.9737],\n        [ 0.9697],\n        [ 1.0002],\n        [ 1.0418],\n        [ 1.0403],\n        [ 1.0160],\n        [ 1.0084],\n        [ 1.0036],\n        [ 1.0267],\n        [ 0.9916],\n        [ 0.9362],\n        [ 1.0098],\n        [ 0.9726],\n        [ 0.9595],\n        [ 0.9484],\n        [ 0.9084],\n        [ 0.9823],\n        [ 0.8991],\n        [ 0.9653],\n        [ 0.9277],\n        [ 0.9341],\n        [ 0.9333],\n        [ 0.8655],\n        [ 0.9336],\n        [ 0.8403],\n        [ 0.8574],\n        [ 0.8428],\n        [ 0.8192],\n        [ 0.8596],\n        [ 0.8325],\n        [ 0.8263],\n        [ 0.8056],\n        [ 0.8008],\n        [ 0.7723],\n        [ 0.7891],\n        [ 0.7370],\n        [ 0.7175],\n        [ 0.7364],\n        [ 0.7166],\n        [ 0.6568],\n        [ 0.7142],\n        [ 0.7107],\n        [ 0.6304],\n        [ 0.6100],\n        [ 0.5725],\n        [ 0.5731],\n        [ 0.6278],\n        [ 0.5446],\n        [ 0.5356],\n        [ 0.5427],\n        [ 0.5091],\n        [ 0.5122],\n        [ 0.4673],\n        [ 0.5046],\n        [ 0.4691],\n        [ 0.4500],\n        [ 0.4347],\n        [ 0.3935],\n        [ 0.3352],\n        [ 0.3193],\n        [ 0.3891],\n        [ 0.2789],\n        [ 0.3389],\n        [ 0.3064],\n        [ 0.3058],\n        [ 0.2837],\n        [ 0.2546],\n        [ 0.1664],\n        [ 0.1471],\n        [ 0.1474],\n        [ 0.1019],\n        [ 0.1677],\n        [ 0.1264],\n        [ 0.0780],\n        [ 0.1080],\n        [ 0.0335],\n        [ 0.0685],\n        [-0.0379],\n        [-0.0549],\n        [-0.0577],\n        [-0.0959],\n        [-0.0948],\n        [-0.1085],\n        [-0.1634],\n        [-0.1356],\n        [-0.1422],\n        [-0.1446],\n        [-0.1650],\n        [-0.1917],\n        [-0.2519],\n        [-0.2223],\n        [-0.3015],\n        [-0.3362],\n        [-0.3200],\n        [-0.3133],\n        [-0.3563],\n        [-0.3390],\n        [-0.3529],\n        [-0.4460],\n        [-0.4293],\n        [-0.4582],\n        [-0.5074],\n        [-0.4392],\n        [-0.5367],\n        [-0.4962],\n        [-0.4891],\n        [-0.5476]])\n\n\n\nX = x.view(-1,1)\nY = y.view(-1,1) + 0.1*(torch.rand(500).view(-1,1) - 0.5)\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(8,4))\nplt.plot(X, Y, label=\"data\")\nplt.plot(X, y.view(-1,1), color=\"grey\", alpha=0.7,   label=\"sin(x)\")\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "checks/other/qiskitML.html",
    "href": "checks/other/qiskitML.html",
    "title": "Qiskit Machine Learning",
    "section": "",
    "text": "dokumentacja\n\nQuantum Kernels (Quantum Support Vector Classifier, Quantum Support Vector Regressor)\nQuantum Neural Networks (Variational Quantum Classifier, Variational Quantum Regressor), fature map (ZZFeatureMap, ZFeatureMap, PauliFeatureMap) i ansatz (RealAmplitudes, EfficientSU2, ZZFeatureMap, ZFeatureMap, PauliFeatureMap). Posiada również konektor do PyTorcha.\n\nużywane do klasyfikacji (QSVC) i regresjii (QSVR). Pozwalają na używanie kwantowego uczenia maszynowego bez wiedzy o obliczeniach kwantowych.\n\n# instalacja \n!pip install --upgrade pip\n!pip install qiskit-machine-learning\n!pip install 'qiskit-machine-learning[torch]'\n!pip install 'qiskit-machine-learning[sparse]' \n# !pip install ipywidgets ipykernel\n\n\nimport qiskit.tools.jupyter\n\n%qiskit_version_table\n\nVersion Information\n\n\n\nSoftware\nVersion\n\n\nqiskit\nNone\n\n\nqiskit-terra\n0.25.2\n\n\nSystem information\n\n\nPython version\n3.10.12\n\n\nPython compiler\nClang 14.0.3 (clang-1403.0.22.14.1)\n\n\nPython build\nmain, Jul 28 2023 18:34:01\n\n\nOS\nDarwin\n\n\nCPUs\n8\n\n\nMemory (Gb)\n16.0\n\n\nSun Oct 15 20:37:42 2023 CEST"
  },
  {
    "objectID": "checks/ml.html",
    "href": "checks/ml.html",
    "title": "Kwantowy model klasyfikatora wariacyjnego",
    "section": "",
    "text": "from sklearn.datasets import load_iris\niris = load_iris()\n\n\nprint(iris.DESCR)\n\n.. _iris_dataset:\n\nIris plants dataset\n--------------------\n\n**Data Set Characteristics:**\n\n    :Number of Instances: 150 (50 in each of three classes)\n    :Number of Attributes: 4 numeric, predictive attributes and the class\n    :Attribute Information:\n        - sepal length in cm\n        - sepal width in cm\n        - petal length in cm\n        - petal width in cm\n        - class:\n                - Iris-Setosa\n                - Iris-Versicolour\n                - Iris-Virginica\n                \n    :Summary Statistics:\n\n    ============== ==== ==== ======= ===== ====================\n                    Min  Max   Mean    SD   Class Correlation\n    ============== ==== ==== ======= ===== ====================\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n    ============== ==== ==== ======= ===== ====================\n\n    :Missing Attribute Values: None\n    :Class Distribution: 33.3% for each of 3 classes.\n    :Creator: R.A. Fisher\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n    :Date: July, 1988\n\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\nfrom Fisher's paper. Note that it's the same as in R, but not as in the UCI\nMachine Learning Repository, which has two wrong data points.\n\nThis is perhaps the best known database to be found in the\npattern recognition literature.  Fisher's paper is a classic in the field and\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\ndata set contains 3 classes of 50 instances each, where each class refers to a\ntype of iris plant.  One class is linearly separable from the other 2; the\nlatter are NOT linearly separable from each other.\n\n|details-start|\n**References**\n|details-split|\n\n- Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n  Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n  Mathematical Statistics\" (John Wiley, NY, 1950).\n- Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n  (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n- Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n  Structure and Classification Rule for Recognition in Partially Exposed\n  Environments\".  IEEE Transactions on Pattern Analysis and Machine\n  Intelligence, Vol. PAMI-2, No. 1, 67-71.\n- Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n  on Information Theory, May 1972, 431-433.\n- See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n  conceptual clustering system finds 3 classes in the data.\n- Many, many more ...\n\n|details-end|\n\n\n\nfeatures = iris.data\nlabels = iris.target"
  },
  {
    "objectID": "checks/ml.html#załadowanie-danych",
    "href": "checks/ml.html#załadowanie-danych",
    "title": "Kwantowy model klasyfikatora wariacyjnego",
    "section": "",
    "text": "from sklearn.datasets import load_iris\niris = load_iris()\n\n\nprint(iris.DESCR)\n\n.. _iris_dataset:\n\nIris plants dataset\n--------------------\n\n**Data Set Characteristics:**\n\n    :Number of Instances: 150 (50 in each of three classes)\n    :Number of Attributes: 4 numeric, predictive attributes and the class\n    :Attribute Information:\n        - sepal length in cm\n        - sepal width in cm\n        - petal length in cm\n        - petal width in cm\n        - class:\n                - Iris-Setosa\n                - Iris-Versicolour\n                - Iris-Virginica\n                \n    :Summary Statistics:\n\n    ============== ==== ==== ======= ===== ====================\n                    Min  Max   Mean    SD   Class Correlation\n    ============== ==== ==== ======= ===== ====================\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n    ============== ==== ==== ======= ===== ====================\n\n    :Missing Attribute Values: None\n    :Class Distribution: 33.3% for each of 3 classes.\n    :Creator: R.A. Fisher\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n    :Date: July, 1988\n\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\nfrom Fisher's paper. Note that it's the same as in R, but not as in the UCI\nMachine Learning Repository, which has two wrong data points.\n\nThis is perhaps the best known database to be found in the\npattern recognition literature.  Fisher's paper is a classic in the field and\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\ndata set contains 3 classes of 50 instances each, where each class refers to a\ntype of iris plant.  One class is linearly separable from the other 2; the\nlatter are NOT linearly separable from each other.\n\n|details-start|\n**References**\n|details-split|\n\n- Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n  Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n  Mathematical Statistics\" (John Wiley, NY, 1950).\n- Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n  (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n- Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n  Structure and Classification Rule for Recognition in Partially Exposed\n  Environments\".  IEEE Transactions on Pattern Analysis and Machine\n  Intelligence, Vol. PAMI-2, No. 1, 67-71.\n- Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n  on Information Theory, May 1972, 431-433.\n- See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n  conceptual clustering system finds 3 classes in the data.\n- Many, many more ...\n\n|details-end|\n\n\n\nfeatures = iris.data\nlabels = iris.target"
  },
  {
    "objectID": "checks/ml.html#normalizacja",
    "href": "checks/ml.html#normalizacja",
    "title": "Kwantowy model klasyfikatora wariacyjnego",
    "section": "Normalizacja",
    "text": "Normalizacja\nZastosujemy prostą transformację aby przedstawić wszystkie zmienne w tej samej skali. Zamienimy wszystkie zmienne do skali \\(\\left[ 0,1 \\right]\\). Normalizacja danych to technika uczenia maszynowego przetworzenia danych pozwalająca na (często) lepszą i szybszą zbiezność algorytmów.\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nfeatures = MinMaxScaler().fit_transform(features)\n\n\nimport pandas as pd \nimport numpy as np\nimport seaborn as sns\n\ndf = pd.DataFrame(features, columns=iris.feature_names)\ndf['class'] = pd.Series(iris.target)\ndf.head()\n\n\n\n\n\n\n\n\nsepal length (cm)\nsepal width (cm)\npetal length (cm)\npetal width (cm)\nclass\n\n\n\n\n0\n0.222222\n0.625000\n0.067797\n0.041667\n0\n\n\n1\n0.166667\n0.416667\n0.067797\n0.041667\n0\n\n\n2\n0.111111\n0.500000\n0.050847\n0.041667\n0\n\n\n3\n0.083333\n0.458333\n0.084746\n0.041667\n0\n\n\n4\n0.194444\n0.666667\n0.067797\n0.041667\n0\n\n\n\n\n\n\n\n\nsns.pairplot(df, hue=\"class\", palette=\"tab10\")\n\n\n\n\n\n\n\n\nZ otrzymanego wykresu łatwo zauwazyć iz klasa 0 jest dobrze separowalna szczególnie dla zmiennej sepal width."
  },
  {
    "objectID": "checks/ml.html#klasyczny-model-svc",
    "href": "checks/ml.html#klasyczny-model-svc",
    "title": "Kwantowy model klasyfikatora wariacyjnego",
    "section": "Klasyczny model SVC",
    "text": "Klasyczny model SVC\n\nfrom sklearn.model_selection import train_test_split\nfrom qiskit_algorithms.utils import algorithm_globals\n\n\n\nalgorithm_globals.random_seed = 123\ntrain_features, test_features, train_labels, test_labels = train_test_split(\n    features, labels, train_size=0.8, random_state=algorithm_globals.random_seed\n)\n\nfrom sklearn.svm import SVC\n\nsvc = SVC()\n_ = svc.fit(train_features, train_labels)\n\ntrain_score_c4 = svc.score(train_features, train_labels)\ntest_score_c4 = svc.score(test_features, test_labels)\n\nprint(f\"Classical SVC on the training dataset: {train_score_c4:.2f}\")\nprint(f\"Classical SVC on the test dataset:     {test_score_c4:.2f}\")\n\nClassical SVC on the training dataset: 0.99\nClassical SVC on the test dataset:     0.97"
  },
  {
    "objectID": "checks/ml.html#kodowanie-danych---zzfeaturemap",
    "href": "checks/ml.html#kodowanie-danych---zzfeaturemap",
    "title": "Kwantowy model klasyfikatora wariacyjnego",
    "section": "Kodowanie danych - ZZFeatureMap",
    "text": "Kodowanie danych - ZZFeatureMap\n\nfrom qiskit.circuit.library import ZZFeatureMap\nnum_features = features.shape[1]\n\nfeature_map = ZZFeatureMap(feature_dimension=num_features, reps=1)\nfeature_map.decompose().draw(output=\"mpl\", fold=20)\n\n\n\n\n\n\n\n\nPrzyjrzyj się uwaznie i zobacz, ze obwód ten jest parametryzowany przez cztery zmienne \\(x \\left[ 0 \\right],\\ldots x\\left[3\\right]\\)."
  },
  {
    "objectID": "checks/ml.html#wybór-modelu---realamplitudes",
    "href": "checks/ml.html#wybór-modelu---realamplitudes",
    "title": "Kwantowy model klasyfikatora wariacyjnego",
    "section": "Wybór modelu - RealAmplitudes",
    "text": "Wybór modelu - RealAmplitudes\n\nfrom qiskit.circuit.library import RealAmplitudes\n\nansatz = RealAmplitudes(num_qubits=num_features, reps=3)\nansatz.decompose().draw(output=\"mpl\", fold=20)"
  },
  {
    "objectID": "checks/ml.html#wybór-optymalizatora-cobyla",
    "href": "checks/ml.html#wybór-optymalizatora-cobyla",
    "title": "Kwantowy model klasyfikatora wariacyjnego",
    "section": "Wybór optymalizatora COBYLA",
    "text": "Wybór optymalizatora COBYLA\n\nfrom qiskit_algorithms.optimizers import COBYLA\n\noptimizer = COBYLA(maxiter=100)\n\n\nfrom qiskit.primitives import Sampler\n\nsampler = Sampler()\n\nZdefiniujmy dodatkową funkcję pozwalającą przeglądać postęp uczenia modelu.\n\nfrom matplotlib import pyplot as plt\nfrom IPython.display import clear_output\n\nobjective_func_vals = []\nplt.rcParams[\"figure.figsize\"] = (12, 6)\n\n\ndef callback_graph(weights, obj_func_eval):\n    clear_output(wait=True)\n    objective_func_vals.append(obj_func_eval)\n    plt.title(\"Objective function value against iteration\")\n    plt.xlabel(\"Iteration\")\n    plt.ylabel(\"Objective function value\")\n    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n    plt.show()"
  },
  {
    "objectID": "checks/ml.html#variational-quantum-classifier",
    "href": "checks/ml.html#variational-quantum-classifier",
    "title": "Kwantowy model klasyfikatora wariacyjnego",
    "section": "Variational Quantum Classifier",
    "text": "Variational Quantum Classifier\n\nimport time\nfrom qiskit_machine_learning.algorithms.classifiers import VQC\n\nvqc = VQC(\n    sampler=sampler,\n    feature_map=feature_map,\n    ansatz=ansatz,\n    optimizer=optimizer,\n    callback=callback_graph,\n)\n\n# clear objective value history\nobjective_func_vals = []\n\nstart = time.time()\nvqc.fit(train_features, train_labels)\nelapsed = time.time() - start\n\nprint(f\"Training time: {round(elapsed)} seconds\")\n\n\n\n\n\n\n\n\nTraining time: 37 seconds\n\n\n\ntrain_score_q4 = vqc.score(train_features, train_labels)\ntest_score_q4 = vqc.score(test_features, test_labels)\n\nprint(f\"Quantum VQC on the training dataset: {train_score_q4:.2f}\")\nprint(f\"Quantum VQC on the test dataset:     {test_score_q4:.2f}\")\n\nQuantum VQC on the training dataset: 0.85\nQuantum VQC on the test dataset:     0.87"
  },
  {
    "objectID": "checks/cw6.html",
    "href": "checks/cw6.html",
    "title": "Kodowanie danych",
    "section": "",
    "text": "Tak jak pokazywaliśmy w części wykładowej, będziemy zainsteresowanie przetwarzaniem klasycznych danych za pomocą kwantowych układów.\nRozwazmy klasyczny zbiór danych \\(X\\) realizujący \\(N\\) zmiennych i składający się z \\(M\\) wierszy. \\[\nX = \\{ x^1, \\dots, x^m,\\dots x^M \\}\n\\]\nChcemy przetworzyć otrzymane dane tak, by mozna je wykorzystać do obliczeń kwantowych. Procedury, które pokazemy mozna traktować jako penwego rodzaju embedding."
  },
  {
    "objectID": "checks/cw6.html#basis-encoding",
    "href": "checks/cw6.html#basis-encoding",
    "title": "Kodowanie danych",
    "section": "Basis encoding",
    "text": "Basis encoding"
  },
  {
    "objectID": "checks/cw1_old_qiskit.html",
    "href": "checks/cw1_old_qiskit.html",
    "title": "Biblioteka Qiskit wprowadzenie",
    "section": "",
    "text": "import numpy as np\n\ndef measure_state(state, num_meas):\n    # assert state[0]* np.conj(state[0]) + state[1]* np.conj(state[1]) == 1\n\n    # COMPUTE THE MEASUREMENT OUTCOME PROBABILITIES\n    p_0 = state[0] * np.conj(state[0])\n    p_1 = state[1] * np.conj(state[1])\n    # RETURN A LIST OF SAMPLE MEASUREMENT OUTCOMES\n    return np.random.choice(2,num_meas, p=[p_0,p_1])\nmeasure_state(np.array([0.8, 0.6]),5)\n\nU = np.array([[1, 1], [1, -1]]) / np.sqrt(2)\nU@np.array([0.8, 0.6])\n\narray([0.98994949, 0.14142136])\nThe other important libs.\nfrom qiskit import  __qiskit_version__\nprint(__qiskit_version__)\n\nimport qiskit.tools.jupyter\n\n%qiskit_version_table\nimport numpy as np\nnp.set_printoptions(precision=3, suppress=True)"
  },
  {
    "objectID": "checks/cw1_old_qiskit.html#qiskit-podstawy",
    "href": "checks/cw1_old_qiskit.html#qiskit-podstawy",
    "title": "Biblioteka Qiskit wprowadzenie",
    "section": "Qiskit podstawy",
    "text": "Qiskit podstawy\nTworzenie rejestrów:\n\nkwantowego QuantumRegister - do inicjalizowania kubitów. Kubity domyślnie inicjalizowane są w stanie \\(|0\\rangle\\)\nklasycznego ClassicalRegister do przechowywania wyników pomiarów kubitów. Po pomiarze otrzymywany wynik zawsze jest binarny \\(\\{0,1\\}\\).\n\n\nfrom qiskit import QuantumRegister, ClassicalRegister, QuantumCircuit\n\nOba rejestry wykorzystywane będą do generowania obwodów kwantowych QuantumCircuit.\nWszystkie podstawowe obiekty dostępne są bezpośrednio w bibliotece qiskit.\n\nqreq = QuantumRegister(4) # rejest kwantowy z 4 qubitami\n\n\ncreg = ClassicalRegister(4) # rejestr klasyczny z 4 bitami\n\n\ncircuit = QuantumCircuit(qreq, creg) # obwód kwantowy z 4 qubitami i 4 bitami\n\n\ncircuit.draw('mpl') # funkcja rysująca obwód\n\n\noutput = QuantumRegister(1) # inny rejestr kwantowy z 1 qubitem\n\n\ncircuit2 = QuantumCircuit(qreq, output, creg)\n\n\ncircuit2.draw(\"mpl\")\n\n\ncircuit3 = QuantumCircuit(qreq)\n\n\ncircuit3.draw('mpl')\n\n\ncircuit4 = QuantumCircuit(3,3)\ncircuit4.draw(\"mpl\")\n\n\nfrom qiskit_aer.primitives import Sampler\n\nfrom qiskit import QuantumCircuit\nfrom qiskit.visualization import plot_histogram\n\nbell = QuantumCircuit(2)\nbell.h(0)\nbell.measure_all()\n \n# execute the quantum circuit\nquasi_dists = Sampler().run(bell, shots=1000).result().quasi_dists[0]\nprint(quasi_dists)\n\n\nplot_histogram(quasi_dists)"
  },
  {
    "objectID": "checks/cw1_old_qiskit.html#podstawowe-backendy",
    "href": "checks/cw1_old_qiskit.html#podstawowe-backendy",
    "title": "Biblioteka Qiskit wprowadzenie",
    "section": "Podstawowe backendy",
    "text": "Podstawowe backendy\nWykonanie obwodu moze być realizowane zarówno na prawidziwym komputerze kwantowym jak i na lokalnym, klasycznym symulatorze. Większość naszych zadań przeprowadzanych będzie z wykorzystaniem symulatora Aer.\n\nfrom qiskit import Aer \n\nAer.backends()\n\nPodstawowym symulatorem na którym mozemy w pełni uruchomić kod obwodu jest qasm_simulator. Uruchamia on cały obwód i zapisuje wyniki do rejestru klasycznego. Po wielokrotnym uruchomieniu obwodu mozemy sprawdzić równiez statystyki otrzymanych wyników.\n\nPomiar w obwodzie i wielokrotne uruchamianie układu\n\nfrom qiskit import QuantumRegister, ClassicalRegister, QuantumCircuit\n\nqreg = QuantumRegister(2)\ncreg = ClassicalRegister(2)\n# utworzenie obwodu kwantowego z 2 qubitami i 2 bitami\ncircuit = QuantumCircuit(qreg, creg)\ncircuit.h(qreg[0]) # działamy jakąś bramką na pierwszym qubicie\ncircuit.measure(qreg, creg) # dokunujemy pomiaru\n\n# zdefiniowanie symulatora\nsimulator = Aer.get_backend('qasm_simulator')\n# definicja zadania do wykonania\njob = execute(circuit, simulator, shots=1000)\n\nprint(job.job_id())\n# wyciągnięcie wyników i statystyk\ncounts = job.result().get_counts(circuit)\nprint(counts)\n\nWizualizacja otrzymanych wyników realizowana metodą plot_histogram.\n\nfrom qiskit.visualization import plot_histogram\ndisplay(plot_histogram(counts))"
  },
  {
    "objectID": "checks/cw1_old_qiskit.html#tworzenie-stanu-jednokubitowego",
    "href": "checks/cw1_old_qiskit.html#tworzenie-stanu-jednokubitowego",
    "title": "Biblioteka Qiskit wprowadzenie",
    "section": "Tworzenie stanu jednokubitowego",
    "text": "Tworzenie stanu jednokubitowego\n\\[\n\\ket{\\psi}=\\ket{0}\n\\]\nDo inspekcji stanu układu (bez jego pomiaru) mozemy uzyć backend statevector_simulator.\n\nqr = QuantumRegister(1)\nqc = QuantumCircuit(qr)\n\n# klasyczny symulator pozwala zobaczyc stan\nbackend = Aer.get_backend('statevector_simulator')\njob = execute(qc, backend)\nresult = job.result()\nstate = result.get_statevector() # wynik w postaci wektora stanu\nprint(state)\n\n\nstate.draw('latex') # metoda wypisująca wektor stanu w latexu\n\n\nfrom qiskit.visualization import plot_bloch_multivector\nplot_bloch_multivector(result.get_statevector())\n\n\nqr = QuantumRegister(1)\nqc = QuantumCircuit(qr)\nqc.h(qr[0])\nbackend = Aer.get_backend('statevector_simulator')\njob = execute(qc, backend)\nresult = job.result()\nstate = result.get_statevector()\nstate.draw('latex')\n\n\nfrom qiskit.visualization import plot_bloch_multivector\nplot_bloch_multivector(result.get_statevector())\n\n\ninicjalizacja stanu\n\nfrom qiskit import QuantumCircuit\nqc = QuantumCircuit(1)\ninitial_state = [0,1]\nqc.initialize(initial_state, 0)\nqc.draw('mpl')\n\n\nfrom qiskit import Aer, execute\nbackend = Aer.get_backend('statevector_simulator')\nresult = execute(qc, backend).result()\nstate = result.get_statevector()\nstate.draw('latex')\n\n\ninitial_state = [1,1]\nqc = QuantumCircuit(1)\nqc.initialize(initial_state, 0)\nresult = execute(qc, backend).result().get_statevector()\nresult.draw('latex')\n\n\nfrom math import sqrt\ninitial_state = [1/sqrt(2),1/sqrt(2)]\nqc = QuantumCircuit(1)\nqc.initialize(initial_state, 0)\nresult = execute(qc, backend).result().get_statevector()\nresult.draw('latex')\n\n\nfrom math import sqrt\ninitial_state = [1/2,sqrt(3)/2]\nqc = QuantumCircuit(1)\nqc.initialize(initial_state, 0)\nresult = execute(qc, backend).result().get_statevector()\nresult.draw('latex')\n\n\nfrom math import pi, cos, sin \ndef get_state(theta):\n    return [cos(theta/2), sin(theta/2)]\n\ntheta = -pi/2\n\nqc = QuantumCircuit(1)\nqc.initialize(get_state(theta), 0)\nbackend = Aer.get_backend('statevector_simulator')\nresult = execute(qc, backend).result().get_statevector()\nresult.draw('latex')\n\n\nfrom qiskit.visualization import plot_histogram\nresult = execute(qc, backend).result().get_counts()\nplot_histogram(result)"
  },
  {
    "objectID": "checks/cw1_old_qiskit.html#tworzenie-stanu-dwukubitowego",
    "href": "checks/cw1_old_qiskit.html#tworzenie-stanu-dwukubitowego",
    "title": "Biblioteka Qiskit wprowadzenie",
    "section": "Tworzenie stanu dwukubitowego",
    "text": "Tworzenie stanu dwukubitowego\n\\[\n\\ket{00}, \\ket{01}, \\ket{10}, \\ket{11}\n\\]\n\nqr = QuantumRegister(2)\nqc = QuantumCircuit(qr)\nbackend = Aer.get_backend('statevector_simulator')\njob = execute(qc, backend)\nresult = job.result()\nstate = result.get_statevector()\nstate.draw('latex')\n\n\nqr = QuantumRegister(2)\nqc = QuantumCircuit(qr)\nqc.h(qr[0])\nqc.h(qr[1])\nbackend = Aer.get_backend('statevector_simulator')\njob = execute(qc, backend)\nresult = job.result()\nstate = result.get_statevector()\nstate.draw('latex')\n\n\nfrom qiskit.visualization import plot_bloch_multivector\nplot_bloch_multivector(result.get_statevector())\n\n\nqr = QuantumRegister(2)\nqc = QuantumCircuit(qr)\nqc.h(qr[0])\nqc.cx(0,1)\n\nbackend = Aer.get_backend('statevector_simulator')\njob = execute(qc, backend)\nresult = job.result()\nstate = result.get_statevector()\n\n\nqc.draw('mpl')\n\n\nstate.draw('latex')\n\n\nfrom qiskit.visualization import plot_bloch_multivector\nplot_bloch_multivector(result.get_statevector())"
  },
  {
    "objectID": "checks/cw1_old_qiskit.html#tworzenie-stanu-trzy-kubitowego",
    "href": "checks/cw1_old_qiskit.html#tworzenie-stanu-trzy-kubitowego",
    "title": "Biblioteka Qiskit wprowadzenie",
    "section": "Tworzenie stanu trzy-kubitowego",
    "text": "Tworzenie stanu trzy-kubitowego\n\\[\n\\ket{000}, \\ket{001}, \\ket{010}, \\ket{011}, \\ket{100}, \\ket{101}, \\ket{110}, \\ket{111}\\]\n\nqr = QuantumRegister(3)\nqc = QuantumCircuit(qr)\n# qc.x(qr[0]) \n# qc.x(qr[1])\n\n# klasyczny symulator pozwala zobaczyc stan\nbackend = Aer.get_backend('statevector_simulator')\njob=execute(qc, backend)\nresult = job.result()\nstate = result.get_statevector()\n\nUruchom powyższy kod usuwajac poszczegolne komentarze i sprawdz wynik.\n\n# uruchom w środowisku IBM Quantum Experience\nfrom qiskit_ibm_provider import IBMProvider\n\nIBMProvider.save_account(token=MY_API_TOKEN)\nprovider = IBMProvider()\n\n# Create a circuit\nqc = QuantumCircuit(2)\nqc.h(0)\nqc.cx(0, 1)\nqc.measure_all()\n\n# Select a backend.\nbackend = provider.get_backend(\"ibmq_qasm_simulator\")\n\n# Transpile the circuit\ntranspiled = transpile(qc, backend=backend)\n\n# Submit a job.\njob = backend.run(transpiled)\n# Get results.\nprint(job.result().get_counts())\n\nWięcej informacji znajdziesz tutaj\n\nfrom qiskit.tools.visualization import circuit_drawer\n\nq = QuantumRegister(1)\nc = ClassicalRegister(1)\ncircuit = QuantumCircuit(q, c)\ncircuit.measure(q, c)\ncircuit_drawer(circuit)"
  },
  {
    "objectID": "checks/titanic.html",
    "href": "checks/titanic.html",
    "title": "Titanic data",
    "section": "",
    "text": "Dane mozna pobrać po utworzeniu (darmowego) konta na portalu Kaggle.\nPobierz dane: interesują nas tylko pliki zbiorów train.csv i test.csv.\nZobaczmy jak wyglądają nasze dane:\nimport pandas as pd\n\ntrain = pd.read_csv('../data/train.csv')\ntest = pd.read_csv('../data/test.csv')\n\nprint(\"train ma {} wierszy i {} kolumn\".format(*train.shape))\nprint(\"test ma {} wierszy i {} kolumn\".format(*test.shape))\n\nprint(f\"train to obiekt typu {type(train)}\")\n\ntrain ma 891 wierszy i 12 kolumn\ntest ma 418 wierszy i 11 kolumn\ntrain to obiekt typu &lt;class 'pandas.core.frame.DataFrame'&gt;\ntrain.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\nMetoda info() zwraca informacje o: - nazyach kolumn, - ich indeksy, - liczbę niepustych (null) elementów dla kazdej kolumny,\n- typy danych.\ntest.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  418 non-null    int64  \n 1   Pclass       418 non-null    int64  \n 2   Name         418 non-null    object \n 3   Sex          418 non-null    object \n 4   Age          332 non-null    float64\n 5   SibSp        418 non-null    int64  \n 6   Parch        418 non-null    int64  \n 7   Ticket       418 non-null    object \n 8   Fare         417 non-null    float64\n 9   Cabin        91 non-null     object \n 10  Embarked     418 non-null    object \ndtypes: float64(2), int64(4), object(5)\nmemory usage: 36.0+ KB\nDla zbioru testowego mamy jedną kolumnę (Survived) mniej, dlaczego?\nZe względu, iz nie planujemy wrzucać wyników modeli na kaggle zbiór test nie jest nam potrzebny.\nInformacje z metody info() przedstawiają tylko ogólne rzeczy, zobaczmy jak zbiór train wygląda w środku.\ntrain.head()\n\n\n\n\n\n\n\n\nPassengerId\nSurvived\nPclass\nName\nSex\nAge\nSibSp\nParch\nTicket\nFare\nCabin\nEmbarked\n\n\n\n\n0\n1\n0\n3\nBraund, Mr. Owen Harris\nmale\n22.0\n1\n0\nA/5 21171\n7.2500\nNaN\nS\n\n\n1\n2\n1\n1\nCumings, Mrs. John Bradley (Florence Briggs Th...\nfemale\n38.0\n1\n0\nPC 17599\n71.2833\nC85\nC\n\n\n2\n3\n1\n3\nHeikkinen, Miss. Laina\nfemale\n26.0\n0\n0\nSTON/O2. 3101282\n7.9250\nNaN\nS\n\n\n3\n4\n1\n1\nFutrelle, Mrs. Jacques Heath (Lily May Peel)\nfemale\n35.0\n1\n0\n113803\n53.1000\nC123\nS\n\n\n4\n5\n0\n3\nAllen, Mr. William Henry\nmale\n35.0\n0\n0\n373450\n8.0500\nNaN\nS\nKazda kolumna reprezentuje jedną zmienną naszych danych. Identyfikatorem, bądź kluczem naszej tabeli jest PassengerId, która przyjmuje rózną wartość dla kazdego wiersza. Czy taka zmienna moze być dobra do modelowania? Zmienna Survived realizuje zmienną celu naszego zadania - pasazer przezyl (1) lub nie (0). Pclass to zmienna opisująca klasę pokładu zgodnie z biletem."
  },
  {
    "objectID": "checks/titanic.html#klasyfikatory",
    "href": "checks/titanic.html#klasyfikatory",
    "title": "Titanic data",
    "section": "Klasyfikatory",
    "text": "Klasyfikatory\n\nimport random\nrandom.seed(42)\n\n# losowa funkcja klasyfikująca\ndef classify(passanger):\n    return random.randint(0,1)\n\n# pomocnicza funkcja\ndef run(f_classufy, x):\n    return list(map(f_classufy, x))\n\ndef evaluate(predictions, actual):\n    correct = list(filter(\n        lambda item: item[0] == item[1],\n        list(zip(predictions, actual))\n    ))\n    return f\"{len(correct)} poprawnych przewidywan z {len(actual)}. Accuracy ({len(correct)/len(actual)*100:.0f}%)\"\n\n\nevaluate(run(classify, tr_input.values), tr_labels.values)\n\n'348 poprawnych przewidywan z 711. Accuracy (49%)'\n\n\n\ndef kill_bill(item):\n    return 0\n\n\nevaluate(run(kill_bill, tr_input.values), tr_labels.values)\n\n'440 poprawnych przewidywan z 711. Accuracy (62%)'\n\n\n\nfrom sklearn.metrics import confusion_matrix\n\npredictions = run(kill_bill, tr_input.values)\nconfusion_matrix(tr_labels.values, predictions)\n# TN, FP, FN, TP\n\narray([[440,   0],\n       [271,   0]])\n\n\n\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\nprint(precision_score(tr_labels.values, predictions))\nprint(recall_score(tr_labels.values, predictions))\nprint(f1_score(tr_labels.values, predictions))\n\n# specificity = \\sum TrueNegatives / \\sum ALLActualNegatives\n# npv = \\sum TrueNegatives / \\sum AllPredictedNegatives\n\ndef specificity(matrix):\n    return matrix[0,0]/(matrix[0][0]+matrix[0][1]) if (matrix[0][0]+matrix[0][1] &gt; 0) else 0\n\ndef npv(matrix):\n    return matrix[0,0]/(matrix[0][0]+matrix[1][0]) if (matrix[0][0]+matrix[1][0] &gt; 0) else 0\n\ncm = confusion_matrix(tr_labels.values, predictions)\nprint(\"specificity\",specificity(cm))\nprint(\"npv\",npv(cm))\n\n0.0\n0.0\n0.0\nspecificity 1.0\nnpv 0.6188466947960619\n\n\n/Users/air/Desktop/quarto_projects/intro_to_qml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\n\nZrob obliczenia dla losowego klasyfikatora!\n\n\ndef raport(name, run, classify, input, labels):\n    cr_predictions = run(classify, input.values)\n    cr_cm = confusion_matrix(labels.values, cr_predictions)\n    cr_prcision  = precision_score(labels.values, cr_predictions)\n    cr_recall = recall_score(labels.values, cr_predictions)\n    cr_scpecificity = specificity(cr_cm)\n    cr_npv = npv(cr_cm)\n    cr_level = 0.25*(cr_prcision + cr_recall + cr_scpecificity + cr_npv)\n    print(f\"{name} precision {cr_prcision:.2f} recall {cr_recall:.2f} specificity {cr_scpecificity:.2f} npv {cr_npv:.2f} level {cr_level:.2f}\")\n    \n\n\nraport(\"losowy\", run, classify, tr_input, tr_labels)\nraport(\"kill bill\", run, kill_bill, tr_input, tr_labels)\n\nlosowy precision 0.38 recall 0.53 specificity 0.47 npv 0.62 level 0.50\nkill bill precision 0.00 recall 0.00 specificity 1.00 npv 0.62 level 0.40\n\n\n/Users/air/Desktop/quarto_projects/intro_to_qml/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\n\nimport qiskit\nqiskit.__qiskit_version__\n\n{'qiskit-terra': '0.25.1', 'qiskit': '0.44.1', 'qiskit-aer': '0.12.2', 'qiskit-ignis': '0.7.1', 'qiskit-ibmq-provider': '0.20.2', 'qiskit-nature': None, 'qiskit-finance': '0.3.4', 'qiskit-optimization': '0.5.0', 'qiskit-machine-learning': '0.6.1'}\n\n\n\nfrom qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, execute, Aer\nfrom math import sqrt\n\nqc = QuantumCircuit(1)\ninitial_state = [1/sqrt(2), 1/sqrt(2)]\nqc.initialize(initial_state, 0)\nqc.measure_all()\n\nPowyzszy obwód realizuje stan superpozycji i zwraca w losowy sposób wynik \\(0\\) lub \\(1\\). Oznacza to, ze moze byc kandydatem na klasyfikator binarny.\nZdefiniujmy powyzszy obwód tak aby realizowany był jako funkcja, którą mozemy wykorzystać w naszym problemie klasyfikacji.\n\nfrom qiskit import execute, Aer, QuantumCircuit\nfrom math import sqrt \nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score \n\ndef pqc_classify(backend, passenger_state):\n    qc = QuantumCircuit(1)\n    qc.initialize(passenger_state, 0)\n    qc.measure_all()\n    result = execute(qc, backend, shots=1).result()\n    counts = result.get_counts()\n    return int(list(map(lambda item: item[0], counts.items()))[0])\n\nbackend = Aer.get_backend('qasm_simulator')\ninitial_state = [1/sqrt(2), 1/sqrt(2)]\n\n\nraport(\"Random PQC\", run, lambda x: pqc_classify(backend, initial_state), \n       tr_input, tr_labels)\n\nRandom PQC precision 0.36 recall 0.47 specificity 0.47 npv 0.59 level 0.47\n\n\nPowyzsze kody realizują klasyfikatory, które nie zalezą od naszych danych pasazerów.\n\nPreprocessing - przetworznie danych wejściowych do postaci przetwarzanej przez nasz obwód kwantowy. Wykorzystamy PQC. Ta część jest związana z klasycznym przetworzeniem danych i utworzeniem embeddingu.\nPQC\nPostprocessing - Nasz klasyfikator powinien zwracać wartość 0 lub 1. Tutaj powinien odbywać się proces przetłumaczenia wyniku realizowanego przez jakiś obwód kwanotwy na binarny wynik klasyfikacji. Tutaj równiez uzyjemy PQC do klasycznego przetworzenia.\n\nTylko druga część będzie w pełni realizowała obwód kwantowy. Łącząc wszystko razem otrzymujemy Wariacyjny hybrydowy klasyczno-kwantowy algorytm. Jest to jedno z najczęściej uzywanych podejść do modelowania danych klasycznych.\n\n# 1 preprocessing\ndef pre_process(passanger):\n    quantum_state = [1/sqrt(2), 1/sqrt(2)]\n    return quantum_state\n\n# 2. pqc\n\ndef pqc(beckend, quantum_state):\n    qc = QuantumCircuit(1)\n    qc.initialize(quantum_state, 0)\n    qc.measure_all()\n    result = execute(qc, backend, shots=1).result()\n    counts = result.get_counts(qc)\n    return counts\n\n# 3. postprocessing\ndef post_process(counts):\n    return int(list(map(lambda item: item[0], counts.items()))[0])\n\nbackend = Aer.get_backend('qasm_simulator')\n\nraport(\"Variational Classifier\", run, lambda passenger: post_process(pqc(backend, pre_process(passenger))), \n       tr_input, tr_labels)\n\nVariational Classifier precision 0.41 recall 0.56 specificity 0.51 npv 0.65 level 0.54\n\n\nDane kazdego pasazera składają się z 7 zmiennych. Ze względu, iz nie chcemy (na razie) zmieniać ostatniego kroku musimy znaleźć jakąś metodę pozwalającą przypisać 7 zmiennym prawdopodobieństwo przezycia i śmierci. W ostatnim kroku odczytujemy po pomiarze tylko te dwie wielkości.\nZnalezienie prawdopodobieństwa dla 7 zmiennych nie jest prostym zadaniem (w końcu to robią nasze klasyczne modele ML). Jendak mozemy zacząć od bardzo statystycznego podejścia. Zakładamy, ze zmienne są od siebie niezalezne i kazda zmienna z jakąś wagą przyczynia się do wartości prawdopodobieństwa przezycia. \\[\nP(survival) = \\sum (F \\mu_F)\n\\]\n\ndef waga_zmiennej(feature, weight):\n    return feature*weight\n\nfrom functools import reduce\n\ndef get_overall_probablity(features, weights):\n    return reduce(lambda result, data: result + waga_zmiennej(*data), \n                  zip(features, weights),\n                  0\n                  )\n\nJak zbudować wektor wag?\nZacznijmy od współczynnika korelacji.\n\nfrom scipy.stats import spearmanr\n\ncolumns = [list(map(lambda passneger: passneger[i], tr_input.values)) for i in range(0,7)]\n\n\ncorrelations = list(map(lambda col: spearmanr(col, tr_labels.values)[0], columns))\n\n\ncorrelations\n\n[-0.33362848376406934,\n -0.5327583106581802,\n -0.03158046336028065,\n 0.0688875885695018,\n 0.12641683959850614,\n 0.3105976636091728,\n -0.16652847475942076]\n\n\nZastosujmy to do pre-processingu\n\nfrom math import pi, sin, cos \n\ndef get_state(theta):\n    return [cos(theta/2), sin(theta/2)]\n\ndef pre_process_weighted(passenger):\n    mu = get_overall_probablity(passenger, correlations)\n    # theta między 0 i pi  0 = |0&gt; a pi = |1&gt;\n    quantum_state = get_state((1-mu)*pi)\n    return quantum_state\n\n\nbackend = Aer.get_backend('statevector_simulator')\n\nraport(\"Variational Classifier - train\", run, lambda passenger: post_process(pqc(backend, pre_process_weighted(passenger))), \n       tr_input, tr_labels)\nraport(\"Variational Classifier- test\", run, lambda passenger: post_process(pqc(backend, pre_process_weighted(passenger))), \n       test_input, test_labels)\n\nVariational Classifier - train precision 0.28 recall 0.35 specificity 0.45 npv 0.53 level 0.40\nVariational Classifier- test precision 0.33 recall 0.39 specificity 0.50 npv 0.56 level 0.44"
  },
  {
    "objectID": "checks/qaoa_penny.html",
    "href": "checks/qaoa_penny.html",
    "title": "Wstęp do kwantowego uczenia maszynowego",
    "section": "",
    "text": "import pennylane as qml\nfrom pennylane import numpy as np \nimport networkx as nx \nimport matplotlib.pyplot as plt\n\n\nedges = [(0, 1), (1, 2),(2,3),(3,0)]\nG = nx.Graph(edges)\nn_edges = len(G.edges)\nn_wires = len(G.nodes)\nprint(f\"potrzebujesz {n_wires} kubitów\")\n\nnx.draw(G, with_labels=True)\nplt.show()\n\npotrzebujesz 4 kubitów\n\n\n\n\n\n\n\n\n\n\ndef maxcut_hamiltonian(graph):\n    coeffs = []\n    obs = []\n    for (i, j) in graph.edges:\n        coeffs.append(0.5)\n        obs.append(qml.PauliZ(i) @ qml.PauliZ(j))\n    return qml.Hamiltonian(coeffs, obs)\n\n\nH = maxcut_hamiltonian(G)\n\n\nH.wires\n\n&lt;Wires = [0, 1, 3, 2]&gt;\n\n\n\ndev = qml.device('default.qubit', wires = H.wires)\n\nwires = H.wires\n\ndef circuit(params):\n\n    n_params = int(len(params)/2)\n    \n    gammas = params[:n_params]\n    \n    betas = params[n_params:]\n    # stan początkowy \n    for i in range(n_wires):\n        qml.Hadamard(wires=i)\n    \n    for gamma, beta in zip(gammas, betas):\n        # cost_h\n        for (i,j) in G.edges:\n            qml.CNOT(wires=[i,j])\n            qml.RZ(-gamma, wires=j)\n            qml.CNOT(wires=[i,j])\n        # mixer\n        for i in range(n_wires):\n            qml.RX(2 * beta, wires=i)\n    \n    return qml.expval(H)\n\n\ndef cost(params):\n    return circuit(params)\n\nn_layers = 2\n\nparams = np.random.uniform(0, np.pi, size = 2 * n_layers, requires_grad=True)\n\n\ncircuit(params)\n\nexpval(0.5 * (Z(0) @ Z(1)) + 0.5 * (Z(0) @ Z(3)) + 0.5 * (Z(1) @ Z(2)) + 0.5 * (Z(2) @ Z(3)))\n\n\n\noptimizer = qml.GradientDescentOptimizer()\nepochs = 50\n\n\nfor epoch in range(epochs):\n        params = optimizer.step(cost, params)\n\nprint(\"Optimal Parameters\")\nprint(params)\n\n/Users/seba/Documents/GitHub/qml2024/venv/lib/python3.11/site-packages/autograd/tracer.py:14: UserWarning: Output seems independent of input.\n  warnings.warn(\"Output seems independent of input.\")\n\n\n\n---------------------------------------------------------------------------\nKeyError                                  Traceback (most recent call last)\nFile ~/Documents/GitHub/qml2024/venv/lib/python3.11/site-packages/autograd/core.py:233, in vspace(value)\n    232 try:\n--&gt; 233     return VSpace.mappings[type(value)](value)\n    234 except KeyError:\n\nKeyError: &lt;class 'pennylane.measurements.expval.ExpectationMP'&gt;\n\nDuring handling of the above exception, another exception occurred:\n\nTypeError                                 Traceback (most recent call last)\nCell In[9], line 2\n      1 for epoch in range(epochs):\n----&gt; 2         params = optimizer.step(cost, params)\n      4 print(\"Optimal Parameters\")\n      5 print(params)\n\nFile ~/Documents/GitHub/qml2024/venv/lib/python3.11/site-packages/pennylane/optimize/gradient_descent.py:93, in GradientDescentOptimizer.step(self, objective_fn, grad_fn, *args, **kwargs)\n     75 def step(self, objective_fn, *args, grad_fn=None, **kwargs):\n     76     \"\"\"Update trainable arguments with one step of the optimizer.\n     77 \n     78     Args:\n   (...)\n     90         If single arg is provided, list [array] is replaced by array.\n     91     \"\"\"\n---&gt; 93     g, _ = self.compute_grad(objective_fn, args, kwargs, grad_fn=grad_fn)\n     94     new_args = self.apply_grad(g, args)\n     96     # unwrap from list if one argument, cleaner return\n\nFile ~/Documents/GitHub/qml2024/venv/lib/python3.11/site-packages/pennylane/optimize/gradient_descent.py:122, in GradientDescentOptimizer.compute_grad(objective_fn, args, kwargs, grad_fn)\n    104 r\"\"\"Compute gradient of the objective function at the given point and return it along with\n    105 the objective function forward pass (if available).\n    106 \n   (...)\n    119     will not be evaluted and instead ``None`` will be returned.\n    120 \"\"\"\n    121 g = get_gradient(objective_fn) if grad_fn is None else grad_fn\n--&gt; 122 grad = g(*args, **kwargs)\n    123 forward = getattr(g, \"forward\", None)\n    125 num_trainable_args = sum(getattr(arg, \"requires_grad\", False) for arg in args)\n\nFile ~/Documents/GitHub/qml2024/venv/lib/python3.11/site-packages/pennylane/_grad.py:165, in grad.__call__(self, *args, **kwargs)\n    162     self._forward = self._fun(*args, **kwargs)\n    163     return ()\n--&gt; 165 grad_value, ans = grad_fn(*args, **kwargs)  # pylint: disable=not-callable\n    166 self._forward = ans\n    168 return grad_value\n\nFile ~/Documents/GitHub/qml2024/venv/lib/python3.11/site-packages/autograd/wrap_util.py:20, in unary_to_nary.&lt;locals&gt;.nary_operator.&lt;locals&gt;.nary_f(*args, **kwargs)\n     18 else:\n     19     x = tuple(args[i] for i in argnum)\n---&gt; 20 return unary_operator(unary_f, x, *nary_op_args, **nary_op_kwargs)\n\nFile ~/Documents/GitHub/qml2024/venv/lib/python3.11/site-packages/pennylane/_grad.py:185, in grad._grad_with_forward(fun, x)\n    180 \"\"\"This function is a replica of ``autograd.grad``, with the only\n    181 difference being that it returns both the gradient *and* the forward pass\n    182 value.\"\"\"\n    183 vjp, ans = _make_vjp(fun, x)  # pylint: disable=redefined-outer-name\n--&gt; 185 if vspace(ans).size != 1:\n    186     raise TypeError(\n    187         \"Grad only applies to real scalar-output functions. \"\n    188         \"Try jacobian, elementwise_grad or holomorphic_grad.\"\n    189     )\n    191 grad_value = vjp(vspace(ans).ones())\n\nFile ~/Documents/GitHub/qml2024/venv/lib/python3.11/site-packages/autograd/core.py:238, in vspace(value)\n    236     return vspace(getval(value))\n    237 else:\n--&gt; 238     raise TypeError(\"Can't find vector space for value {} of type {}. \"\n    239                     \"Valid types are {}\".format(\n    240                         value, type(value), VSpace.mappings.keys()))\n\nTypeError: Can't find vector space for value expval(0.5 * (Z(0) @ Z(1)) + 0.5 * (Z(0) @ Z(3)) + 0.5 * (Z(1) @ Z(2)) + 0.5 * (Z(2) @ Z(3))) of type &lt;class 'pennylane.measurements.expval.ExpectationMP'&gt;. Valid types are dict_keys([&lt;class 'autograd.core.SparseObject'&gt;, &lt;class 'list'&gt;, &lt;class 'tuple'&gt;, &lt;class 'dict'&gt;, &lt;class 'numpy.ndarray'&gt;, &lt;class 'float'&gt;, &lt;class 'numpy.longdouble'&gt;, &lt;class 'numpy.float64'&gt;, &lt;class 'numpy.float32'&gt;, &lt;class 'numpy.float16'&gt;, &lt;class 'complex'&gt;, &lt;class 'numpy.clongdouble'&gt;, &lt;class 'numpy.complex64'&gt;, &lt;class 'numpy.complex128'&gt;, &lt;class 'numpy.linalg.linalg.EigResult'&gt;, &lt;class 'numpy.linalg.linalg.EighResult'&gt;, &lt;class 'numpy.linalg.linalg.QRResult'&gt;, &lt;class 'numpy.linalg.linalg.SlogdetResult'&gt;, &lt;class 'numpy.linalg.linalg.SVDResult'&gt;, &lt;class 'pennylane.numpy.tensor.tensor'&gt;])"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Informacje ogólne",
    "section": "",
    "text": "Witajcie wszyscy! Dziś chiałbym poruszyć temat nowego kursu z zakresu kwantowego uczenia maszynowego. Kurs ten będzie skupiał się na wykorzystaniu biblioteki pennylane, która jest jedną z najpopularniejszych bibliotek do tworzenia modeli kwantowych. W ramach kursu będziemy uczyć się podstaw kwantowego uczenia maszynowego, a także zastosowania tej wiedzy w praktyce. W trakcie kursu będziemy mieli okazję zapoznać się z różnymi narzędziami i technikami, które pozwolą nam na tworzenie modeli kwantowych opartych o sieci neuronowe. W trakcie kursu będziemy również mieli okazję zapoznać się z różnymi algorytmami kwantowymi. Bardziej szczegółowo przetwarzać będziemy parametryzowane obwody kwantowe, które będą podstawowym elementem naszych modeli kwantowego uczenia maszynowego. Wszystko to pozwoli nam na lepsze zrozumienie zasad rządzących światem kwantowym i na wykorzystanie tej wiedzy w praktyce.",
    "crumbs": [
      "Sylabus",
      "Informacje ogólne"
    ]
  },
  {
    "objectID": "index.html#section",
    "href": "index.html#section",
    "title": "Informacje ogólne",
    "section": "Wstęp do kwantowego uczenia maszynowego",
    "text": "Wstęp do kwantowego uczenia maszynowego\nKod: 232530-D\nSemestr zimowy 2024/2025,\nSGH Szkoła Główna Handlowa w Warszawie\nPodstawowe informacje znajdziesz w sylabusie.\nCiekawe książki i strony internetowe zamieszczone zostały w zakładce książki. Jeśli chciał(a)byś coś dodać prześlij informację przez MS teams.",
    "crumbs": [
      "Sylabus",
      "Informacje ogólne"
    ]
  },
  {
    "objectID": "index.html#kalendarz",
    "href": "index.html#kalendarz",
    "title": "Informacje ogólne",
    "section": "Kalendarz",
    "text": "Kalendarz\n\nWykład\nWykład jest realizowany w trybie hybrydowym. Jest on NIEOBOWIĄZKOWY i odbywa się w sali C4D.\n\n30-09-2024 (poniedziałek) 11:40-13:20 - Wykład 1\n07-10-2024 (poniedziałek) 11:40-13:20 - Wykład 2\n14-10-2024 (poniedziałek) 11:40-13:20 - Wykład 3\n21-10-2023 (poniedziałek) 11:40-13:20 - Wykład 4\n28-10-2023 (poniedziałek) 11:40-13:20 - Wykład 5\n\n\n\nLaboratoria\nWszystkie laboratoria odbywają się w sali C4D.\n\n04-11-2024 (poniedziałek) 11:40-13:20 - Lab1\n13-11-2023 (poniedziałek) 11:40-13:20 - Lab2\n20-11-2023 (poniedziałek) 11:40-13:20 - Lab3\n25-11-2023 (poniedziałek) 11:40-13:20 - Lab4\n02-12-2023 (poniedziałek) 11:40-13:20 - Lab5\n09-12-2023 (poniedziałek) 11:40-13:20 - Lab6\n16-12-2023 (poniedziałek) 11:40-13:20 - Lab7\n13-01-2024 (poniedziałek) 11:40-13:20 - Lab8",
    "crumbs": [
      "Sylabus",
      "Informacje ogólne"
    ]
  },
  {
    "objectID": "index.html#sobota-niedziela",
    "href": "index.html#sobota-niedziela",
    "title": "Informacje ogólne",
    "section": "Sobota-Niedziela",
    "text": "Sobota-Niedziela\n\n12.10.2024 11:40-13:20 - Wykład 1\n26.10.2024 11:40-13:20 - Wykład 2\n09.11.2024 11:40-13:20 - Lab1\n23.11.2024 11:40-13:20 - Lab2\n07.12.2024 11:40-13:20 - Lab3\n21.12.2024 11:40-13:20 - Lab4\n18.01.2025 11:40-13:20 - Lab5",
    "crumbs": [
      "Sylabus",
      "Informacje ogólne"
    ]
  },
  {
    "objectID": "index.html#technologie",
    "href": "index.html#technologie",
    "title": "Informacje ogólne",
    "section": "Technologie",
    "text": "Technologie\nUczestnicząc w zajęciach musisz opanować i przynajmniej w podstawowym zakresie posługiwać się następującymi technologiami informatycznymi:\n\nAlgebra liniowa - wektory, macierze, baza, iloczyn skalarny, iloczyn tensorowy\nPython, Jupyter notebook, Jupyter lab, Colab\nAlgorytmy sieci neuronowych i uczenia maszynowego w procesie klasyfikacji binarnej",
    "crumbs": [
      "Sylabus",
      "Informacje ogólne"
    ]
  },
  {
    "objectID": "index.html#qpoland",
    "href": "index.html#qpoland",
    "title": "Informacje ogólne",
    "section": "QPoland",
    "text": "QPoland\nQPoland jest cześcią międzynarodowej sieci QWorld.",
    "crumbs": [
      "Sylabus",
      "Informacje ogólne"
    ]
  },
  {
    "objectID": "lectures/wyklad2.html",
    "href": "lectures/wyklad2.html",
    "title": "Bramki logiczne",
    "section": "",
    "text": "\\[\n\\newcommand{\\bra}[1]{\\left \\langle #1 \\right \\rvert}\n\\newcommand{\\ket}[1]{\\left \\rvert #1 \\right \\rangle}\n\\newcommand{\\braket}[2]{\\left \\langle #1 \\middle \\rvert #2 \\right \\rangle}\n\\]\nObliczenia (przetwarzanie) wykonywane przez komputer możemy zdefiniować jako transformacje jednego stanu pamięci na inny. Z matematycznego punktu widzenia oznacza to, że obliczenia to funkcje, które przekształcają informacje.\nW przypadku klasycznych komputerów podstawową jednostką pamięci jest bit (ang. binary digit). Funkcje, które operują na bitach nazywamy bramkami logicznymi (ang. logic gates).",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Bramki logiczne"
    ]
  },
  {
    "objectID": "lectures/wyklad2.html#bramki-logiczne",
    "href": "lectures/wyklad2.html#bramki-logiczne",
    "title": "Bramki logiczne",
    "section": "Bramki logiczne",
    "text": "Bramki logiczne\nBramki logiczne to funkcje Boolowskie, które możemy składać w bardziej złożone układy (ang. circuits). Stworzone przez George’a Boole’a w 1854 roku, algebra boola jest matematyczną strukturą, która opisuje zachowanie się obiektów, które mogą przyjmować tylko jedną z dwóch wartości: prawda lub fałsz. Zdolne są one do wykonywania np. dodawania, mnożenia czy też innych bardziej skomplikowanych operacji.\nW latach trzydziestych XX wieku Claude Shannon zastosował algebrę boola do analizy i projektowania układów elektrycznych. Co oznacza, że zareprezentował on funkcje boolowskie za pomocą przełączników elektrycznych. Dlatego też komponenty elektroniczne odpowiadające funkcjom boolowskim nazywamy bramkami logicznymi.\n\nCiekawostka. Richard Feynman wykładał teorię obliczeń na Kalifornijskim Instytucie Technologii. Wykład ten prezentowany jest obecnie jako Feynmana wykłady o obliczeniach (ang. Feynman Lectures on Computation).\n\n\nZ pozoru obliczenia przedstawione w ten sposób wyglądają jako abstrakcjny matematyczny koncept. Jednak jego realizacja zawsze wymaga jakiegoś układu fizycznego realizującego wykonywanie funkcji. Nie ma znaczenia jak ten układ zostanie zrealizowany: kule bilardowe, przełączniki elektroniczne, tranzystory, czy cokolwiek innego.\n\nLogika obliczeń jest niezależna od realizacji bramek logicznych.\n\nZ punktu widzenia realizacji zawsze chodzi nam o kontrolowany sposób zmiany stanu układu.\nNa wykładzie postaramy się wskazać jak i kiedy logika klasycznych obliczeń może być uogólniona przez logikę obliczeń kwantowych. Jasne jest, że przypadek klasyczny powinien być szczególnym przypadkiem kwantowego.\nobwody klasyczne\nZobaczmy jakie bramki możemy określić dla jednego bitu.\n\nBramki logiczne dla jednego bitu\nIle bramek mamy gdy input = 1 bit, output = 1 bit? Ile funkcji możemy zdefiniować dla odwzorowania jednego bitu w jeden bit?\nWszystkie cztery operatory działające na jednym bicie możemy określić jako:\n\nIdentyczność (ang. identity) - \\(I(0)=0\\), \\(I(1)=1\\)\nNegacja (ang. negation, NOT, filps) - \\(NOT(0)=1\\), \\(NOT(1)=0\\)\nStałe zero \\(ZERO(0)=0\\), \\(ZERO(1)=0\\)\nStałe jeden \\(ONE(0)=1\\), \\(ONE(1)=1\\)\n\nPo zastosowaniu operatora \\(I\\) oraz \\(NOT\\), z otrzymanego wyniku możemy wyznaczyc wartości początkowe. Jednak po zastosowaniu dwóch pozostałych operacji \\(ZERO\\) i \\(ONE\\) nie jesteśmy w stanie określic jaki był stan początkowy, który wygenerował określony wynik.\nTe dwie własności pozwalają nam sklasyfikowac operatory jako:\n\nOdwracalne - możemy odtworzyc wartośc początkową z wartości końcowej\nNieodwracalne - NIE możemy odtworzyc wartości początkowej z wartości końcowej.\n\nJak pokażemy później, wszystkie operatory reprezentujące kwantowe bramki będą odwracalne.\n\n\nInne bramki i operacje logiczne\n\nZróbmy krótkie przedstawienie niektórych, klasycznych bramek logicznych.\nBramka logiczna jest implementacją funkcji boolowskiej. Operacją logiczną przeprowadzaną na jednym lub kilku binarnych wejściach produkującą jedną binarną wartość wyjściową. \\[f: \\{0,1\\}^{n} \\to \\{0,1\\} \\]\nKażdy element algebry boola (Boolean Statements) musi być określony jako prawda albo fałsz.\nBramki logiczne możemy wyrazić za pomocą tablicy prawdy (ang. truth table). Tablica ta posiada jedną kolumnę dla każdej zmiennej wejściowej oraz jedną kolumnę dla zmiennej wyjściowej. Kolumna wyjściowa przedstawia wszystkie możliwe wyniki przedstawianej logicznej operacji reprezentowanej przez tablicę. Każdy wiersz tablicy prawdy reprezentuje jedną możliwą kombinację (konfiguracje) danych wejściowych oraz wyniku.\nPodstawowe bramki, które znasz to:\n\nAND - koniunkcja\nOR - alternatywa\nNOT - negacja\nNAND - not and\nXOR - alternatywa wykluczająca (Exclusive OR) - dodawanie modulo 2\n\n\nZadanie: zapisz tablicę prawdy dla każdej bramki.\n\n\nNOT gate\n\n\n\nA\nnot A\n\n\n\n\n0\n\n\n\n1\n\n\n\n\n\n\nAND gate\n\n\n\nA\nB\nC\n\n\n\n\n0\n0\n\n\n\n1\n0\n\n\n\n0\n1\n\n\n\n1\n1\n\n\n\n\n\n\nOR gate\n\n\n\nA\nB\nC\n\n\n\n\n0\n0\n\n\n\n1\n0\n\n\n\n0\n1\n\n\n\n1\n1\n\n\n\n\n\n\nNAND\n\n\n\nA\nB\nC\n\n\n\n\n0\n0\n\n\n\n1\n0\n\n\n\n0\n1\n\n\n\n1\n1\n\n\n\n\n\n\nXOR\n\n\n\nA\nB\nC\n\n\n\n\n0\n0\n\n\n\n1\n0\n\n\n\n0\n1\n\n\n\n1\n1\n\n\n\n\nPowyższe bramki pozwalają łączyć poszczególne elementy algebry boola ze sobą.\n\nZadanie: Porównaj AND oraz OR z potocznym znaczeniem tych słów.\n\n\nZadanie: Dlaczego Algebra boola nazywana jest algebrą zbiorów?\n\n\nZadanie: Czy składanie podzbiorów zbioru również generuje algebrę boola ?\n\n\nZadanie: ile bramek logicznych możemy stworzyć dla jednego bitu, dwóch bitów, trzech bitów?\n\n\n\n\nUniweralne bramki logiczne - NAND\nTak jak widzieliśmy dla 1-bitu informacji mieliśmy 4 bramki logiczne. Dla 2-bitów mieliśmy 16 bramek logicznych. Dla 3-bitów mamy już 256 możliwości.\nW przypadku 2-bitów nie wypisaliśmy wszystkich bramek, dlaczego?\nCzy musimy realizować wszystkie?\n\nNa szczęście odpowiedź jest negatywna.\n\nIstnieją tzw. zbiory bramek uniwersalnych dzięki którym możemy zrealizować dowolną funkcję boolowską.\n\nNOT, AND, OR\nNAND, AND\nNAND\nNOT, OR\nNOR",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Bramki logiczne"
    ]
  },
  {
    "objectID": "lectures/wyklad2.html#szyfrowanie-z-wykorzystaniem-bramki-xor",
    "href": "lectures/wyklad2.html#szyfrowanie-z-wykorzystaniem-bramki-xor",
    "title": "Bramki logiczne",
    "section": "Szyfrowanie z wykorzystaniem bramki XOR",
    "text": "Szyfrowanie z wykorzystaniem bramki XOR\nWeźmy dwie sekwencje bitów:\nsekwencja A - przedstawiająca naszą zakodowaną wiadomośc: \\[1 0 1 1 0 1 1 1 0 0 0\\]\nlosowa sekwencja B: \\[0 1 1 0 1 1 0 1 1 0 1\\]\ni obliczmy XOR między dwoma sekwencjami (dla poszczególnych kolumn) \\(A\\) XOR \\(B\\).\nZgodnie z tablicą prawdy dla XOR otrzymujemy: \\[1 1 0 1 1 0 1 0 1 0 1\\]\nNa otrzymanym wyniku jeszcze raz zastosuj bramkę XOR.\nCo możesz zauważyć?\n\nOblicz A XOR B XOR B.\n\nZamień wiadomość, którą chcesz zaszyfrować na binarną postać (czyli jako sekwencję zer i jedynek).\nWeź losową sekwencję bitów (klucz szyfrujący), którą zna tylko nadawca i odbiorca.\n\\(1001011010...\\) - wiadomość\n\\(0110101010...\\) - klucz szyfrujący, czyli losowa sekwencja bitów\nZaszyfruj wiadomość wykonując operację XOR na każdym bicie wiadomości i klucza szyfrującego. Tak otrzymaną wiadomość (zaszyfrowaną) wyślij do odbiorcy.\n\ndecyrpting message\nOdbiorca otrzymuje zaszyfrowaną wiadomość (posiada klucz szyfrujący).\nMessage XOR SecretSequence = EncryptedMessage\nMessage XOR SecretSequence XOR SecretSequence = Message\nNie powinniśmy używać SecretSequence więcej niż raz. Jeśli użyjemy jej więcej niż raz, to łatwo jest złamać szyfrowanie.\n\nDlaczego nie powinno się używać szyfru więcej niż jeden raz? Podpowiedź: Zakodowana wiadomość przestaje być losowa.",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Bramki logiczne"
    ]
  },
  {
    "objectID": "lectures/wyklad1.html",
    "href": "lectures/wyklad1.html",
    "title": "Wprowadzenie do uczenia maszynowego",
    "section": "",
    "text": "Nature isn’t classical, dammit, and if you want to make a simulation of Nature, you’d better make it quantum mechanical, and by golly it’s a wonderful problem because it doesn’t look so easy. Richard Feynman",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Wprowadzenie do uczenia maszynowego"
    ]
  },
  {
    "objectID": "lectures/wyklad1.html#zanim-zaczniemy",
    "href": "lectures/wyklad1.html#zanim-zaczniemy",
    "title": "Wprowadzenie do uczenia maszynowego",
    "section": "Zanim zaczniemy",
    "text": "Zanim zaczniemy\n\nCo oznacza termin kwantowe uczenie maszynowe?\n\n\nCo wiesz o obliczeniach kwantowych?\n\n\nJakie masz oczekiwania i dlaczego interesujesz się QML?",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Wprowadzenie do uczenia maszynowego"
    ]
  },
  {
    "objectID": "lectures/wyklad1.html#podstawowe-pojęcia",
    "href": "lectures/wyklad1.html#podstawowe-pojęcia",
    "title": "Wprowadzenie do uczenia maszynowego",
    "section": "Podstawowe pojęcia",
    "text": "Podstawowe pojęcia\nUczenie maszynowe (w tym także uczenie głębokie) to dziedzina, która łączy naukę i technikę, pozwalając komputerom uczyć się na podstawie danych. Dzięki temu mogą one rozwiązywać problemy, których tradycyjne programowanie nie byłoby w stanie efektywnie rozwiązać – ze względu na złożoność, brak wzorców lub dynamicznie zmieniające się dane. Zamiast ręcznie programować konkretne rozwiązania, algorytmy uczą się na podstawie dostępnych danych, aby samodzielnie znaleźć wzorce i optymalne odpowiedzi. Więcej na ten temat znajdziesz w książce\nObliczenia kwantowe to interdyscyplinarna dziedzina wykorzystująca świat nauki kwantowej (fizyki, chemii) i technologii. Rozwija takie dziedziny jak: projektowanie algorytmów, teoria obliczeń złozonych, optymalizacja, architektura systemów komputerowych, czy tworzenie sprzętu komputerowego.\n\nWarto zauważyć, że klasyczne komputery (bazujące na tranzystorach) również działają zgodnie z prawami mechaniki kwantowej, jednak wykonywane przez nie operacje opierają się na klasycznej logice.\n\nOba podejścia – klasyczne i kwantowe – odgrywają kluczową rolę w przetwarzaniu danych zarówno dziś, jak i w niedalekiej przyszłości. Zatem nasuwa się naturalne pytanie: jak można te dwa światy ze sobą połączyć?\nXanadu link - what is quantum computing\nKwantowe uczenie maszynowe (ang. Quantum Machine Learning) to zastosowanie metod uczenia maszynowego, które mogą być realizowane na komputerach kwantowych. Wykorzystuje ono zjawiska mechaniki kwantowej, takie jak superpozycja i splątanie, aby potencjalnie przyspieszyć procesy uczenia i rozwiązywania problemów, które dla klasycznych komputerów mogą być zbyt złożone.\nXanadu link - What is QML\n\nyou start with classical mechanics and electrodynamics, solving lots of differential equations at every step. Then you learn about the “black-body paradox” and various strange experimental results, and the great crisis these things posed for physics. Next you learn a complicated patchwork of ideas that physicists invented between 1900 and 1926 to try to make the crisis go away. Then, if you’re lucky, after years of study you finally get around to the central conceptual point: that nature is described not by probabilities (which are always non-negative), but by numbers called amplitudes that can be positive, negative, or even complex. Scott Aaronson, Quantum Computing Since Democritus\n\nXanadu link - QML blog",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Wprowadzenie do uczenia maszynowego"
    ]
  },
  {
    "objectID": "lectures/wyklad1.html#sztuczna-inteligencja",
    "href": "lectures/wyklad1.html#sztuczna-inteligencja",
    "title": "Wprowadzenie do uczenia maszynowego",
    "section": "Sztuczna inteligencja",
    "text": "Sztuczna inteligencja\n\nHistoria sztucznej inteligencji (AI) sięga 1950 roku, kiedy Alan Turing zaproponował swój słynny test Turinga. Od tamtej pory rozwój technologii AI przyspieszył, obejmując zarówno dane ustrukturyzowane, jak i nieustrukturyzowane. Przykłady zastosowań AI obejmują:\n\nrozpoznawanie i generowanie mowy,\n,,rozumienie’’ obrazów i filmów,\nrozgrywanie gier (np. szachy, Go),\nsystemy rekomendacji (np. w e-commerce),\ndiagnostykę (np. w medycynie),\nplanowanie i optymalizację procesów,\npodejmowanie decyzji,\nchatboty i wirtualnych asystentów.\n\nWszystkie te zadania są realizowane dzięki zastosowaniu uczenia maszynowego (Machine Learning) oraz głębokich sieci neuronowych (Deep Learning).\nDlaczego sztuczna inteligencja jest tak chętnie wykorzystywana?\n\nWykładniczy wzrost ilości danych treningowych, dostępnych m.in. dzięki mediom społecznościowym, Internetowi, aplikacjom mobilnym i urządzeniom IoT.\nWzrost mocy obliczeniowej oraz spadek kosztów sprzętu komputerowego (np. co-procesorów GPU, TPU).\nDostępność oprogramowania typu Open Source, ułatwiającego rozwój AI.\nPrzewaga konkurencyjna, jaką zyskują firmy wykorzystujące AI w porównaniu do tych, które tego nie robią.\n\n\n\nUwaga! Zakładam, że masz podstawową znajomość pojęć związanych z uczeniem maszynowym i głębokim, ale w razie potrzeby, będziemy przypominać kluczowe zagadnienia.\n\n\nKategorie uczenia maszynowego\nUczenie maszynowe (ang. Machine Learning) można podzielić na kilka głównych kategorii:\n\nUczenie nadzorowane (ang. supervised learning) – mając oznaczone dane \\((x_i, y_i)\\) , uczymy model, który znajdzie funkcję \\(f(x_i) = y_i\\) , aby poprawnie przewidywać wartości dla nowych, nieznanych danych. Przykłady obejmują decyzje o przyznaniu kredytu lub klasyfikację obrazów, takich jak rozpoznanie, czy na obrazie znajduje się kot, czy pies.\nUczenie nienadzorowane (ang. unsupervised learning) – mając nieoznaczone dane (x_i) , szukamy ukrytych struktur w danych, takich jak grupowanie (klasteryzacja) czy redukcja wymiarów. Celem jest odkrywanie zależności lub wzorców, które nie są jawnie widoczne.\nUczenie przez wzmacnianie (ang. reinforcement learning) – agent uczy się podejmować decyzje w środowisku na podstawie nagród i kar, optymalizując swoje działania w celu maksymalizacji długoterminowych korzyści. Przykłady obejmują gry komputerowe, sterowanie robotami czy optymalizację procesów biznesowych.\nUczenie transferowe (ang. transfer learning) – technika, która polega na wykorzystaniu wiedzy nabytej w jednym zadaniu do rozwiązania innych, podobnych zadań. Przykładem jest model językowy nauczony rozumienia języka naturalnego, który może być wykorzystany do innych zadań, takich jak tłumaczenie maszynowe, analiza sentymentu czy rozpoznawanie tekstu pisanego.\nUczenie pół-nadzorowane (ang. semi-supervised learning) – podejście, które łączy dane oznaczone (z etykietami) i nieoznaczone (bez etykiet) w celu trenowania modelu. Jest to przydatne, gdy dostępnych jest dużo danych nieoznaczonych, ale tylko niewielka część z nich ma przypisane etykiety.",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Wprowadzenie do uczenia maszynowego"
    ]
  },
  {
    "objectID": "lectures/wyklad1.html#klasyczny-model-obliczeń",
    "href": "lectures/wyklad1.html#klasyczny-model-obliczeń",
    "title": "Wprowadzenie do uczenia maszynowego",
    "section": "Klasyczny model obliczeń",
    "text": "Klasyczny model obliczeń\nKomputer to fizyczne urządzenie, które przetwarza informacje za pomocą obwodów elektronicznych (ang. electronic circuits). Jego działanie opiera się na klasycznej logice binarnej, w której informacje są reprezentowane przez bity przyjmujące wartości \\(0\\) lub \\(1\\). Komputery klasyczne wykonują obliczenia, przetwarzając te bity za pomocą zestawu logicznych operacji, takich jak \\(AND\\), \\(OR\\), \\(NOT\\), oraz innych.\nKomputery klasyczne opierają swoje działanie na:\n\nProcesorach (CPU – Central Processing Unit), które wykonują instrukcje programu.\nPamięci (RAM – Random Access Memory), która tymczasowo przechowuje dane potrzebne do obliczeń.\nMagazynach danych, takich jak dyski twarde (HDD) lub półprzewodnikowe dyski (SSD), które służą do trwałego przechowywania danych.\nObwodach logicznych, zbudowanych na podstawie tranzystorów, które tworzą podstawowe elementy przetwarzania danych.\n\nKomputery klasyczne są niezwykle wydajne w rozwiązywaniu szerokiego spektrum problemów, zwłaszcza tych, które dają się łatwo zredukować do logicznych operacji lub operacji arytmetycznych. Jednakże, w miarę wzrostu złożoności problemów, ich wydajność może być ograniczona przez dostępne zasoby obliczeniowe i czas.\n\nAlgorytmy (programy komputerowe – ang. software) to sekwencje logicznych i matematycznych kroków, które definiują sposób rozwiązywania problemów lub wykonywania obliczeń przy użyciu komputera. Algorytmy są abstrakcyjnymi przepisami, które programy komputerowe implementują, aby przetwarzać dane i osiągać zamierzone cele. Wykorzystują one zasoby obliczeniowe komputera, takie jak procesor, pamięć i dysk, do wykonywania zadań w określonej kolejności i z określoną efektywnością.\nPrawo Moore’a\n\nPrawo Moore’a to obserwacja, że liczba tranzystorów na mikroczipie podwaja się mniej więcej co dwa lata, podczas gdy jego koszt zmniejsza się o połowę w tym samym okresie. Wzrost mocy mikroprocesorów jest wykładniczy.\n\nZwiększenie szybkości działania oraz pojemności klasycznych komputerów co dwa lata pozwala na szybsze i bardziej złożone obliczenia przy niższych kosztach. Jednak w ostatnich latach obserwujemy, że prawo Moore’a zbliża się do swoich fizycznych ograniczeń. Miniaturyzacja tranzystorów staje się coraz trudniejsza, co sugeruje, że dalszy wzrost mocy obliczeniowej komputerów tradycyjnych może być trudniejszy do osiągnięcia w dotychczasowy sposób.\n\n\nFizyczne (klasyczne) ograniczenia dla procesorów\n\nRozmiary tranzystora: Rozmiary tranzystorów zbliżają się do skali atomowej. W latach 90-tych tranzystory miały rozmiar około 500 nm, obecnie mają około 14 nm, a najnowsze technologie osiągają nawet 7 nm. Dalsze zmniejszanie rozmiarów napotyka na ograniczenia związane z fizyką materiałów.\nPrędkość światła: Jest to maksymalna prędkość przesyłu informacji w tradycyjnych układach komputerowych. Ogranicza to szybkość, z jaką dane mogą być przesyłane pomiędzy komponentami procesora i pamięci.\nWysoki koszt wytwarzania: Proces produkcji nowoczesnych układów scalonych jest bardzo kosztowny. To skłania do rozwoju układów wieloprocesorowych i rozwiązań z większą liczbą rdzeni w celu zwiększenia wydajności bez konieczności ciągłego zmniejszania tranzystorów.\nEfekty kwantowe: Gdy tranzystory stają się coraz mniejsze, pojawiają się efekty kwantowe, które mogą wpływać na ich działanie. Te efekty stają się istotne, gdy rozmiar tranzystora zbliża się do skali atomowej. Komputery kwantowe są próbą obejścia tych ograniczeń.\nWysoki pobór mocy: Zmniejszanie rozmiarów tranzystorów często prowadzi do zwiększenia gęstości obliczeniowej, co z kolei zwiększa pobór mocy i generuje więcej ciepła.\nGenerowanie ciepła: Zaawansowane komputery wykonujące intensywne obliczenia generują znaczne ilości ciepła. Problemy z chłodzeniem mogą wpływać na wydajność i niezawodność systemu, co wymaga innowacji w zakresie rozwiązań chłodzących.\nWykorzystanie rzadkich materiałów: Produkcja mikroprocesorów i układów scalonych wymaga rzadkich materiałów i zasobów, co może stanowić wyzwanie dla zrównoważonego rozwoju technologii komputerowych.\n\nDla większości praktycznych zastosowań opis makroskopowy oraz klasyczne teorie fizyczne są wystarczające do opisu właściwości prądu w obwodach elektrycznych. Jednak gdy celem jest realizacja obliczeń wykorzystujących mikroskopowe właściwości obiektów, klasyczny opis przestaje być adekwatny.\nW takich przypadkach konieczne jest zwrócenie się ku mechanice kwantowej, która jest najdokładniejszym i najbardziej powszechnie stosowanym modelem opisującym mikroświat. Komputer, który realizuje obliczenia zgodnie z zasadami mechaniki kwantowej, nazywamy komputerem kwantowym.\nDzięki zdolności do wykorzystania zjawisk kwantowych, takich jak superpozycja i splątanie, komputery kwantowe mogą rozwiązywać problemy, które są trudne lub wręcz niemożliwe do rozwiązania za pomocą klasycznych komputerów. Komputery kwantowe oferują obiecującą technologię, która otwiera nowe możliwości w dziedzinie obliczeń oraz nauki.",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Wprowadzenie do uczenia maszynowego"
    ]
  },
  {
    "objectID": "lectures/wyklad1.html#obliczenia-kwantowe",
    "href": "lectures/wyklad1.html#obliczenia-kwantowe",
    "title": "Wprowadzenie do uczenia maszynowego",
    "section": "Obliczenia kwantowe",
    "text": "Obliczenia kwantowe\n\nFilm wprowadzający: link\n\nNowy paradygmat obliczeń kwantowych wykorzystuje unikalne cechy interferencji, superpozycji i splątania do realizacji obliczeń. Obecnie realizowany jest w trzech głównych modelach:\n\nQuantum Circuits (Obwody Kwantowe) - oparty na modelu bramkowym, pozwala realizować algorytmy typu QAOA, VQA oraz metody hybrydowe.\nAdiabatyczne Obliczenia Kwantowe (D-Wave) - polegające na minimalizacji energii, wykorzystując optymalizację QUBO i analogię do modelu Isinga.\nTopologiczne Komputery Kwantowe - oparte na topologicznych kubitach.\n\n\nNie za krótkie wprowadzenie do fizyki kwantowej\nTermin Mechanika Kwantowa (MK) jest często używany zamiennie z teorią kwantową, choć istnieją również inne teorie kwantowe, takie jak Kwantowa Teoria Pola (ang. quantum field theory), które wykraczają poza zakres standardowej mechaniki kwantowej.\nMechanika Kwantowa przewiduje wyniki eksperymentów przeprowadzanych na układach kwantowych, tj. mikroskopowych obiektach fizycznych, dla których fizyka klasyczna nie jest wystarczająca do opisania ich zachowania. Przykładem może być atom wodoru. MK opisuje zachowanie takich obiektów jak fotony, elektrony oraz kwantowe bity (qubity).\nWarto zaznaczyć, że Mechanika Kwantowa jest fundamentem, na którym opiera się wiele innych teorii i dziedzin fizyki, w tym teorie kwantowe stosowane w obliczeniach kwantowych.\n\nNa naszym wykładzie nie będziemy koncentrować się na fizycznych właściwościach kubitów, lecz ograniczymy się do znajomości ich pewnych, abstrakcyjnych stanów, w jakich mogą się znajdować. Stany te będą numerowane liczbami naturalnymi.\n\nFizyka klasyczna jest zazwyczaj traktowana jako graniczny przypadek mechaniki kwantowej. Mimo to, w praktyce fizycy często oddzielają te dwie dziedziny i stosują odpowiednią teorię do odpowiednich problemów. Na przykład, w konstrukcji mostów wykorzystuje się fizykę klasyczną, a nie mechanikę kwantową.\nWarto również zaznaczyć, że wyniki mechaniki kwantowej mają charakter probabilistyczny, co może prowadzić do błędnego przekonania, że mechanika kwantowa jest teorią statystyczną. W rzeczywistości mechanikę kwantową można raczej uznać za uogólnienie klasycznej definicji prawdopodobieństwa.\n\n\nHistoria fizyki kwantowej\nPoczątki Mechaniki Kwantowej sięgają prac Maxa Plancka (1900) i Alberta Einsteina (1905), którzy wprowadzili pojęcie kwantu - najmniejszej jednostki energii. Rozwój tej dziedziny związany jest z badaniami wielu wybitnych naukowców, takich jak Niels Bohr, Erwin Schrödinger, Louis de Broglie, Werner Heisenberg, Paul Dirac, Richard Feynman i wielu innych.\nSzczegółowe informacje na temat historii obliczeń kwantowych można znaleźć w artykule o obliczeniach kwantowych.\n\nInformatyków zazwyczaj nie interesuje, jak dokładnie fizyczne właściwości układów są wykorzystywane do przechowywania informacji w komputerze klasycznym. Podobnie, nie muszą oni zgłębiać fizycznego mechanizmu, dzięki któremu informacja kwantowa jest realizowana w komputerze kwantowym. Tak jak prowadząc samochód, nie zastanawiasz się nad działaniem każdej jego części, tak samo pisząc kod, nie musisz interesować się, jak został on zaimplementowany w bibliotece. Informatycy często koncentrują się na efektywnym wykorzystaniu technologii komputerowych, a nie na szczegółach ich fizycznej realizacji.\n\n\n\nRealizacja komputerów kwantowych\nprocesory kwantowe\n\n\n\nHistoria obliczeń kwantowych\n\n1936: Alan Turing opublikował pracę On Computable Numbers, która stanowiła istotny krok w kierunku teoretycznych podstaw obliczeń (Hilbert Problems) - universal computing machine\n1976: Roman S. Ingarden opublikował artykuł Quantum Information Theory, wprowadzając pojęcie teorii informacji kwantowej, co miało kluczowe znaczenie dla rozwoju komputerów kwantowych.\n1980: Paul Benioff przedstawił teoretyczną koncepcję komputerów kwantowych jako fizycznych systemów, otwierając drzwi do praktycznych implementacji.\n1981: Richard Feynman zwrócił uwagę na to, że klasyczne komputery nie są w stanie efektywnie symulować procesów kwantowych.\n1985: David Deutsch opracował pierwszy opis kwantowej maszyny Turinga oraz algorytmy przeznaczone do uruchamiania na komputerach kwantowych, w tym bramki kwantowe.\n1994: Peter Shor opracował algorytm faktoryzacji liczb w czasie wielomianowym, co miało znaczenie dla kryptografii i bezpieczeństwa informacji.\n1996: Lov Grover stworzył algorytm Grovera, który okazał się wyjątkowo efektywny w przeszukiwaniu stanów kwantowych.\n2000: Zbudowano pierwszy komputer kwantowy (5 qubitów) oparty na nuklearnym rezonansie magnetycznym, co stanowiło ważny krok w rozwoju fizycznych platform komputerów kwantowych.\n2001: Demonstracja algorytmu Shora potwierdziła praktyczność i znaczenie algorytmów kwantowych.\n2007: Firma D-Wave sprzedała pierwszy komercyjny komputer kwantowy, co miało wpływ na rozwój technologii komputerów kwantowych w sektorze prywatnym.\n2019: 23 października, Google ogłosił uzyskanie tzw. quantum supremacy na 53 kubitach.\n2020: Zespół Jian-Wei Pana z University of Science and Technology of China dokonał przełomu, realizując 76 fotonowych kubitów na komputerze Jiuzhang.\n2022: Firma Xanadu dokonała znaczących postępów w dziedzinie technologii komputerów kwantowych.\n2023: Pojawienie się pierwszego logicznego qubitu? (wymaga dalszych szczegółów lub aktualizacji)\n2024: Google - Pierwsze zadowalające wyniki z kwantowej korekcji błędów\n\nOd około 1990 roku fizycy i informatycy pracują nad fizyczną realizacją komputerów kwantowych. Jednym z popularnych modeli obliczeń na komputerach kwantowych jest model oparty na kwantowych obwodach (ang. quantum circuits), który wykorzystuje qubity zamiast klasycznych bitów.\nPodobnie jak w przypadku obwodów klasycznych, w modelu kwantowym definiuje się bramki kwantowe (ang. quantum gates), które umożliwiają wykonywanie operacji na qubitach.\nFizyczna konstrukcja komputera kwantowego, a właściwie qubitu, jest zadaniem nietrywialnym, ponieważ wymaga manipulacji bardzo małym układem, który jest zazwyczaj wyjątkowo wrażliwy na wszelkie oddziaływania z otoczeniem. Efektem tych oddziaływań jest pomiar układu, który prowadzi do przejścia do jego stanu własnego (co oznacza zniszczenie przygotowanego stanu, np. superpozycji). Efekt ten nazywa się dekoherencją.\n\n\n\nDlaczego chcemy używać komputerów kwantowych?\nZasadnicze pytanie brzmi: na ile komputery kwantowe mogą faktycznie poprawić jakość modeli uczenia maszynowego i czy umożliwią realizację zadań, które są poza zasięgiem klasycznych komputerów.\n\nCo o tym sądzisz?\n\nMoja i książkowa odpowiedź: To zależy:\n\njaki problem chcemy rozwiązać?\njakie dane są dostępne i jakiej są natury?\njaki typ analizy chcemy przeprowadzić?\njaki typ komputera kwantowego wykorzystujemy (np. NISQ czy pełnoskalowy komputer kwantowy)?\nco rozumiemy przez “lepiej”? Precyzja, czas obliczeń, koszt, skalowalność, zużycie energii, a może coś innego?\n\n\nKwantowa Złożoność (Quantum Complexity)\nProblemy, które klasycznie są trudne do rozwiązania, takie jak optymalizacja, mogą być realizowane szybciej przez komputery kwantowe. Przykładem jest faktoryzacja liczb.\nPodstawowym faktem przewagi komputerów kwantowych nad klasycznymi jest tzw. parallelizm. Dzięki temu, że kubity mogą znajdować się w superpozycji stanów, komputer kwantowy może przeprowadzać obliczenia jednocześnie na wszystkich stanach. Co dokładnie to oznacza, poznamy w dalszej części wykładu.\nRozważmy sytuację, w której chcemy poznać działanie funkcji \\(f(x)\\) dla pewnego argumentu \\(x\\) . Aby znaleźć wynik dla dwóch liczb (np. \\(x = 0\\) i \\(x = 1\\)), klasyczny komputer musi wykonać dwie operacje. Komputer kwantowy może uzyskać ten wynik, przeprowadzając obliczenia jednocześnie dla obu wartości. Do wykonania takiej operacji wystarczy jeden kubit.\nJeśli chcemy obliczyć naszą funkcję dla kolejnych liczb \\(x = 2\\) (które binarnie reprezentowane jest jako 10 ) oraz liczby \\(x = 3\\) (binarnie 11 ), musimy dodać kolejny kubit. Dwa kubity mogą posłużyć do realizacji czterech równoległych operacji. Jeśli rozważymy 3 kubity, możemy podwoić liczbę operacji (3 kubity mają 8 stanów bazowych). Dodanie kubitu do komputera kwantowego pozwala podwoić liczbę równoległych obliczeń. W przypadku klasycznego komputera, aby uzyskać taki efekt, trzeba by podwoić liczbę bitów. Generalnie, n -kubitów może realizować 2^n równoległych obliczeń.\nDruga istotna koncepcja w obliczeniach kwantowych to pamięć.\nW klasycznych komputerach (np. 64-bitowy laptop) każda liczba może być reprezentowana w 64-bitowej formie (rozszerzenie reprezentacji 8-bitowej). Jeśli chcemy przechować 4 liczby w tej reprezentacji, potrzebujemy \\(4 \\times 64 = 256\\) bitów pamięci na twardym dysku. Generalnie, dla \\(M\\) liczb potrzebujemy \\(M \\times 64\\) bitów pamięci.\nW przypadku komputerów kwantowych operujących na \\(n\\)-kubitach, sytuacja wygląda inaczej. Możemy przechowywać \\(2^n\\) różnych współczynników, traktując taki stan jako pamięć. W odróżnieniu od klasycznej pamięci, gdzie ilość bitów pamięci jest liniowa w stosunku do liczby przechowywanych danych, pamięć realizowana na kubitach jest funkcją logarytmiczną od liczby liczb.\nPrzykładowo, dla \\(n\\)-kubitów, komputer kwantowy jest w stanie przechować \\(2^n\\) stanów, co jest równoważne \\(2^n\\) różnym współczynnikom. Tak więc, liczba kubitów potrzebnych do przechowania dużej ilości informacji rośnie znacznie wolniej niż liczba bitów w klasycznych komputerach.\nWspółczesne klasyczne komputery są bardzo zaawansowane i mogą zawierać dziesiątki terabajtów pamięci, co pozwala im na symulację niewielkich układów kwantowych. Największe klasyczne komputery są w stanie symulować układy do około 46 kubitów. Dla porównania, obecnie IBM oferuje komputery kwantowe oparte na 127 kubitach, a nawet rozwijają technologie dla układów z 1000 kubitami.\nPamięć w komputerach kwantowych jest znacznie bardziej efektywna w przechowywaniu informacji w porównaniu do klasycznych komputerów. Dzięki możliwości reprezentowania wielu stanów jednocześnie, komputery kwantowe oferują potencjalnie ogromne możliwości obliczeniowe przy znacznie mniejszych wymaganiach pamięciowych.\n\n\nKwantowa korekcja błędów (Quantum Error Correction)\nDekoherencja, czyli oddziaływanie kwantowego systemu z jego otoczeniem, może zniszczyć stan komputera kwantowego i wprowadzać błędy obliczeniowe. Aby zapewnić integralność obliczeń w komputerach kwantowych, konieczne jest zastosowanie technik korekcji błędów.\nKwantowa korekcja błędów (Quantum Error Correction) jest kluczowym obszarem badawczym w dziedzinie obliczeń kwantowych, który zajmuje się identyfikowaniem i korygowaniem błędów w systemach kwantowych. W przeciwieństwie do klasycznych systemów komputerowych, gdzie błędy mogą być łatwo korygowane, w przypadku komputerów kwantowych sytuacja jest bardziej złożona z powodu delikatnej natury stanów kwantowych oraz zjawisk takich jak superpozycja i splątanie.\nEra Noisy Intermediate-Scale Quantum (NISQ) oznacza, że obecne komputery kwantowe, mimo że są zaawansowane, wciąż są w fazie rozwoju i borykają się z problemami związanymi z błędami i stabilnością. Systemy NISQ są wystarczająco zaawansowane, by wykonywać pewne interesujące obliczenia kwantowe, ale nadal wymagają dalszych postępów w zakresie korekcji błędów oraz stabilności, aby mogły osiągnąć pełny potencjał.\nW praktyce, kwantowa korekcja błędów wymaga stosowania specjalnych kodów kwantowych, które pozwalają na detekcję i korekcję błędów bez bezpośredniego pomiaru stanów kwantowych. Kody te wprowadzają redundancję w reprezentacji informacji kwantowej, co pozwala na naprawę błędów i utrzymanie poprawności obliczeń.",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Wprowadzenie do uczenia maszynowego"
    ]
  },
  {
    "objectID": "lectures/wyklad1.html#proces-obliczeń-kwantowych",
    "href": "lectures/wyklad1.html#proces-obliczeń-kwantowych",
    "title": "Wprowadzenie do uczenia maszynowego",
    "section": "Proces obliczeń kwantowych",
    "text": "Proces obliczeń kwantowych\nW obliczeniach kwantowych cały proces można podzielić na trzy główne etapy:\n\nPrzygotowanie\n\nPrzygotowanie stanów kwantowych kubitów to pierwszy krok w procesie obliczeń kwantowych. W tym etapie tworzymy początkowy stan kubitów, który będzie podstawą dla dalszych operacji. Stan ten może być przygotowany na różne sposoby, w zależności od problemu i algorytmu, który chcemy zaimplementować. Przykładowo, kubity mogą być przygotowane w stanach podstawowych, stanach superpozycji lub w stanach splątanych.\n\nEwolucja\n\nEwolucja polega na stosowaniu bramek kwantowych, które transformują stan kubitów zgodnie z zaplanowanym algorytmem. Bramki kwantowe to odpowiedniki operacji logicznych w klasycznych komputerach, ale operują one na stanach kwantowych, wykorzystując zjawiska takie jak superpozycja i splątanie. Bramki kwantowe są reprezentowane przez macierze unitarnie, które przekształcają stany kubitów w czasie ewolucji obliczeń.\n\nPomiar i interpretacja wyników\n\nPo przeprowadzeniu ewolucji kwantowej następuje pomiar kubitów, który kończy obliczenia. Pomiar kwantowy “zapada” stan kubitu do jednego z możliwych wyników, co powoduje kolaps stanu kwantowego. Wyniki pomiaru są klasycznymi bitami, które można analizować i interpretować, aby uzyskać końcowy wynik obliczeń. Pomiar jest kluczowy, ponieważ to właśnie na podstawie wyników pomiarów uzyskujemy informacje, które są następnie analizowane w kontekście rozwiązania problemu.\n\n\nW codziennej interakcji z komputerem nie obserwujemy bezpośrednio tych etapów, ponieważ są one zautomatyzowane i wbudowane w działanie systemów komputerowych i programów. Dlatego często nie zauważamy świadomie tego schematu działania, mimo że jest on integralną częścią procesu obliczeń, zarówno klasycznych, jak i kwantowych. Piotr Gawron, Oscar Słowik - Rewolucja Stanu, Fantastyczne wprowadzenie do informatyki kwantowej.\n\nKażdy komputer kwantowy (lub koprocesor kwantowy) musi współpracować z układem klasycznym, aby realizować pełne obliczenia i operacje. Oto, jak ta integracja zazwyczaj wygląda:\n\nInterfejs Komunikacyjny\n\nKomputer kwantowy potrzebuje interfejsu do komunikacji z klasycznym komputerem. Interfejs ten umożliwia przesyłanie danych wejściowych do komputera kwantowego oraz odbieranie wyników obliczeń. Współczesne systemy często używają standardowych protokołów komunikacyjnych, takich jak TCP/IP, do przesyłania danych między układami klasycznymi a kwantowymi.\n\nPrzygotowanie Danych\n\nKlasyczny komputer przygotowuje dane wejściowe dla komputera kwantowego. Może to obejmować kodowanie danych w formacie odpowiednim dla kwantowego algorytmu oraz przygotowanie stanów kwantowych. Proces ten często wymaga przetworzenia i dostosowania danych do specyficznych wymagań obliczeń kwantowych.\n\nWykonanie Obliczeń\n\nKomputer kwantowy realizuje obliczenia, wykorzystując swoje qubity i bramki kwantowe. Operacje te są przeprowadzane zgodnie z algorytmami kwantowymi, które mogą wymagać precyzyjnego kontrolowania stanu qubitów i przeprowadzania skomplikowanych transformacji kwantowych.\n\nPomiar i interpretacja\n\nPo zakończeniu obliczeń kwantowych, wyniki są mierzone i interpretowane. Pomiar kwantowy powoduje kolaps stanu qubitów do jednego z możliwych wyników, który jest następnie przesyłany do klasycznego komputera.\n\nPostprocessing\n\nKlasyczny komputer przeprowadza dalszą obróbkę wyników, interpretując i analizując dane uzyskane z obliczeń kwantowych. Może to obejmować interpretację wyników, porównanie z oczekiwaniami oraz podejmowanie decyzji na podstawie uzyskanych wyników.\n\nWspółpraca i Synchronizacja\n\nWspółczesne systemy kwantowe często integrują komputery kwantowe jako koprocesory, które wspierają obliczenia klasyczne. Synchronizacja między komputerami kwantowymi a klasycznymi jest kluczowa dla efektywnego wykorzystania obu typów obliczeń i osiągnięcia optymalnych wyników.\nIntegracja komputerów kwantowych z klasycznymi umożliwia korzystanie z unikalnych właściwości obliczeń kwantowych przy jednoczesnym wykorzystaniu sprawdzonych technologii klasycznych, co pozwala na efektywne i wszechstronne podejście do rozwiązywania problemów obliczeniowych.",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Wprowadzenie do uczenia maszynowego"
    ]
  },
  {
    "objectID": "lectures/wyklad1.html#quantum-machine-learning",
    "href": "lectures/wyklad1.html#quantum-machine-learning",
    "title": "Wprowadzenie do uczenia maszynowego",
    "section": "Quantum Machine Learning",
    "text": "Quantum Machine Learning\n\nDane w QML\n\n\nCC - Classical data using classical computers, algorytmy inspirowane obliczeniami kwantowymi\nQC - Quantum data using classical (ML) computers. link1, link2, link3\nCQ - Classical data on qunatum computers. Na tym chcemy się skupić.\nQQ - Quantum data on quantum computers. Who knows?\n\n\n\nRealizacje problemów biznesowych na komputerach kwantowych\n\nSystemy obrony - kryptografia\nRigetti - przewidywanie pogody\nNASA (QuAIL) - Kontrola lotów kosmicznych\nAccenture - Finanse, logistyka, komunikacja i systemy bezpieczeństwa\nBASF - Obliczenia molekularne w chemii kwantowej.\nFord link\nVolkswagen link\nBMW link\nBoeing/Airbus\nGoldman Sach / JPMorgan\nDWave DWave and VW\nIBM Case study\nIBM 127 qubitów\nQuantum Natural Language Processing link\n\n\n\nDostęp do obliczeń kwantowych w chmurze\n\nIBM Quantum z wykorzystaniem biblioteki qiskit.\nPennylane z wykorzystaniem biblioteki pennylane.\nCirq Google z wykorzystaniem biblioteki cirq.\nD-Wave - Python\nXanadu - Pennylane Python library\nAmazon braket - AWS Python, Julia",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "Wprowadzenie do uczenia maszynowego"
    ]
  },
  {
    "objectID": "lectures/cw_w5.html",
    "href": "lectures/cw_w5.html",
    "title": "Trenowanie sieci neuronowej PyTorch",
    "section": "",
    "text": "import torch\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\n\ntorch.manual_seed(1234)\n\n# DANE \nx = torch.linspace(0,10,500).view(-1,1)\ny = torch.sin(x)\ny = y + 0.1*(torch.rand(500).view(-1,1)-0.5)\n\nplt.figure(figsize=(8,4))\nplt.plot(x, torch.sin(x).view(-1,1), color=\"tab:grey\", alpha=0.6, label=\"sin(x)\")\nplt.scatter(x,y, label=\"dane treningowe\")\nplt.xlabel('x')\nplt.ylabel('y')\nplt.legend()\nplt.show()",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "ćwiczenia do W5",
      "Trenowanie sieci neuronowej PyTorch"
    ]
  },
  {
    "objectID": "lectures/cw_w5.html#klasyczna-sieć-neuronowa",
    "href": "lectures/cw_w5.html#klasyczna-sieć-neuronowa",
    "title": "Trenowanie sieci neuronowej PyTorch",
    "section": "klasyczna sieć neuronowa",
    "text": "klasyczna sieć neuronowa\n\nclass SinusEstimator(torch.nn.Module):\n\n    def __init__(self, N_INPUT: int, N_OUTPUT: int):\n        super(SinusEstimator,self).__init__()\n        self.layers = torch.nn.Sequential(\n            torch.nn.Linear(N_INPUT, 64),\n            torch.nn.ReLU(),\n            torch.nn.Linear(64,32),\n            torch.nn.ReLU(),\n            torch.nn.Linear(32,16),\n            torch.nn.Tanh(),\n            torch.nn.Linear(16,N_OUTPUT)\n        )\n\n\n    def forward(self, x):\n        x = self.layers(x)\n        return x\n\nmodel = SinusEstimator(1,1)\n\nlearning_rate=0.001\noptimiser = torch.optim.Adam(model.parameters(), lr=learning_rate)\ncriterion = torch.nn.MSELoss()\n\nlosses = []\n\ndef callback(model, loss):\n    losses.append(loss.item())\n\n    clear_output(wait=True)\n    prediction = model(x).detach()\n    plt.figure(figsize=(6,2.5))\n    plt.plot(x[:,0].detach(), torch.sin(x)[:,0].detach(), label=\"Exact solution\", color=\"tab:grey\", alpha=0.6)\n    plt.plot(x[:,0].detach(), prediction[:,0], label=\"Classical solution\", color=\"tab:green\")\n    plt.title(f\"Training step {len(losses)}\")\n    plt.legend()\n    plt.show()\n\n    plt.figure(figsize=(6,2.5))\n    plt.title('Lossfn Visualised')\n    plt.plot(losses)\n    plt.show()\n\n\ndef train(X,Y, model, optimiser, epochs, lossfn, callback = None):\n    for epoch in range(epochs):\n        model.train()\n        prediction = model(X)\n        loss = lossfn(prediction, Y)\n\n        optimiser.zero_grad()\n        loss.backward()\n        optimiser.step()\n        model.eval()\n        if callback != None:\n            callback(model, loss)\n\nx_train = x.requires_grad_(True)\n\ntrain(x_train, y, model, optimiser, 300, criterion, callback)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSprawdź czy modyfikacja funkcji straty pomoze polepszyć wynik\n\ndef mse(y, y_pred) -&gt; torch.Tensor:\n    return torch.mean((y-y_pred)**2)\n\ndef special_loss_fn(y, y_pred) -&gt; torch.Tensor:\n    return mse(y, y_pred) + torch.mean((y_pred - torch.sin(x))**2)\n\nmodel2 = SinusEstimator(1,1)\n\nlearning_rate=0.001\noptimiser = torch.optim.Adam(model2.parameters(), lr=learning_rate)\ncriterion = torch.nn.MSELoss()\nlosses = []\n\ntrain(x_train, y, model2, optimiser, 200, special_loss_fn, callback)",
    "crumbs": [
      "Sylabus",
      "Wykłady",
      "ćwiczenia do W5",
      "Trenowanie sieci neuronowej PyTorch"
    ]
  }
]